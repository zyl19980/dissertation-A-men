/home/users/ntu/yzheng05/.conda/envs/A-mem-sglang/lib/python3.11/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.
We recommend installing via `pip install torch-c-dlpack-ext`
  warnings.warn(
[2025-12-17 19:51:36] WARNING server_args.py:1406: Attention backend not explicitly specified. Use flashinfer backend by default.
[2025-12-17 19:51:36] Fail to set RLIMIT_NOFILE: current limit exceeds maximum limit
[2025-12-17 19:51:36] server_args=ServerArgs(model_path='/scratch/users/ntu/yzheng05/models/Qwen2.5-1.5B-Instruct', tokenizer_path='/scratch/users/ntu/yzheng05/models/Qwen2.5-1.5B-Instruct', tokenizer_mode='auto', tokenizer_worker_num=1, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', rl_quant_profile=None, trust_remote_code=False, context_length=None, is_embedding=False, enable_multimodal=None, revision=None, model_impl='auto', host='0.0.0.0', port=30000, fastapi_root_path='', grpc_mode=False, skip_server_warmup=False, warmups=None, nccl_port=None, checkpoint_engine_wait_weights_before_ready=False, dtype='auto', quantization=None, quantization_param_path=None, kv_cache_dtype='auto', enable_fp32_lm_head=False, modelopt_quant=None, modelopt_checkpoint_restore_path=None, modelopt_checkpoint_save_path=None, modelopt_export_path=None, quantize_and_serve=False, mem_fraction_static=0.833, max_running_requests=None, max_queued_requests=None, max_total_tokens=None, chunked_prefill_size=4096, max_prefill_tokens=16384, schedule_policy='fcfs', enable_priority_scheduling=False, abort_on_priority_when_disabled=False, schedule_low_priority_values_first=False, priority_scheduling_preemption_threshold=10, schedule_conservativeness=1.0, page_size=1, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, radix_eviction_policy='lru', device='cuda', tp_size=1, pp_size=1, pp_max_micro_batch_size=None, stream_interval=1, stream_output=False, random_seed=759282162, constrained_json_whitespace_pattern=None, constrained_json_disable_any_whitespace=False, watchdog_timeout=300, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, mm_process_config={}, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, tokenizer_metrics_custom_labels_header='x-custom-labels', tokenizer_metrics_allowed_custom_labels=None, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, gc_warning_threshold_secs=0.0, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, enable_trace=False, otlp_traces_endpoint='localhost:4317', export_metrics_to_file=False, export_metrics_to_file_dir=None, api_key=None, served_model_name='/scratch/users/ntu/yzheng05/models/Qwen2.5-1.5B-Instruct', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, sampling_defaults='model', dp_size=1, load_balance_method='round_robin', load_watch_interval=0.1, prefill_round_robin_balance=False, dist_init_addr=None, nnodes=1, node_rank=0, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_eviction_policy='lru', lora_backend='csgmv', max_lora_chunk_size=16, attention_backend='flashinfer', decode_attention_backend=None, prefill_attention_backend=None, sampling_backend='flashinfer', grammar_backend='xgrammar', mm_attention_backend=None, fp8_gemm_runner_backend='auto', nsa_prefill_backend='flashmla_sparse', nsa_decode_backend='fa3', enable_flashinfer_autotune=False, speculative_algorithm=None, speculative_draft_model_path=None, speculative_draft_model_revision=None, speculative_draft_load_format=None, speculative_num_steps=None, speculative_eagle_topk=None, speculative_num_draft_tokens=None, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', speculative_moe_runner_backend=None, speculative_moe_a2a_backend=None, speculative_ngram_min_match_window_size=1, speculative_ngram_max_match_window_size=12, speculative_ngram_min_bfs_breadth=1, speculative_ngram_max_bfs_breadth=10, speculative_ngram_match_type='BFS', speculative_ngram_branch_length=18, speculative_ngram_capacity=10000000, ep_size=1, moe_a2a_backend='none', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='auto', ep_num_redundant_experts=0, ep_dispatch_algorithm=None, init_expert_location='trivial', enable_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=None, elastic_ep_backend=None, mooncake_ib_device=None, max_mamba_cache_size=None, mamba_ssm_dtype='float32', mamba_full_memory_ratio=0.9, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, kt_weight_path=None, kt_method='AMXINT4', kt_cpuinfer=None, kt_threadpool_count=2, kt_num_gpu_experts=None, kt_max_deferred_experts_per_token=None, dllm_algorithm=None, dllm_algorithm_config=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', multi_item_scoring_delimiter=None, disable_radix_cache=False, cuda_graph_max_bs=32, cuda_graph_bs=[1, 2, 4, 8, 12, 16, 24, 32], disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_layerwise_nvtx_marker=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_tokenizer_batch_decode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=False, enable_mscclpp=False, enable_torch_symm_mem=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=False, enable_dp_lm_head=False, enable_two_batch_overlap=False, enable_single_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, enable_piecewise_cuda_graph=False, enable_torch_compile_debug_mode=False, torch_compile_max_bs=32, piecewise_cuda_graph_max_tokens=4096, piecewise_cuda_graph_tokens=[4, 8, 12, 16, 20, 24, 28, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 640, 768, 896, 1024, 1152, 1280, 1408, 1536, 1664, 1792, 1920, 2048, 2176, 2304, 2432, 2560, 2688, 2816, 2944, 3072, 3200, 3328, 3456, 3584, 3712, 3840, 3968, 4096], piecewise_cuda_graph_compiler='eager', torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, triton_attention_split_tile_size=None, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, enable_weights_cpu_backup=False, enable_draft_weights_cpu_backup=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=False, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, keep_mm_feature_on_device=False, enable_return_hidden_states=False, scheduler_recv_interval=1, numa_node=None, enable_deterministic_inference=False, rl_on_policy_target=None, enable_attn_tp_input_scattered=False, enable_nsa_prefill_context_parallel=False, enable_fused_qk_norm_rope=False, enable_dynamic_batch_tokenizer=False, dynamic_batch_tokenizer_batch_size=32, dynamic_batch_tokenizer_batch_timeout=0.002, debug_tensor_dump_output_folder=None, debug_tensor_dump_layers=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, disaggregation_mode='null', disaggregation_transfer_backend='mooncake', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, disaggregation_decode_enable_offload_kvcache=False, num_reserved_decode_tokens=512, disaggregation_decode_polling_interval=1, custom_weight_loader=[], weight_loader_disable_mmap=False, remote_instance_weight_loader_seed_instance_ip=None, remote_instance_weight_loader_seed_instance_service_port=None, remote_instance_weight_loader_send_weights_group_ports=None, enable_pdmux=False, pdmux_config_path=None, sm_group_num=8, mm_max_concurrent_calls=32, mm_per_request_timeout=10.0, enable_broadcast_mm_inputs_process=False, decrypted_config_file=None, decrypted_draft_config_file=None, mm_enable_dp_encoder=False, forward_hooks=None)
[2025-12-17 19:51:37] Using default HuggingFace chat template with detected content format: string
/home/users/ntu/yzheng05/.conda/envs/A-mem-sglang/lib/python3.11/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.
We recommend installing via `pip install torch-c-dlpack-ext`
  warnings.warn(
[2025-12-17 19:51:50] Init torch distributed begin.
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[2025-12-17 19:51:50] Init torch distributed ends. mem usage=0.00 GB
[2025-12-17 19:51:50] MOE_RUNNER_BACKEND is not initialized, the backend will be automatically selected
/home/users/ntu/yzheng05/.conda/envs/A-mem-sglang/lib/python3.11/site-packages/tvm_ffi/_optional_torch_c_dlpack.py:174: UserWarning: Failed to JIT torch c dlpack extension, EnvTensorAllocator will not be enabled.
We recommend installing via `pip install torch-c-dlpack-ext`
  warnings.warn(
[2025-12-17 19:51:51] Ignore import error when loading sglang.srt.models.mindspore: name 'ms' is not defined
[2025-12-17 19:51:51] Load weight begin. avail mem=39.14 GB
Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.22it/s]
Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.22it/s]

[2025-12-17 19:51:52] Load weight end. type=Qwen2ForCausalLM, dtype=torch.bfloat16, avail mem=36.04 GB, mem usage=3.10 GB.
[2025-12-17 19:51:52] Using KV cache dtype: torch.bfloat16
[2025-12-17 19:51:52] KV Cache is allocated. #tokens: 1104879, K size: 14.75 GB, V size: 14.75 GB
[2025-12-17 19:51:52] Memory pool end. avail mem=5.97 GB
[2025-12-17 19:51:52] Capture cuda graph begin. This can take up to several minutes. avail mem=5.35 GB
[2025-12-17 19:51:52] Capture cuda graph bs [1, 2, 4, 8, 12, 16, 24, 32]
  0%|          | 0/8 [00:00<?, ?it/s]Capturing batches (bs=32 avail_mem=5.33 GB):   0%|          | 0/8 [00:00<?, ?it/s]Capturing batches (bs=32 avail_mem=5.33 GB):  12%|█▎        | 1/8 [00:01<00:08,  1.27s/it]Capturing batches (bs=24 avail_mem=5.28 GB):  12%|█▎        | 1/8 [00:01<00:08,  1.27s/it]Capturing batches (bs=16 avail_mem=5.25 GB):  12%|█▎        | 1/8 [00:01<00:08,  1.27s/it]Capturing batches (bs=16 avail_mem=5.25 GB):  38%|███▊      | 3/8 [00:01<00:01,  2.65it/s]Capturing batches (bs=12 avail_mem=5.25 GB):  38%|███▊      | 3/8 [00:01<00:01,  2.65it/s]Capturing batches (bs=8 avail_mem=5.22 GB):  38%|███▊      | 3/8 [00:01<00:01,  2.65it/s] Capturing batches (bs=4 avail_mem=5.22 GB):  38%|███▊      | 3/8 [00:01<00:01,  2.65it/s]Capturing batches (bs=4 avail_mem=5.22 GB):  75%|███████▌  | 6/8 [00:01<00:00,  5.72it/s]Capturing batches (bs=2 avail_mem=5.19 GB):  75%|███████▌  | 6/8 [00:01<00:00,  5.72it/s]Capturing batches (bs=1 avail_mem=5.19 GB):  75%|███████▌  | 6/8 [00:01<00:00,  5.72it/s]Capturing batches (bs=1 avail_mem=5.19 GB): 100%|██████████| 8/8 [00:01<00:00,  4.88it/s]
[2025-12-17 19:51:54] Capture cuda graph end. Time elapsed: 2.09 s. mem usage=0.19 GB. avail mem=5.16 GB.
[2025-12-17 19:51:54] max_total_num_tokens=1104879, chunked_prefill_size=4096, max_prefill_tokens=16384, max_running_requests=4096, context_len=32768, available_gpu_mem=5.16 GB
[2025-12-17 19:51:55] INFO:     Started server process [771311]
[2025-12-17 19:51:55] INFO:     Waiting for application startup.
[2025-12-17 19:51:55] Using default chat sampling params from model generation config: {'repetition_penalty': 1.1, 'temperature': 0.7, 'top_k': 20, 'top_p': 0.8}
[2025-12-17 19:51:55] Using default chat sampling params from model generation config: {'repetition_penalty': 1.1, 'temperature': 0.7, 'top_k': 20, 'top_p': 0.8}
[2025-12-17 19:51:55] INFO:     Application startup complete.
[2025-12-17 19:51:55] INFO:     Uvicorn running on http://0.0.0.0:30000 (Press CTRL+C to quit)
[2025-12-17 19:51:56] Endpoint '/get_model_info' is deprecated and will be removed in a future version. Please use '/model_info' instead.
[2025-12-17 19:51:56] INFO:     127.0.0.1:35600 - "GET /get_model_info HTTP/1.1" 200 OK
[2025-12-17 19:51:56] Prefill batch, #new-seq: 1, #new-token: 6, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:52:02] INFO:     127.0.0.1:35602 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:52:02] The server is fired up and ready to roll!
[2025-12-17 19:53:24] INFO:     127.0.0.1:35626 - "GET /v1/models HTTP/1.1" 200 OK
[2025-12-17 19:54:51] Prefill batch, #new-seq: 1, #new-token: 70, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:54:57] INFO:     127.0.0.1:35654 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:03] Prefill batch, #new-seq: 1, #new-token: 1343, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:03] INFO:     127.0.0.1:35668 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:26] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:26] INFO:     127.0.0.1:35684 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:26] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 0.19, #queue-req: 0, 
[2025-12-17 19:55:26] Prefill batch, #new-seq: 1, #new-token: 1270, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:26] INFO:     127.0.0.1:35688 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:28] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:28] INFO:     127.0.0.1:35692 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:28] Prefill batch, #new-seq: 1, #new-token: 1318, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:28] INFO:     127.0.0.1:35696 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:30] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:30] Decode batch, #running-req: 1, #token: 69, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.59, #queue-req: 0, 
[2025-12-17 19:55:30] INFO:     127.0.0.1:35700 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:30] Prefill batch, #new-seq: 1, #new-token: 962, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:30] Decode batch, #running-req: 1, #token: 992, token usage: 0.00, cuda graph: True, gen throughput (token/s): 192.43, #queue-req: 0, 
[2025-12-17 19:55:30] INFO:     127.0.0.1:35704 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:32] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:33] INFO:     127.0.0.1:35708 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:33] Prefill batch, #new-seq: 1, #new-token: 1437, #cached-token: 9, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:33] Decode batch, #running-req: 1, #token: 1448, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.68, #queue-req: 0, 
[2025-12-17 19:55:33] INFO:     127.0.0.1:35712 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:34] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:34] INFO:     127.0.0.1:35716 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:34] Prefill batch, #new-seq: 1, #new-token: 1212, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:34] INFO:     127.0.0.1:35720 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:36] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:36] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.96, #queue-req: 0, 
[2025-12-17 19:55:36] INFO:     127.0.0.1:35724 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:36] Prefill batch, #new-seq: 1, #new-token: 1098, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:36] INFO:     127.0.0.1:35728 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:38] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:38] INFO:     127.0.0.1:35732 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:38] Prefill batch, #new-seq: 1, #new-token: 1282, #cached-token: 37, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:38] INFO:     127.0.0.1:35736 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:40] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:40] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.04, #queue-req: 0, 
[2025-12-17 19:55:40] INFO:     127.0.0.1:35740 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:40] Prefill batch, #new-seq: 1, #new-token: 913, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:40] INFO:     127.0.0.1:35744 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:43] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:43] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.44, #queue-req: 0, 
[2025-12-17 19:55:43] INFO:     127.0.0.1:35748 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:43] Prefill batch, #new-seq: 1, #new-token: 840, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:43] INFO:     127.0.0.1:35752 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:44] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:45] INFO:     127.0.0.1:35756 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:45] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 971, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:45] Decode batch, #running-req: 1, #token: 993, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.18, #queue-req: 0, 
[2025-12-17 19:55:45] INFO:     127.0.0.1:35760 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:46] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:46] INFO:     127.0.0.1:35764 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:46] Prefill batch, #new-seq: 1, #new-token: 1100, #cached-token: 9, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:47] INFO:     127.0.0.1:35768 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:49] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:49] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.21, #queue-req: 0, 
[2025-12-17 19:55:49] INFO:     127.0.0.1:35772 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:49] Prefill batch, #new-seq: 1, #new-token: 1097, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:49] INFO:     127.0.0.1:35776 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:50] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:50] INFO:     127.0.0.1:35780 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:50] Prefill batch, #new-seq: 1, #new-token: 1388, #cached-token: 10, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:51] INFO:     127.0.0.1:35784 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:52] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:52] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.81, #queue-req: 0, 
[2025-12-17 19:55:52] INFO:     127.0.0.1:35790 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:52] Prefill batch, #new-seq: 1, #new-token: 1360, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:52] Decode batch, #running-req: 1, #token: 1426, token usage: 0.00, cuda graph: True, gen throughput (token/s): 181.14, #queue-req: 0, 
[2025-12-17 19:55:53] INFO:     127.0.0.1:35794 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:54] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:54] INFO:     127.0.0.1:35798 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:54] Prefill batch, #new-seq: 1, #new-token: 1029, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:54] Decode batch, #running-req: 1, #token: 1062, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.55, #queue-req: 0, 
[2025-12-17 19:55:54] INFO:     127.0.0.1:35802 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:57] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:57] INFO:     127.0.0.1:35806 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:57] Prefill batch, #new-seq: 1, #new-token: 1409, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:57] Decode batch, #running-req: 1, #token: 1433, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.42, #queue-req: 0, 
[2025-12-17 19:55:57] INFO:     127.0.0.1:35810 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:59] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:59] INFO:     127.0.0.1:35814 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:55:59] Prefill batch, #new-seq: 1, #new-token: 1618, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:55:59] INFO:     127.0.0.1:35818 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:00] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:01] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.88, #queue-req: 0, 
[2025-12-17 19:56:01] INFO:     127.0.0.1:35822 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:01] Prefill batch, #new-seq: 1, #new-token: 1347, #cached-token: 9, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:01] INFO:     127.0.0.1:35826 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:02] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:02] INFO:     127.0.0.1:35830 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:02] Prefill batch, #new-seq: 1, #new-token: 1229, #cached-token: 9, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:02] Decode batch, #running-req: 1, #token: 1249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.34, #queue-req: 0, 
[2025-12-17 19:56:02] INFO:     127.0.0.1:35834 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:04] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:04] INFO:     127.0.0.1:35842 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:04] Prefill batch, #new-seq: 1, #new-token: 1284, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:04] INFO:     127.0.0.1:35846 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:06] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:06] INFO:     127.0.0.1:35850 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:06] Prefill batch, #new-seq: 1, #new-token: 995, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:06] Decode batch, #running-req: 1, #token: 1010, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.77, #queue-req: 0, 
[2025-12-17 19:56:06] INFO:     127.0.0.1:35854 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:08] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:08] INFO:     127.0.0.1:35858 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:08] Prefill batch, #new-seq: 1, #new-token: 1184, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:08] INFO:     127.0.0.1:35862 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:10] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:10] Decode batch, #running-req: 1, #token: 70, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.92, #queue-req: 0, 
[2025-12-17 19:56:10] INFO:     127.0.0.1:35866 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:10] Prefill batch, #new-seq: 1, #new-token: 1352, #cached-token: 37, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:10] INFO:     127.0.0.1:35870 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:12] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:12] INFO:     127.0.0.1:35874 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:12] Prefill batch, #new-seq: 1, #new-token: 1111, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:12] Decode batch, #running-req: 1, #token: 1126, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.99, #queue-req: 0, 
[2025-12-17 19:56:12] INFO:     127.0.0.1:35878 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:14] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:14] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.89, #queue-req: 0, 
[2025-12-17 19:56:14] INFO:     127.0.0.1:35882 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:14] Prefill batch, #new-seq: 1, #new-token: 1038, #cached-token: 98, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:14] INFO:     127.0.0.1:35886 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:16] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:16] INFO:     127.0.0.1:35890 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:16] Prefill batch, #new-seq: 1, #new-token: 1257, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:16] INFO:     127.0.0.1:35894 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:17] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:17] Decode batch, #running-req: 1, #token: 71, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.76, #queue-req: 0, 
[2025-12-17 19:56:18] INFO:     127.0.0.1:35898 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:18] Prefill batch, #new-seq: 1, #new-token: 1291, #cached-token: 191, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:18] INFO:     127.0.0.1:35902 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:19] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:19] INFO:     127.0.0.1:35906 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:19] Prefill batch, #new-seq: 1, #new-token: 1484, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:19] Decode batch, #running-req: 1, #token: 1527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.35, #queue-req: 0, 
[2025-12-17 19:56:19] INFO:     127.0.0.1:35910 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:21] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:21] INFO:     127.0.0.1:35914 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:21] Prefill batch, #new-seq: 1, #new-token: 1395, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:21] INFO:     127.0.0.1:35918 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:23] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:23] INFO:     127.0.0.1:35922 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:23] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 1068, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:23] INFO:     127.0.0.1:35926 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:25] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:25] Decode batch, #running-req: 1, #token: 72, token usage: 0.00, cuda graph: True, gen throughput (token/s): 7.37, #queue-req: 0, 
[2025-12-17 19:56:25] INFO:     127.0.0.1:35930 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:25] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 973, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:25] INFO:     127.0.0.1:35934 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:27] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:27] INFO:     127.0.0.1:35938 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:27] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 954, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:27] Decode batch, #running-req: 1, #token: 975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.29, #queue-req: 0, 
[2025-12-17 19:56:27] INFO:     127.0.0.1:35942 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:29] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:29] Decode batch, #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.74, #queue-req: 0, 
[2025-12-17 19:56:29] Decode batch, #running-req: 1, #token: 139, token usage: 0.00, cuda graph: True, gen throughput (token/s): 215.84, #queue-req: 0, 
[2025-12-17 19:56:29] Decode batch, #running-req: 1, #token: 179, token usage: 0.00, cuda graph: True, gen throughput (token/s): 225.95, #queue-req: 0, 
[2025-12-17 19:56:29] Decode batch, #running-req: 1, #token: 219, token usage: 0.00, cuda graph: True, gen throughput (token/s): 226.12, #queue-req: 0, 
[2025-12-17 19:56:30] Decode batch, #running-req: 1, #token: 259, token usage: 0.00, cuda graph: True, gen throughput (token/s): 226.03, #queue-req: 0, 
[2025-12-17 19:56:30] Decode batch, #running-req: 1, #token: 299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 223.54, #queue-req: 0, 
[2025-12-17 19:56:30] Decode batch, #running-req: 1, #token: 339, token usage: 0.00, cuda graph: True, gen throughput (token/s): 223.23, #queue-req: 0, 
[2025-12-17 19:56:30] Decode batch, #running-req: 1, #token: 379, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.51, #queue-req: 0, 
[2025-12-17 19:56:30] Decode batch, #running-req: 1, #token: 419, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.09, #queue-req: 0, 
[2025-12-17 19:56:30] Decode batch, #running-req: 1, #token: 459, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.09, #queue-req: 0, 
[2025-12-17 19:56:31] Decode batch, #running-req: 1, #token: 499, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.82, #queue-req: 0, 
[2025-12-17 19:56:31] Decode batch, #running-req: 1, #token: 539, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.77, #queue-req: 0, 
[2025-12-17 19:56:31] Decode batch, #running-req: 1, #token: 579, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.83, #queue-req: 0, 
[2025-12-17 19:56:31] Decode batch, #running-req: 1, #token: 619, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.71, #queue-req: 0, 
[2025-12-17 19:56:31] Decode batch, #running-req: 1, #token: 659, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.76, #queue-req: 0, 
[2025-12-17 19:56:31] Decode batch, #running-req: 1, #token: 699, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.67, #queue-req: 0, 
[2025-12-17 19:56:32] Decode batch, #running-req: 1, #token: 739, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.65, #queue-req: 0, 
[2025-12-17 19:56:32] Decode batch, #running-req: 1, #token: 779, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.89, #queue-req: 0, 
[2025-12-17 19:56:32] Decode batch, #running-req: 1, #token: 819, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.52, #queue-req: 0, 
[2025-12-17 19:56:32] Decode batch, #running-req: 1, #token: 859, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.69, #queue-req: 0, 
[2025-12-17 19:56:32] Decode batch, #running-req: 1, #token: 899, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.56, #queue-req: 0, 
[2025-12-17 19:56:33] Decode batch, #running-req: 1, #token: 939, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.63, #queue-req: 0, 
[2025-12-17 19:56:33] Decode batch, #running-req: 1, #token: 979, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.48, #queue-req: 0, 
[2025-12-17 19:56:33] Decode batch, #running-req: 1, #token: 1019, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.70, #queue-req: 0, 
[2025-12-17 19:56:33] Decode batch, #running-req: 1, #token: 1059, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.07, #queue-req: 0, 
[2025-12-17 19:56:33] INFO:     127.0.0.1:35946 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:33] Prefill batch, #new-seq: 1, #new-token: 1020, #cached-token: 96, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:33] INFO:     127.0.0.1:35952 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:35] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:35] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.68, #queue-req: 0, 
[2025-12-17 19:56:35] INFO:     127.0.0.1:35956 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:35] Prefill batch, #new-seq: 1, #new-token: 820, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:35] INFO:     127.0.0.1:35960 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:37] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:37] INFO:     127.0.0.1:35964 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:37] Prefill batch, #new-seq: 1, #new-token: 6, #cached-token: 977, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:37] Decode batch, #running-req: 1, #token: 990, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.32, #queue-req: 0, 
[2025-12-17 19:56:37] INFO:     127.0.0.1:35968 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:39] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:39] INFO:     127.0.0.1:35972 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:39] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 974, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:39] INFO:     127.0.0.1:35976 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:41] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:41] Decode batch, #running-req: 1, #token: 71, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.16, #queue-req: 0, 
[2025-12-17 19:56:41] INFO:     127.0.0.1:35980 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:41] Prefill batch, #new-seq: 1, #new-token: 1125, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:41] INFO:     127.0.0.1:35984 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:43] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:43] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.44, #queue-req: 0, 
[2025-12-17 19:56:43] INFO:     127.0.0.1:35992 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:43] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 954, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:43] INFO:     127.0.0.1:35996 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:45] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:45] INFO:     127.0.0.1:36000 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:45] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 953, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:45] Decode batch, #running-req: 1, #token: 982, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.38, #queue-req: 0, 
[2025-12-17 19:56:45] INFO:     127.0.0.1:36004 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:47] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:47] INFO:     127.0.0.1:36008 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:47] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.07, #queue-req: 0, 
[2025-12-17 19:56:47] Prefill batch, #new-seq: 1, #new-token: 1264, #cached-token: 9, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:47] INFO:     127.0.0.1:36012 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:49] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:49] INFO:     127.0.0.1:36018 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:49] Prefill batch, #new-seq: 1, #new-token: 797, #cached-token: 148, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:49] Decode batch, #running-req: 1, #token: 962, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.39, #queue-req: 0, 
[2025-12-17 19:56:49] INFO:     127.0.0.1:36022 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:51] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:51] INFO:     127.0.0.1:36026 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:51] Prefill batch, #new-seq: 1, #new-token: 1386, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:51] INFO:     127.0.0.1:36030 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:53] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:53] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.93, #queue-req: 0, 
[2025-12-17 19:56:53] INFO:     127.0.0.1:36034 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:53] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 954, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:53] INFO:     127.0.0.1:36038 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:55] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:55] INFO:     127.0.0.1:36042 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:55] Prefill batch, #new-seq: 1, #new-token: 1241, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:55] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.39, #queue-req: 0, 
[2025-12-17 19:56:55] INFO:     127.0.0.1:36046 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:57] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:57] INFO:     127.0.0.1:36054 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:57] Prefill batch, #new-seq: 1, #new-token: 1399, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:57] INFO:     127.0.0.1:36058 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:58] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:59] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.81, #queue-req: 0, 
[2025-12-17 19:56:59] INFO:     127.0.0.1:36062 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:56:59] Prefill batch, #new-seq: 1, #new-token: 1420, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:56:59] INFO:     127.0.0.1:36066 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:00] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:00] INFO:     127.0.0.1:36070 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:00] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 953, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:01] INFO:     127.0.0.1:36074 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:02] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:03] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.01, #queue-req: 0, 
[2025-12-17 19:57:03] INFO:     127.0.0.1:36078 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:03] Prefill batch, #new-seq: 1, #new-token: 1383, #cached-token: 10, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:03] INFO:     127.0.0.1:36082 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:03] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 177.28, #queue-req: 0, 
[2025-12-17 19:57:04] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:05] INFO:     127.0.0.1:36086 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:05] Prefill batch, #new-seq: 1, #new-token: 1038, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:05] INFO:     127.0.0.1:36090 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:06] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:06] INFO:     127.0.0.1:36096 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:06] Prefill batch, #new-seq: 1, #new-token: 1363, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:06] Decode batch, #running-req: 1, #token: 1403, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.79, #queue-req: 0, 
[2025-12-17 19:57:06] INFO:     127.0.0.1:36100 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:08] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:08] INFO:     127.0.0.1:36104 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:08] Prefill batch, #new-seq: 1, #new-token: 1067, #cached-token: 173, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:08] Decode batch, #running-req: 1, #token: 1257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.35, #queue-req: 0, 
[2025-12-17 19:57:08] INFO:     127.0.0.1:36108 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:10] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:10] INFO:     127.0.0.1:36112 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:10] Prefill batch, #new-seq: 1, #new-token: 1246, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:10] INFO:     127.0.0.1:36116 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:13] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:13] Decode batch, #running-req: 1, #token: 70, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.18, #queue-req: 0, 
[2025-12-17 19:57:13] INFO:     127.0.0.1:36124 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:13] Prefill batch, #new-seq: 1, #new-token: 891, #cached-token: 173, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:13] INFO:     127.0.0.1:36128 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:15] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:15] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.70, #queue-req: 0, 
[2025-12-17 19:57:15] INFO:     127.0.0.1:36132 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:15] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 897, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:15] INFO:     127.0.0.1:36136 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:17] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:17] INFO:     127.0.0.1:36140 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:17] Prefill batch, #new-seq: 1, #new-token: 1199, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:17] Decode batch, #running-req: 1, #token: 1216, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.32, #queue-req: 0, 
[2025-12-17 19:57:17] INFO:     127.0.0.1:36144 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:19] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:19] INFO:     127.0.0.1:36150 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:19] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 954, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:19] INFO:     127.0.0.1:36154 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:21] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:21] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.03, #queue-req: 0, 
[2025-12-17 19:57:21] INFO:     127.0.0.1:36158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:21] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 974, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:21] INFO:     127.0.0.1:36162 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:23] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:23] INFO:     127.0.0.1:36166 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:23] Prefill batch, #new-seq: 1, #new-token: 1274, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:23] Decode batch, #running-req: 1, #token: 1406, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.68, #queue-req: 0, 
[2025-12-17 19:57:23] INFO:     127.0.0.1:36170 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:25] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:25] INFO:     127.0.0.1:36174 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:25] Prefill batch, #new-seq: 1, #new-token: 1380, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:25] Decode batch, #running-req: 1, #token: 1400, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.93, #queue-req: 0, 
[2025-12-17 19:57:25] INFO:     127.0.0.1:36178 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:27] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:27] Decode batch, #running-req: 1, #token: 70, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.84, #queue-req: 0, 
[2025-12-17 19:57:27] INFO:     127.0.0.1:36182 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:27] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 1047, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:27] INFO:     127.0.0.1:36186 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:29] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:29] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.58, #queue-req: 0, 
[2025-12-17 19:57:29] INFO:     127.0.0.1:36190 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:29] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 1047, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:29] INFO:     127.0.0.1:36194 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:31] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:31] INFO:     127.0.0.1:36198 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:31] Prefill batch, #new-seq: 1, #new-token: 1070, #cached-token: 37, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:31] INFO:     127.0.0.1:36202 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:32] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:32] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.85, #queue-req: 0, 
[2025-12-17 19:57:33] INFO:     127.0.0.1:36206 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:33] Prefill batch, #new-seq: 1, #new-token: 1301, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:33] Decode batch, #running-req: 1, #token: 1345, token usage: 0.00, cuda graph: True, gen throughput (token/s): 187.30, #queue-req: 0, 
[2025-12-17 19:57:33] Decode batch, #running-req: 1, #token: 1385, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 19:57:33] Decode batch, #running-req: 1, #token: 1425, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.90, #queue-req: 0, 
[2025-12-17 19:57:33] Decode batch, #running-req: 1, #token: 1465, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.18, #queue-req: 0, 
[2025-12-17 19:57:33] Decode batch, #running-req: 1, #token: 1505, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.15, #queue-req: 0, 
[2025-12-17 19:57:34] Decode batch, #running-req: 1, #token: 1545, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 19:57:34] Decode batch, #running-req: 1, #token: 1585, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 19:57:34] Decode batch, #running-req: 1, #token: 1625, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 19:57:34] Decode batch, #running-req: 1, #token: 1665, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 19:57:34] Decode batch, #running-req: 1, #token: 1705, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 19:57:35] Decode batch, #running-req: 1, #token: 1745, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 19:57:35] Decode batch, #running-req: 1, #token: 1785, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 19:57:35] Decode batch, #running-req: 1, #token: 1825, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 19:57:35] Decode batch, #running-req: 1, #token: 1865, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 19:57:35] Decode batch, #running-req: 1, #token: 1905, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 19:57:35] Decode batch, #running-req: 1, #token: 1945, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 19:57:36] Decode batch, #running-req: 1, #token: 1985, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.97, #queue-req: 0, 
[2025-12-17 19:57:36] Decode batch, #running-req: 1, #token: 2025, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 19:57:36] Decode batch, #running-req: 1, #token: 2065, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 19:57:36] Decode batch, #running-req: 1, #token: 2105, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 19:57:36] Decode batch, #running-req: 1, #token: 2145, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 19:57:37] Decode batch, #running-req: 1, #token: 2185, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.25, #queue-req: 0, 
[2025-12-17 19:57:37] Decode batch, #running-req: 1, #token: 2225, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.28, #queue-req: 0, 
[2025-12-17 19:57:37] Decode batch, #running-req: 1, #token: 2265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.33, #queue-req: 0, 
[2025-12-17 19:57:37] Decode batch, #running-req: 1, #token: 2305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.33, #queue-req: 0, 
[2025-12-17 19:57:37] INFO:     127.0.0.1:36210 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:39] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:39] INFO:     127.0.0.1:36216 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:39] Prefill batch, #new-seq: 1, #new-token: 1154, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:39] Decode batch, #running-req: 1, #token: 1202, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.75, #queue-req: 0, 
[2025-12-17 19:57:39] INFO:     127.0.0.1:36220 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:41] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:41] INFO:     127.0.0.1:36224 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:41] Prefill batch, #new-seq: 1, #new-token: 1469, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:41] Decode batch, #running-req: 1, #token: 1486, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.05, #queue-req: 0, 
[2025-12-17 19:57:41] INFO:     127.0.0.1:36228 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:41] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.71, #queue-req: 0, 
[2025-12-17 19:57:43] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:43] INFO:     127.0.0.1:36232 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:43] Prefill batch, #new-seq: 1, #new-token: 1357, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:43] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.62, #queue-req: 0, 
[2025-12-17 19:57:43] INFO:     127.0.0.1:36236 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:45] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:45] INFO:     127.0.0.1:36242 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:45] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 974, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:45] INFO:     127.0.0.1:36246 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:47] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:47] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.90, #queue-req: 0, 
[2025-12-17 19:57:47] INFO:     127.0.0.1:36250 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:47] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 894, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:47] INFO:     127.0.0.1:36254 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:49] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:49] INFO:     127.0.0.1:36258 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:49] Prefill batch, #new-seq: 1, #new-token: 1052, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:49] Decode batch, #running-req: 1, #token: 1068, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.43, #queue-req: 0, 
[2025-12-17 19:57:49] INFO:     127.0.0.1:36262 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:51] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:51] INFO:     127.0.0.1:36266 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:51] Prefill batch, #new-seq: 1, #new-token: 1540, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:51] INFO:     127.0.0.1:36270 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:53] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:53] Decode batch, #running-req: 1, #token: 72, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.89, #queue-req: 0, 
[2025-12-17 19:57:53] INFO:     127.0.0.1:36274 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:53] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 954, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:53] INFO:     127.0.0.1:36278 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:55] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:55] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.54, #queue-req: 0, 
[2025-12-17 19:57:55] INFO:     127.0.0.1:36282 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:55] Prefill batch, #new-seq: 1, #new-token: 1046, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:55] INFO:     127.0.0.1:36286 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:56] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:56] INFO:     127.0.0.1:36290 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:56] Prefill batch, #new-seq: 1, #new-token: 7, #cached-token: 974, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:57] Decode batch, #running-req: 1, #token: 990, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.42, #queue-req: 0, 
[2025-12-17 19:57:57] INFO:     127.0.0.1:36294 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:58] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:58] INFO:     127.0.0.1:36300 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:57:58] Prefill batch, #new-seq: 1, #new-token: 1146, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:57:59] Decode batch, #running-req: 1, #token: 1183, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.60, #queue-req: 0, 
[2025-12-17 19:57:59] Decode batch, #running-req: 1, #token: 1223, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 19:57:59] Decode batch, #running-req: 1, #token: 1263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 19:57:59] Decode batch, #running-req: 1, #token: 1303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.64, #queue-req: 0, 
[2025-12-17 19:57:59] Decode batch, #running-req: 1, #token: 1343, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 19:57:59] Decode batch, #running-req: 1, #token: 1383, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.42, #queue-req: 0, 
[2025-12-17 19:58:00] Decode batch, #running-req: 1, #token: 1423, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 19:58:00] Decode batch, #running-req: 1, #token: 1463, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 19:58:00] Decode batch, #running-req: 1, #token: 1503, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 19:58:00] Decode batch, #running-req: 1, #token: 1543, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 19:58:00] Decode batch, #running-req: 1, #token: 1583, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 19:58:01] Decode batch, #running-req: 1, #token: 1623, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 19:58:01] Decode batch, #running-req: 1, #token: 1663, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.38, #queue-req: 0, 
[2025-12-17 19:58:01] Decode batch, #running-req: 1, #token: 1703, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 19:58:01] Decode batch, #running-req: 1, #token: 1743, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.34, #queue-req: 0, 
[2025-12-17 19:58:01] Decode batch, #running-req: 1, #token: 1783, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 19:58:01] Decode batch, #running-req: 1, #token: 1823, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 19:58:02] Decode batch, #running-req: 1, #token: 1863, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.24, #queue-req: 0, 
[2025-12-17 19:58:02] Decode batch, #running-req: 1, #token: 1903, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.39, #queue-req: 0, 
[2025-12-17 19:58:02] Decode batch, #running-req: 1, #token: 1943, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 19:58:02] Decode batch, #running-req: 1, #token: 1983, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.62, #queue-req: 0, 
[2025-12-17 19:58:02] Decode batch, #running-req: 1, #token: 2023, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.55, #queue-req: 0, 
[2025-12-17 19:58:03] Decode batch, #running-req: 1, #token: 2063, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.42, #queue-req: 0, 
[2025-12-17 19:58:03] Decode batch, #running-req: 1, #token: 2103, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.91, #queue-req: 0, 
[2025-12-17 19:58:03] Decode batch, #running-req: 1, #token: 2143, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.11, #queue-req: 0, 
[2025-12-17 19:58:03] INFO:     127.0.0.1:36304 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:05] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:05] INFO:     127.0.0.1:36308 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:05] Prefill batch, #new-seq: 1, #new-token: 1215, #cached-token: 9, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:05] INFO:     127.0.0.1:36312 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:07] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:07] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.93, #queue-req: 0, 
[2025-12-17 19:58:07] INFO:     127.0.0.1:36316 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:07] Prefill batch, #new-seq: 1, #new-token: 1213, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:07] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 188.69, #queue-req: 0, 
[2025-12-17 19:58:07] INFO:     127.0.0.1:36320 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:09] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:09] INFO:     127.0.0.1:36324 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:09] Prefill batch, #new-seq: 1, #new-token: 1047, #cached-token: 99, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:09] INFO:     127.0.0.1:36328 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:10] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:10] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.93, #queue-req: 0, 
[2025-12-17 19:58:10] INFO:     127.0.0.1:36332 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:10] Prefill batch, #new-seq: 1, #new-token: 1205, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:11] INFO:     127.0.0.1:36336 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:12] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:12] INFO:     127.0.0.1:36340 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:12] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 1126, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:12] INFO:     127.0.0.1:36344 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:14] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:14] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.89, #queue-req: 0, 
[2025-12-17 19:58:14] INFO:     127.0.0.1:36348 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:14] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 974, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:14] INFO:     127.0.0.1:36352 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:16] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:16] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.74, #queue-req: 0, 
[2025-12-17 19:58:16] INFO:     127.0.0.1:36358 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:16] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 850, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:16] INFO:     127.0.0.1:36362 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:18] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:18] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.50, #queue-req: 0, 
[2025-12-17 19:58:18] INFO:     127.0.0.1:36366 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:18] Prefill batch, #new-seq: 1, #new-token: 1519, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:18] INFO:     127.0.0.1:36370 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:20] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:20] INFO:     127.0.0.1:36374 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:20] Prefill batch, #new-seq: 1, #new-token: 1181, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:20] Decode batch, #running-req: 1, #token: 1224, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.15, #queue-req: 0, 
[2025-12-17 19:58:20] INFO:     127.0.0.1:36378 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:22] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:22] INFO:     127.0.0.1:36382 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:22] Prefill batch, #new-seq: 1, #new-token: 1276, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:22] Decode batch, #running-req: 1, #token: 1323, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.40, #queue-req: 0, 
[2025-12-17 19:58:22] INFO:     127.0.0.1:36386 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:24] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:24] INFO:     127.0.0.1:36390 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:24] Prefill batch, #new-seq: 1, #new-token: 1301, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:24] INFO:     127.0.0.1:36394 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:26] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:26] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.78, #queue-req: 0, 
[2025-12-17 19:58:26] INFO:     127.0.0.1:36398 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:26] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 877, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:26] INFO:     127.0.0.1:36402 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:28] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:28] INFO:     127.0.0.1:36406 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:28] Prefill batch, #new-seq: 1, #new-token: 1106, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:28] Decode batch, #running-req: 1, #token: 1125, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.44, #queue-req: 0, 
[2025-12-17 19:58:28] INFO:     127.0.0.1:36410 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:30] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:30] INFO:     127.0.0.1:36414 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:30] Prefill batch, #new-seq: 1, #new-token: 1389, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:30] Decode batch, #running-req: 1, #token: 1433, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.73, #queue-req: 0, 
[2025-12-17 19:58:30] INFO:     127.0.0.1:36418 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:31] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:32] INFO:     127.0.0.1:36424 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:32] Prefill batch, #new-seq: 1, #new-token: 1155, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:32] INFO:     127.0.0.1:36428 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:33] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:33] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.94, #queue-req: 0, 
[2025-12-17 19:58:33] INFO:     127.0.0.1:36434 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:33] Prefill batch, #new-seq: 1, #new-token: 1075, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:34] INFO:     127.0.0.1:36438 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:35] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:35] Decode batch, #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.57, #queue-req: 0, 
[2025-12-17 19:58:36] Decode batch, #running-req: 1, #token: 129, token usage: 0.00, cuda graph: True, gen throughput (token/s): 227.40, #queue-req: 0, 
[2025-12-17 19:58:36] Decode batch, #running-req: 1, #token: 169, token usage: 0.00, cuda graph: True, gen throughput (token/s): 225.88, #queue-req: 0, 
[2025-12-17 19:58:36] Decode batch, #running-req: 1, #token: 209, token usage: 0.00, cuda graph: True, gen throughput (token/s): 225.82, #queue-req: 0, 
[2025-12-17 19:58:36] Decode batch, #running-req: 1, #token: 249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 225.89, #queue-req: 0, 
[2025-12-17 19:58:36] Decode batch, #running-req: 1, #token: 289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 223.76, #queue-req: 0, 
[2025-12-17 19:58:36] Decode batch, #running-req: 1, #token: 329, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.98, #queue-req: 0, 
[2025-12-17 19:58:37] Decode batch, #running-req: 1, #token: 369, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.49, #queue-req: 0, 
[2025-12-17 19:58:37] Decode batch, #running-req: 1, #token: 409, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.88, #queue-req: 0, 
[2025-12-17 19:58:37] Decode batch, #running-req: 1, #token: 449, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.66, #queue-req: 0, 
[2025-12-17 19:58:37] Decode batch, #running-req: 1, #token: 489, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.75, #queue-req: 0, 
[2025-12-17 19:58:37] Decode batch, #running-req: 1, #token: 529, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.63, #queue-req: 0, 
[2025-12-17 19:58:38] Decode batch, #running-req: 1, #token: 569, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.39, #queue-req: 0, 
[2025-12-17 19:58:38] Decode batch, #running-req: 1, #token: 609, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.42, #queue-req: 0, 
[2025-12-17 19:58:38] Decode batch, #running-req: 1, #token: 649, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.32, #queue-req: 0, 
[2025-12-17 19:58:38] Decode batch, #running-req: 1, #token: 689, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.34, #queue-req: 0, 
[2025-12-17 19:58:38] Decode batch, #running-req: 1, #token: 729, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.39, #queue-req: 0, 
[2025-12-17 19:58:38] Decode batch, #running-req: 1, #token: 769, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.30, #queue-req: 0, 
[2025-12-17 19:58:39] Decode batch, #running-req: 1, #token: 809, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.40, #queue-req: 0, 
[2025-12-17 19:58:39] Decode batch, #running-req: 1, #token: 849, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.25, #queue-req: 0, 
[2025-12-17 19:58:39] Decode batch, #running-req: 1, #token: 889, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.15, #queue-req: 0, 
[2025-12-17 19:58:39] Decode batch, #running-req: 1, #token: 929, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.19, #queue-req: 0, 
[2025-12-17 19:58:39] Decode batch, #running-req: 1, #token: 969, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.30, #queue-req: 0, 
[2025-12-17 19:58:39] Decode batch, #running-req: 1, #token: 1009, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.46, #queue-req: 0, 
[2025-12-17 19:58:40] Decode batch, #running-req: 1, #token: 1049, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.12, #queue-req: 0, 
[2025-12-17 19:58:40] INFO:     127.0.0.1:36444 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:40] Prefill batch, #new-seq: 1, #new-token: 1127, #cached-token: 133, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:40] Decode batch, #running-req: 1, #token: 1281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 186.69, #queue-req: 0, 
[2025-12-17 19:58:40] Decode batch, #running-req: 1, #token: 1321, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 19:58:40] Decode batch, #running-req: 1, #token: 1361, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 19:58:40] Decode batch, #running-req: 1, #token: 1401, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 19:58:41] Decode batch, #running-req: 1, #token: 1441, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 19:58:41] Decode batch, #running-req: 1, #token: 1481, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.62, #queue-req: 0, 
[2025-12-17 19:58:41] Decode batch, #running-req: 1, #token: 1521, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 19:58:41] Decode batch, #running-req: 1, #token: 1561, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 19:58:41] Decode batch, #running-req: 1, #token: 1601, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 19:58:42] Decode batch, #running-req: 1, #token: 1641, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 19:58:42] Decode batch, #running-req: 1, #token: 1681, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 19:58:42] Decode batch, #running-req: 1, #token: 1721, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.42, #queue-req: 0, 
[2025-12-17 19:58:42] Decode batch, #running-req: 1, #token: 1761, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 19:58:42] Decode batch, #running-req: 1, #token: 1801, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.34, #queue-req: 0, 
[2025-12-17 19:58:42] Decode batch, #running-req: 1, #token: 1841, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.35, #queue-req: 0, 
[2025-12-17 19:58:43] Decode batch, #running-req: 1, #token: 1881, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.21, #queue-req: 0, 
[2025-12-17 19:58:43] Decode batch, #running-req: 1, #token: 1921, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.32, #queue-req: 0, 
[2025-12-17 19:58:43] Decode batch, #running-req: 1, #token: 1961, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 19:58:43] Decode batch, #running-req: 1, #token: 2001, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 19:58:43] Decode batch, #running-req: 1, #token: 2041, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 19:58:44] Decode batch, #running-req: 1, #token: 2081, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.10, #queue-req: 0, 
[2025-12-17 19:58:44] Decode batch, #running-req: 1, #token: 2121, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.02, #queue-req: 0, 
[2025-12-17 19:58:44] Decode batch, #running-req: 1, #token: 2161, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.75, #queue-req: 0, 
[2025-12-17 19:58:44] Decode batch, #running-req: 1, #token: 2201, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.94, #queue-req: 0, 
[2025-12-17 19:58:44] Decode batch, #running-req: 1, #token: 2241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.85, #queue-req: 0, 
[2025-12-17 19:58:44] INFO:     127.0.0.1:36450 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:46] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:46] INFO:     127.0.0.1:36454 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:46] Prefill batch, #new-seq: 1, #new-token: 1095, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:46] INFO:     127.0.0.1:36458 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:48] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:48] Decode batch, #running-req: 1, #token: 71, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.80, #queue-req: 0, 
[2025-12-17 19:58:48] INFO:     127.0.0.1:36464 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:48] Prefill batch, #new-seq: 1, #new-token: 1382, #cached-token: 40, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:48] INFO:     127.0.0.1:36468 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:50] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:50] INFO:     127.0.0.1:36472 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:50] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 954, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:50] Decode batch, #running-req: 1, #token: 975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.51, #queue-req: 0, 
[2025-12-17 19:58:50] INFO:     127.0.0.1:36476 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:52] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:52] INFO:     127.0.0.1:36480 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:52] Prefill batch, #new-seq: 1, #new-token: 1273, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:52] INFO:     127.0.0.1:36484 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:54] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:54] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.98, #queue-req: 0, 
[2025-12-17 19:58:54] INFO:     127.0.0.1:36488 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:54] Prefill batch, #new-seq: 1, #new-token: 1419, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:54] INFO:     127.0.0.1:36492 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:55] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:55] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.70, #queue-req: 0, 
[2025-12-17 19:58:55] INFO:     127.0.0.1:36498 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:55] Prefill batch, #new-seq: 1, #new-token: 1365, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:56] INFO:     127.0.0.1:36502 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:57] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:57] INFO:     127.0.0.1:36506 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:58:57] Prefill batch, #new-seq: 1, #new-token: 858, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:58:57] Decode batch, #running-req: 1, #token: 940, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.35, #queue-req: 0, 
[2025-12-17 19:58:58] Decode batch, #running-req: 1, #token: 980, token usage: 0.00, cuda graph: True, gen throughput (token/s): 216.81, #queue-req: 0, 
[2025-12-17 19:58:58] Decode batch, #running-req: 1, #token: 1020, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.59, #queue-req: 0, 
[2025-12-17 19:58:58] Decode batch, #running-req: 1, #token: 1060, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.99, #queue-req: 0, 
[2025-12-17 19:58:58] Decode batch, #running-req: 1, #token: 1100, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.03, #queue-req: 0, 
[2025-12-17 19:58:58] Decode batch, #running-req: 1, #token: 1140, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 19:58:59] Decode batch, #running-req: 1, #token: 1180, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.98, #queue-req: 0, 
[2025-12-17 19:58:59] Decode batch, #running-req: 1, #token: 1220, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.03, #queue-req: 0, 
[2025-12-17 19:58:59] Decode batch, #running-req: 1, #token: 1260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.06, #queue-req: 0, 
[2025-12-17 19:58:59] Decode batch, #running-req: 1, #token: 1300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 19:58:59] Decode batch, #running-req: 1, #token: 1340, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.98, #queue-req: 0, 
[2025-12-17 19:58:59] Decode batch, #running-req: 1, #token: 1380, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.12, #queue-req: 0, 
[2025-12-17 19:59:00] Decode batch, #running-req: 1, #token: 1420, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.06, #queue-req: 0, 
[2025-12-17 19:59:00] Decode batch, #running-req: 1, #token: 1460, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.99, #queue-req: 0, 
[2025-12-17 19:59:00] Decode batch, #running-req: 1, #token: 1500, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.06, #queue-req: 0, 
[2025-12-17 19:59:00] Decode batch, #running-req: 1, #token: 1540, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 19:59:00] Decode batch, #running-req: 1, #token: 1580, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 19:59:01] Decode batch, #running-req: 1, #token: 1620, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 19:59:01] Decode batch, #running-req: 1, #token: 1660, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 19:59:01] Decode batch, #running-req: 1, #token: 1700, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 19:59:01] Decode batch, #running-req: 1, #token: 1740, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 19:59:01] Decode batch, #running-req: 1, #token: 1780, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 19:59:01] Decode batch, #running-req: 1, #token: 1820, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 19:59:02] Decode batch, #running-req: 1, #token: 1860, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.64, #queue-req: 0, 
[2025-12-17 19:59:02] Decode batch, #running-req: 1, #token: 1900, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 19:59:02] INFO:     127.0.0.1:36510 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:04] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:04] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.05, #queue-req: 0, 
[2025-12-17 19:59:04] INFO:     127.0.0.1:36514 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:04] Prefill batch, #new-seq: 1, #new-token: 1354, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:04] Decode batch, #running-req: 1, #token: 1428, token usage: 0.00, cuda graph: True, gen throughput (token/s): 185.98, #queue-req: 0, 
[2025-12-17 19:59:04] INFO:     127.0.0.1:36518 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:06] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:06] INFO:     127.0.0.1:36522 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:06] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 956, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:06] INFO:     127.0.0.1:36528 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:07] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:08] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.96, #queue-req: 0, 
[2025-12-17 19:59:08] INFO:     127.0.0.1:36534 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:08] Prefill batch, #new-seq: 1, #new-token: 1264, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:08] INFO:     127.0.0.1:36538 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:09] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:09] INFO:     127.0.0.1:36542 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:09] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 1380, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:10] Decode batch, #running-req: 1, #token: 1408, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.25, #queue-req: 0, 
[2025-12-17 19:59:10] Decode batch, #running-req: 1, #token: 1448, token usage: 0.00, cuda graph: True, gen throughput (token/s): 212.52, #queue-req: 0, 
[2025-12-17 19:59:10] Decode batch, #running-req: 1, #token: 1488, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 19:59:10] Decode batch, #running-req: 1, #token: 1528, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 19:59:10] Decode batch, #running-req: 1, #token: 1568, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.26, #queue-req: 0, 
[2025-12-17 19:59:10] Decode batch, #running-req: 1, #token: 1608, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 19:59:11] Decode batch, #running-req: 1, #token: 1648, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.43, #queue-req: 0, 
[2025-12-17 19:59:11] Decode batch, #running-req: 1, #token: 1688, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.40, #queue-req: 0, 
[2025-12-17 19:59:11] Decode batch, #running-req: 1, #token: 1728, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 19:59:11] Decode batch, #running-req: 1, #token: 1768, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.36, #queue-req: 0, 
[2025-12-17 19:59:11] Decode batch, #running-req: 1, #token: 1808, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.34, #queue-req: 0, 
[2025-12-17 19:59:12] Decode batch, #running-req: 1, #token: 1848, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.27, #queue-req: 0, 
[2025-12-17 19:59:12] Decode batch, #running-req: 1, #token: 1888, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.34, #queue-req: 0, 
[2025-12-17 19:59:12] Decode batch, #running-req: 1, #token: 1928, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.39, #queue-req: 0, 
[2025-12-17 19:59:12] Decode batch, #running-req: 1, #token: 1968, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 19:59:12] Decode batch, #running-req: 1, #token: 2008, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 19:59:12] Decode batch, #running-req: 1, #token: 2048, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 19:59:13] Decode batch, #running-req: 1, #token: 2088, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.92, #queue-req: 0, 
[2025-12-17 19:59:13] Decode batch, #running-req: 1, #token: 2128, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.04, #queue-req: 0, 
[2025-12-17 19:59:13] Decode batch, #running-req: 1, #token: 2168, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.03, #queue-req: 0, 
[2025-12-17 19:59:13] Decode batch, #running-req: 1, #token: 2208, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.87, #queue-req: 0, 
[2025-12-17 19:59:13] Decode batch, #running-req: 1, #token: 2248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.00, #queue-req: 0, 
[2025-12-17 19:59:14] Decode batch, #running-req: 1, #token: 2288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.01, #queue-req: 0, 
[2025-12-17 19:59:14] Decode batch, #running-req: 1, #token: 2328, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.88, #queue-req: 0, 
[2025-12-17 19:59:14] Decode batch, #running-req: 1, #token: 2368, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.91, #queue-req: 0, 
[2025-12-17 19:59:14] INFO:     127.0.0.1:36546 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:16] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:16] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.02, #queue-req: 0, 
[2025-12-17 19:59:16] INFO:     127.0.0.1:36552 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:16] Prefill batch, #new-seq: 1, #new-token: 1117, #cached-token: 116, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:16] INFO:     127.0.0.1:36556 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:18] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:18] INFO:     127.0.0.1:36560 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:18] Prefill batch, #new-seq: 1, #new-token: 1375, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:18] INFO:     127.0.0.1:36564 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:20] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:20] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.28, #queue-req: 0, 
[2025-12-17 19:59:20] INFO:     127.0.0.1:36568 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:20] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 956, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:20] Decode batch, #running-req: 1, #token: 999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 183.62, #queue-req: 0, 
[2025-12-17 19:59:20] INFO:     127.0.0.1:36572 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:22] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:22] INFO:     127.0.0.1:36576 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:22] Prefill batch, #new-seq: 1, #new-token: 1069, #cached-token: 41, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:22] INFO:     127.0.0.1:36580 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:24] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:24] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.92, #queue-req: 0, 
[2025-12-17 19:59:24] INFO:     127.0.0.1:36584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:24] Prefill batch, #new-seq: 1, #new-token: 1052, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:24] INFO:     127.0.0.1:36588 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:26] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:26] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.11, #queue-req: 0, 
[2025-12-17 19:59:26] INFO:     127.0.0.1:36592 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:26] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 1047, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:26] INFO:     127.0.0.1:36596 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:28] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:28] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.29, #queue-req: 0, 
[2025-12-17 19:59:28] INFO:     127.0.0.1:36600 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:28] Prefill batch, #new-seq: 1, #new-token: 1250, #cached-token: 147, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:28] INFO:     127.0.0.1:36604 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:30] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:30] INFO:     127.0.0.1:36608 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:30] Prefill batch, #new-seq: 1, #new-token: 1180, #cached-token: 170, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:30] Decode batch, #running-req: 1, #token: 1352, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.41, #queue-req: 0, 
[2025-12-17 19:59:30] INFO:     127.0.0.1:36612 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:32] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:32] INFO:     127.0.0.1:36618 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:32] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 954, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:32] INFO:     127.0.0.1:36622 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:32] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.75, #queue-req: 0, 
[2025-12-17 19:59:34] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:34] INFO:     127.0.0.1:36626 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:34] Prefill batch, #new-seq: 1, #new-token: 1228, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:34] INFO:     127.0.0.1:36630 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:36] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:36] INFO:     127.0.0.1:36634 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:36] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 956, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:36] Decode batch, #running-req: 1, #token: 972, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.10, #queue-req: 0, 
[2025-12-17 19:59:36] INFO:     127.0.0.1:36638 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:38] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:38] INFO:     127.0.0.1:36642 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:38] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 954, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:38] Decode batch, #running-req: 1, #token: 974, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.64, #queue-req: 0, 
[2025-12-17 19:59:38] Decode batch, #running-req: 1, #token: 1014, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.75, #queue-req: 0, 
[2025-12-17 19:59:38] Decode batch, #running-req: 1, #token: 1054, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.21, #queue-req: 0, 
[2025-12-17 19:59:38] Decode batch, #running-req: 1, #token: 1094, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.02, #queue-req: 0, 
[2025-12-17 19:59:39] Decode batch, #running-req: 1, #token: 1134, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.96, #queue-req: 0, 
[2025-12-17 19:59:39] Decode batch, #running-req: 1, #token: 1174, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 19:59:39] Decode batch, #running-req: 1, #token: 1214, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 19:59:39] Decode batch, #running-req: 1, #token: 1254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 19:59:39] Decode batch, #running-req: 1, #token: 1294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 19:59:40] Decode batch, #running-req: 1, #token: 1334, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 19:59:40] Decode batch, #running-req: 1, #token: 1374, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 19:59:40] Decode batch, #running-req: 1, #token: 1414, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 19:59:40] Decode batch, #running-req: 1, #token: 1454, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.06, #queue-req: 0, 
[2025-12-17 19:59:40] Decode batch, #running-req: 1, #token: 1494, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.14, #queue-req: 0, 
[2025-12-17 19:59:40] Decode batch, #running-req: 1, #token: 1534, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.06, #queue-req: 0, 
[2025-12-17 19:59:41] Decode batch, #running-req: 1, #token: 1574, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 19:59:41] Decode batch, #running-req: 1, #token: 1614, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 19:59:41] Decode batch, #running-req: 1, #token: 1654, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 19:59:41] Decode batch, #running-req: 1, #token: 1694, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 19:59:41] Decode batch, #running-req: 1, #token: 1734, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 19:59:42] Decode batch, #running-req: 1, #token: 1774, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 19:59:42] Decode batch, #running-req: 1, #token: 1814, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 19:59:42] Decode batch, #running-req: 1, #token: 1854, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 19:59:42] Decode batch, #running-req: 1, #token: 1894, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.53, #queue-req: 0, 
[2025-12-17 19:59:42] Decode batch, #running-req: 1, #token: 1934, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 19:59:42] INFO:     127.0.0.1:36646 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:44] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:44] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.90, #queue-req: 0, 
[2025-12-17 19:59:44] INFO:     127.0.0.1:36650 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:44] Prefill batch, #new-seq: 1, #new-token: 1247, #cached-token: 38, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:44] INFO:     127.0.0.1:36654 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:46] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:46] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.73, #queue-req: 0, 
[2025-12-17 19:59:46] INFO:     127.0.0.1:36658 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:46] Prefill batch, #new-seq: 1, #new-token: 1291, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:46] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 179.01, #queue-req: 0, 
[2025-12-17 19:59:46] INFO:     127.0.0.1:36662 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:48] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:48] INFO:     127.0.0.1:36666 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:48] Prefill batch, #new-seq: 1, #new-token: 1103, #cached-token: 184, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:48] INFO:     127.0.0.1:36670 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:48] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.40, #queue-req: 0, 
[2025-12-17 19:59:50] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:50] INFO:     127.0.0.1:36676 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:50] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 1047, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:50] INFO:     127.0.0.1:36680 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:52] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:52] INFO:     127.0.0.1:36684 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:52] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.97, #queue-req: 0, 
[2025-12-17 19:59:52] Prefill batch, #new-seq: 1, #new-token: 1185, #cached-token: 48, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:52] INFO:     127.0.0.1:36688 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:54] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:54] INFO:     127.0.0.1:36692 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:54] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 953, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:54] Decode batch, #running-req: 1, #token: 977, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.27, #queue-req: 0, 
[2025-12-17 19:59:54] INFO:     127.0.0.1:36696 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:56] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:56] INFO:     127.0.0.1:36700 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:56] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 1105, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:56] INFO:     127.0.0.1:36704 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 19:59:58] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 19:59:58] Decode batch, #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.99, #queue-req: 0, 
[2025-12-17 19:59:58] Decode batch, #running-req: 1, #token: 131, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.21, #queue-req: 0, 
[2025-12-17 19:59:58] Decode batch, #running-req: 1, #token: 171, token usage: 0.00, cuda graph: True, gen throughput (token/s): 226.71, #queue-req: 0, 
[2025-12-17 19:59:58] Decode batch, #running-req: 1, #token: 211, token usage: 0.00, cuda graph: True, gen throughput (token/s): 226.78, #queue-req: 0, 
[2025-12-17 19:59:59] Decode batch, #running-req: 1, #token: 251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 226.78, #queue-req: 0, 
[2025-12-17 19:59:59] Decode batch, #running-req: 1, #token: 291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 224.47, #queue-req: 0, 
[2025-12-17 19:59:59] Decode batch, #running-req: 1, #token: 331, token usage: 0.00, cuda graph: True, gen throughput (token/s): 223.81, #queue-req: 0, 
[2025-12-17 19:59:59] Decode batch, #running-req: 1, #token: 371, token usage: 0.00, cuda graph: True, gen throughput (token/s): 223.27, #queue-req: 0, 
[2025-12-17 19:59:59] Decode batch, #running-req: 1, #token: 411, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.68, #queue-req: 0, 
[2025-12-17 20:00:00] Decode batch, #running-req: 1, #token: 451, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.67, #queue-req: 0, 
[2025-12-17 20:00:00] Decode batch, #running-req: 1, #token: 491, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.47, #queue-req: 0, 
[2025-12-17 20:00:00] Decode batch, #running-req: 1, #token: 531, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.36, #queue-req: 0, 
[2025-12-17 20:00:00] Decode batch, #running-req: 1, #token: 571, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.29, #queue-req: 0, 
[2025-12-17 20:00:00] Decode batch, #running-req: 1, #token: 611, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.21, #queue-req: 0, 
[2025-12-17 20:00:00] Decode batch, #running-req: 1, #token: 651, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.21, #queue-req: 0, 
[2025-12-17 20:00:01] Decode batch, #running-req: 1, #token: 691, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.37, #queue-req: 0, 
[2025-12-17 20:00:01] Decode batch, #running-req: 1, #token: 731, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.16, #queue-req: 0, 
[2025-12-17 20:00:01] Decode batch, #running-req: 1, #token: 771, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.15, #queue-req: 0, 
[2025-12-17 20:00:01] Decode batch, #running-req: 1, #token: 811, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.13, #queue-req: 0, 
[2025-12-17 20:00:01] Decode batch, #running-req: 1, #token: 851, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.10, #queue-req: 0, 
[2025-12-17 20:00:02] Decode batch, #running-req: 1, #token: 891, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.11, #queue-req: 0, 
[2025-12-17 20:00:02] Decode batch, #running-req: 1, #token: 931, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.28, #queue-req: 0, 
[2025-12-17 20:00:02] Decode batch, #running-req: 1, #token: 971, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.11, #queue-req: 0, 
[2025-12-17 20:00:02] Decode batch, #running-req: 1, #token: 1011, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.26, #queue-req: 0, 
[2025-12-17 20:00:02] Decode batch, #running-req: 1, #token: 1051, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.82, #queue-req: 0, 
[2025-12-17 20:00:02] INFO:     127.0.0.1:36708 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:02] Prefill batch, #new-seq: 1, #new-token: 1102, #cached-token: 41, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:02] Decode batch, #running-req: 1, #token: 1160, token usage: 0.00, cuda graph: True, gen throughput (token/s): 169.25, #queue-req: 0, 
[2025-12-17 20:00:03] INFO:     127.0.0.1:36712 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:04] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:04] INFO:     127.0.0.1:36716 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:04] Prefill batch, #new-seq: 1, #new-token: 1185, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:04] INFO:     127.0.0.1:36720 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:06] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:06] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.76, #queue-req: 0, 
[2025-12-17 20:00:06] INFO:     127.0.0.1:36724 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:06] Prefill batch, #new-seq: 1, #new-token: 1295, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:06] INFO:     127.0.0.1:36728 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:08] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:08] INFO:     127.0.0.1:36732 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:08] Prefill batch, #new-seq: 1, #new-token: 892, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:08] Decode batch, #running-req: 1, #token: 1065, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.36, #queue-req: 0, 
[2025-12-17 20:00:08] INFO:     127.0.0.1:36736 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:10] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:10] INFO:     127.0.0.1:36740 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:10] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 954, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:10] INFO:     127.0.0.1:36744 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:12] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:12] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.67, #queue-req: 0, 
[2025-12-17 20:00:12] INFO:     127.0.0.1:36748 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:12] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 956, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:12] INFO:     127.0.0.1:36752 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:14] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:14] INFO:     127.0.0.1:36758 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:14] Prefill batch, #new-seq: 1, #new-token: 931, #cached-token: 102, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:14] Decode batch, #running-req: 1, #token: 1041, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.19, #queue-req: 0, 
[2025-12-17 20:00:14] INFO:     127.0.0.1:36762 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:16] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:16] INFO:     127.0.0.1:36766 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:16] Prefill batch, #new-seq: 1, #new-token: 1061, #cached-token: 101, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:16] Decode batch, #running-req: 1, #token: 1183, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.10, #queue-req: 0, 
[2025-12-17 20:00:16] INFO:     127.0.0.1:36770 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:18] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:18] INFO:     127.0.0.1:36774 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:18] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 953, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:18] INFO:     127.0.0.1:36778 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:20] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:20] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.48, #queue-req: 0, 
[2025-12-17 20:00:20] INFO:     127.0.0.1:36782 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:20] Prefill batch, #new-seq: 1, #new-token: 1025, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:20] INFO:     127.0.0.1:36786 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:22] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:22] INFO:     127.0.0.1:36790 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:22] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 1046, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:22] Decode batch, #running-req: 1, #token: 1066, token usage: 0.00, cuda graph: True, gen throughput (token/s): 14.60, #queue-req: 0, 
[2025-12-17 20:00:23] INFO:     127.0.0.1:36794 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:25] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:25] INFO:     127.0.0.1:36798 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:25] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.09, #queue-req: 0, 
[2025-12-17 20:00:25] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 954, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:25] INFO:     127.0.0.1:36804 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:26] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:27] INFO:     127.0.0.1:36810 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:27] Prefill batch, #new-seq: 1, #new-token: 1398, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:27] Decode batch, #running-req: 1, #token: 1445, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.99, #queue-req: 0, 
[2025-12-17 20:00:27] Decode batch, #running-req: 1, #token: 1485, token usage: 0.00, cuda graph: True, gen throughput (token/s): 218.75, #queue-req: 0, 
[2025-12-17 20:00:27] INFO:     127.0.0.1:36814 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:29] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:29] INFO:     127.0.0.1:36818 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:29] Prefill batch, #new-seq: 1, #new-token: 880, #cached-token: 171, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:29] Decode batch, #running-req: 1, #token: 1060, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.67, #queue-req: 0, 
[2025-12-17 20:00:29] INFO:     127.0.0.1:36822 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:31] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:31] INFO:     127.0.0.1:36826 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:31] Prefill batch, #new-seq: 1, #new-token: 1294, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:31] INFO:     127.0.0.1:36830 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:33] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:33] Decode batch, #running-req: 1, #token: 92, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.60, #queue-req: 0, 
[2025-12-17 20:00:33] INFO:     127.0.0.1:36836 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:33] Prefill batch, #new-seq: 1, #new-token: 1154, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:33] INFO:     127.0.0.1:36840 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:35] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:35] Decode batch, #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.26, #queue-req: 0, 
[2025-12-17 20:00:35] INFO:     127.0.0.1:36844 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:35] Prefill batch, #new-seq: 1, #new-token: 24, #cached-token: 1047, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:35] INFO:     127.0.0.1:36848 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:37] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:37] INFO:     127.0.0.1:36852 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:37] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 954, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:37] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.90, #queue-req: 0, 
[2025-12-17 20:00:37] INFO:     127.0.0.1:36856 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:40] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:40] INFO:     127.0.0.1:36860 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:40] Prefill batch, #new-seq: 1, #new-token: 1118, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:40] INFO:     127.0.0.1:36864 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:42] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:42] Decode batch, #running-req: 1, #token: 72, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.23, #queue-req: 0, 
[2025-12-17 20:00:42] INFO:     127.0.0.1:36868 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:42] Prefill batch, #new-seq: 1, #new-token: 1140, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:42] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 177.54, #queue-req: 0, 
[2025-12-17 20:00:42] INFO:     127.0.0.1:36872 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:44] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:44] INFO:     127.0.0.1:36878 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:44] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 876, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:44] Decode batch, #running-req: 1, #token: 915, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.77, #queue-req: 0, 
[2025-12-17 20:00:44] Decode batch, #running-req: 1, #token: 955, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.79, #queue-req: 0, 
[2025-12-17 20:00:44] Decode batch, #running-req: 1, #token: 995, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.51, #queue-req: 0, 
[2025-12-17 20:00:44] Decode batch, #running-req: 1, #token: 1035, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.42, #queue-req: 0, 
[2025-12-17 20:00:45] Decode batch, #running-req: 1, #token: 1075, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.96, #queue-req: 0, 
[2025-12-17 20:00:45] Decode batch, #running-req: 1, #token: 1115, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.94, #queue-req: 0, 
[2025-12-17 20:00:45] Decode batch, #running-req: 1, #token: 1155, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.94, #queue-req: 0, 
[2025-12-17 20:00:45] Decode batch, #running-req: 1, #token: 1195, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.12, #queue-req: 0, 
[2025-12-17 20:00:45] Decode batch, #running-req: 1, #token: 1235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.02, #queue-req: 0, 
[2025-12-17 20:00:45] Decode batch, #running-req: 1, #token: 1275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 20:00:46] Decode batch, #running-req: 1, #token: 1315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 20:00:46] Decode batch, #running-req: 1, #token: 1355, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.94, #queue-req: 0, 
[2025-12-17 20:00:46] Decode batch, #running-req: 1, #token: 1395, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:00:46] Decode batch, #running-req: 1, #token: 1435, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.14, #queue-req: 0, 
[2025-12-17 20:00:46] Decode batch, #running-req: 1, #token: 1475, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.10, #queue-req: 0, 
[2025-12-17 20:00:47] Decode batch, #running-req: 1, #token: 1515, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 20:00:47] Decode batch, #running-req: 1, #token: 1555, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:00:47] Decode batch, #running-req: 1, #token: 1595, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:00:47] Decode batch, #running-req: 1, #token: 1635, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:00:47] Decode batch, #running-req: 1, #token: 1675, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:00:47] Decode batch, #running-req: 1, #token: 1715, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:00:48] Decode batch, #running-req: 1, #token: 1755, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:00:48] Decode batch, #running-req: 1, #token: 1795, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:00:48] Decode batch, #running-req: 1, #token: 1835, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.45, #queue-req: 0, 
[2025-12-17 20:00:48] Decode batch, #running-req: 1, #token: 1875, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 20:00:48] INFO:     127.0.0.1:36882 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:50] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:50] INFO:     127.0.0.1:36888 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:50] Prefill batch, #new-seq: 1, #new-token: 1175, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:50] INFO:     127.0.0.1:36892 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:50] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.17, #queue-req: 0, 
[2025-12-17 20:00:53] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:53] INFO:     127.0.0.1:36896 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:53] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 1047, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:53] INFO:     127.0.0.1:36900 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:54] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:55] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.20, #queue-req: 0, 
[2025-12-17 20:00:55] INFO:     127.0.0.1:36904 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:55] Prefill batch, #new-seq: 1, #new-token: 970, #cached-token: 224, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:55] INFO:     127.0.0.1:36908 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:56] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:56] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.52, #queue-req: 0, 
[2025-12-17 20:00:57] INFO:     127.0.0.1:36912 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:57] Prefill batch, #new-seq: 1, #new-token: 1250, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:57] INFO:     127.0.0.1:36916 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:59] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:59] INFO:     127.0.0.1:36920 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:00:59] Prefill batch, #new-seq: 1, #new-token: 1042, #cached-token: 116, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:00:59] Decode batch, #running-req: 1, #token: 1162, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.53, #queue-req: 0, 
[2025-12-17 20:00:59] INFO:     127.0.0.1:36924 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:01] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:01] INFO:     127.0.0.1:36930 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:01] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 916, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:01] Decode batch, #running-req: 1, #token: 945, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.60, #queue-req: 0, 
[2025-12-17 20:01:01] INFO:     127.0.0.1:36934 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:03] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:03] INFO:     127.0.0.1:36940 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:03] Prefill batch, #new-seq: 1, #new-token: 1269, #cached-token: 9, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:03] Decode batch, #running-req: 1, #token: 1291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.45, #queue-req: 0, 
[2025-12-17 20:01:03] INFO:     127.0.0.1:36944 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:05] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:05] INFO:     127.0.0.1:36948 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:05] Prefill batch, #new-seq: 1, #new-token: 1126, #cached-token: 92, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:05] INFO:     127.0.0.1:36952 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:07] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:07] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.15, #queue-req: 0, 
[2025-12-17 20:01:07] INFO:     127.0.0.1:36958 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:07] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 877, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:07] INFO:     127.0.0.1:36962 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:09] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:09] INFO:     127.0.0.1:36966 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:09] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 1025, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:09] Decode batch, #running-req: 1, #token: 1062, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.25, #queue-req: 0, 
[2025-12-17 20:01:09] INFO:     127.0.0.1:36970 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:11] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:11] INFO:     127.0.0.1:36976 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:11] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 855, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:11] INFO:     127.0.0.1:36980 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:13] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:13] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.98, #queue-req: 0, 
[2025-12-17 20:01:13] INFO:     127.0.0.1:36984 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:13] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 1026, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:13] INFO:     127.0.0.1:36988 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:15] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:16] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.42, #queue-req: 0, 
[2025-12-17 20:01:16] INFO:     127.0.0.1:36992 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:16] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 932, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:16] Decode batch, #running-req: 1, #token: 1005, token usage: 0.00, cuda graph: True, gen throughput (token/s): 186.15, #queue-req: 0, 
[2025-12-17 20:01:16] Decode batch, #running-req: 1, #token: 1045, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 20:01:16] Decode batch, #running-req: 1, #token: 1085, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:01:16] Decode batch, #running-req: 1, #token: 1125, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:01:16] Decode batch, #running-req: 1, #token: 1165, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.53, #queue-req: 0, 
[2025-12-17 20:01:17] Decode batch, #running-req: 1, #token: 1205, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.46, #queue-req: 0, 
[2025-12-17 20:01:17] Decode batch, #running-req: 1, #token: 1245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.64, #queue-req: 0, 
[2025-12-17 20:01:17] Decode batch, #running-req: 1, #token: 1285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.43, #queue-req: 0, 
[2025-12-17 20:01:17] Decode batch, #running-req: 1, #token: 1325, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.55, #queue-req: 0, 
[2025-12-17 20:01:17] Decode batch, #running-req: 1, #token: 1365, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 20:01:18] Decode batch, #running-req: 1, #token: 1405, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.62, #queue-req: 0, 
[2025-12-17 20:01:18] Decode batch, #running-req: 1, #token: 1445, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:01:18] Decode batch, #running-req: 1, #token: 1485, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:01:18] Decode batch, #running-req: 1, #token: 1525, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 20:01:18] Decode batch, #running-req: 1, #token: 1565, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:01:18] Decode batch, #running-req: 1, #token: 1605, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 20:01:19] Decode batch, #running-req: 1, #token: 1645, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:01:19] Decode batch, #running-req: 1, #token: 1685, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 20:01:19] Decode batch, #running-req: 1, #token: 1725, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.46, #queue-req: 0, 
[2025-12-17 20:01:19] Decode batch, #running-req: 1, #token: 1765, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.36, #queue-req: 0, 
[2025-12-17 20:01:19] Decode batch, #running-req: 1, #token: 1805, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.55, #queue-req: 0, 
[2025-12-17 20:01:20] Decode batch, #running-req: 1, #token: 1845, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 20:01:20] Decode batch, #running-req: 1, #token: 1885, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.39, #queue-req: 0, 
[2025-12-17 20:01:20] Decode batch, #running-req: 1, #token: 1925, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 20:01:20] Decode batch, #running-req: 1, #token: 1965, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:01:20] INFO:     127.0.0.1:36996 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:22] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:22] INFO:     127.0.0.1:37000 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:22] Prefill batch, #new-seq: 1, #new-token: 1328, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:22] Decode batch, #running-req: 1, #token: 1383, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.49, #queue-req: 0, 
[2025-12-17 20:01:22] INFO:     127.0.0.1:37004 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:24] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:24] INFO:     127.0.0.1:37008 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:24] Prefill batch, #new-seq: 1, #new-token: 1309, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:24] INFO:     127.0.0.1:37012 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:26] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:26] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.10, #queue-req: 0, 
[2025-12-17 20:01:26] INFO:     127.0.0.1:37016 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:26] Prefill batch, #new-seq: 1, #new-token: 27, #cached-token: 856, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:26] INFO:     127.0.0.1:37020 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:28] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:28] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.01, #queue-req: 0, 
[2025-12-17 20:01:28] INFO:     127.0.0.1:37024 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:28] Prefill batch, #new-seq: 1, #new-token: 28, #cached-token: 932, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:29] INFO:     127.0.0.1:37028 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:30] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:30] INFO:     127.0.0.1:37032 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:30] Prefill batch, #new-seq: 1, #new-token: 1197, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:30] INFO:     127.0.0.1:37036 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:32] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:32] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.67, #queue-req: 0, 
[2025-12-17 20:01:32] INFO:     127.0.0.1:37042 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:32] Prefill batch, #new-seq: 1, #new-token: 1253, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:32] INFO:     127.0.0.1:37046 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:34] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:34] INFO:     127.0.0.1:37050 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:34] Prefill batch, #new-seq: 1, #new-token: 1143, #cached-token: 40, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:34] Decode batch, #running-req: 1, #token: 1188, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.32, #queue-req: 0, 
[2025-12-17 20:01:34] INFO:     127.0.0.1:37054 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:36] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:36] INFO:     127.0.0.1:37058 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:36] Prefill batch, #new-seq: 1, #new-token: 1439, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:36] INFO:     127.0.0.1:37062 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:38] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:38] Decode batch, #running-req: 1, #token: 72, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.84, #queue-req: 0, 
[2025-12-17 20:01:38] INFO:     127.0.0.1:37066 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:38] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 933, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:38] INFO:     127.0.0.1:37070 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:40] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:40] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.45, #queue-req: 0, 
[2025-12-17 20:01:40] INFO:     127.0.0.1:37076 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:40] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 933, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:40] INFO:     127.0.0.1:37080 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:42] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:42] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.49, #queue-req: 0, 
[2025-12-17 20:01:42] INFO:     127.0.0.1:37084 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:42] Prefill batch, #new-seq: 1, #new-token: 888, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:42] Decode batch, #running-req: 1, #token: 925, token usage: 0.00, cuda graph: True, gen throughput (token/s): 194.07, #queue-req: 0, 
[2025-12-17 20:01:42] INFO:     127.0.0.1:37088 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:44] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:44] INFO:     127.0.0.1:37092 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:44] Prefill batch, #new-seq: 1, #new-token: 811, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:44] INFO:     127.0.0.1:37096 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:46] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:46] INFO:     127.0.0.1:37100 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:46] Prefill batch, #new-seq: 1, #new-token: 30, #cached-token: 933, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:46] Decode batch, #running-req: 1, #token: 969, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.83, #queue-req: 0, 
[2025-12-17 20:01:46] INFO:     127.0.0.1:37104 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:47] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:48] INFO:     127.0.0.1:37108 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:48] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 810, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:48] INFO:     127.0.0.1:37112 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:49] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:49] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.86, #queue-req: 0, 
[2025-12-17 20:01:49] INFO:     127.0.0.1:37116 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:49] Prefill batch, #new-seq: 1, #new-token: 1059, #cached-token: 106, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:50] INFO:     127.0.0.1:37120 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:51] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:51] INFO:     127.0.0.1:37126 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:51] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 933, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:51] Decode batch, #running-req: 1, #token: 983, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.89, #queue-req: 0, 
[2025-12-17 20:01:51] INFO:     127.0.0.1:37130 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:53] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:53] INFO:     127.0.0.1:37134 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:53] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 1026, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:53] Decode batch, #running-req: 1, #token: 1082, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.35, #queue-req: 0, 
[2025-12-17 20:01:53] INFO:     127.0.0.1:37138 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:55] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:55] INFO:     127.0.0.1:37142 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:55] Prefill batch, #new-seq: 1, #new-token: 1414, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:55] INFO:     127.0.0.1:37146 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:57] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:57] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.70, #queue-req: 0, 
[2025-12-17 20:01:57] INFO:     127.0.0.1:37150 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:57] Prefill batch, #new-seq: 1, #new-token: 1313, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:57] INFO:     127.0.0.1:37154 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:59] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:59] INFO:     127.0.0.1:37158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:01:59] Prefill batch, #new-seq: 1, #new-token: 1325, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:01:59] Decode batch, #running-req: 1, #token: 1364, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.28, #queue-req: 0, 
[2025-12-17 20:01:59] INFO:     127.0.0.1:37162 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:01] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:01] INFO:     127.0.0.1:37166 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:01] Prefill batch, #new-seq: 1, #new-token: 1216, #cached-token: 104, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:01] INFO:     127.0.0.1:37170 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:03] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:03] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.84, #queue-req: 0, 
[2025-12-17 20:02:03] INFO:     127.0.0.1:37174 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:03] Prefill batch, #new-seq: 1, #new-token: 1279, #cached-token: 44, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:03] INFO:     127.0.0.1:37178 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:05] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:05] INFO:     127.0.0.1:37182 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:05] Prefill batch, #new-seq: 1, #new-token: 26, #cached-token: 1084, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:05] Decode batch, #running-req: 1, #token: 1118, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.92, #queue-req: 0, 
[2025-12-17 20:02:05] INFO:     127.0.0.1:37186 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:07] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:07] INFO:     127.0.0.1:37190 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:07] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 932, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:07] INFO:     127.0.0.1:37194 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:08] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:08] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.86, #queue-req: 0, 
[2025-12-17 20:02:08] INFO:     127.0.0.1:37198 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:08] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 1134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:09] INFO:     127.0.0.1:37202 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:10] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:10] INFO:     127.0.0.1:37206 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:10] Prefill batch, #new-seq: 1, #new-token: 1203, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:10] Decode batch, #running-req: 1, #token: 1248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.83, #queue-req: 0, 
[2025-12-17 20:02:10] INFO:     127.0.0.1:37210 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:12] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:12] INFO:     127.0.0.1:37214 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:12] Prefill batch, #new-seq: 1, #new-token: 30, #cached-token: 935, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:12] INFO:     127.0.0.1:37218 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:14] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:14] Decode batch, #running-req: 1, #token: 72, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.81, #queue-req: 0, 
[2025-12-17 20:02:14] INFO:     127.0.0.1:37222 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:14] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 932, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:14] INFO:     127.0.0.1:37226 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:16] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:16] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.51, #queue-req: 0, 
[2025-12-17 20:02:16] INFO:     127.0.0.1:37230 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:16] Prefill batch, #new-seq: 1, #new-token: 1130, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:16] INFO:     127.0.0.1:37234 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:18] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:18] INFO:     127.0.0.1:37238 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:18] Prefill batch, #new-seq: 1, #new-token: 30, #cached-token: 933, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:18] Decode batch, #running-req: 1, #token: 973, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.26, #queue-req: 0, 
[2025-12-17 20:02:18] INFO:     127.0.0.1:37242 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:20] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:20] INFO:     127.0.0.1:37246 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:20] Prefill batch, #new-seq: 1, #new-token: 1063, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:20] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.88, #queue-req: 0, 
[2025-12-17 20:02:20] INFO:     127.0.0.1:37250 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:22] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:22] INFO:     127.0.0.1:37256 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:23] Prefill batch, #new-seq: 1, #new-token: 1211, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:23] INFO:     127.0.0.1:37260 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:24] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:24] INFO:     127.0.0.1:37264 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:24] Prefill batch, #new-seq: 1, #new-token: 1199, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:24] Decode batch, #running-req: 1, #token: 1238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.76, #queue-req: 0, 
[2025-12-17 20:02:25] INFO:     127.0.0.1:37268 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:27] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:27] INFO:     127.0.0.1:37274 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:27] Prefill batch, #new-seq: 1, #new-token: 1103, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:27] Decode batch, #running-req: 1, #token: 1149, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.74, #queue-req: 0, 
[2025-12-17 20:02:27] INFO:     127.0.0.1:37278 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:28] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:28] INFO:     127.0.0.1:37282 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:29] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 934, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:29] INFO:     127.0.0.1:37286 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:30] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:30] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.95, #queue-req: 0, 
[2025-12-17 20:02:30] INFO:     127.0.0.1:37290 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:30] Prefill batch, #new-seq: 1, #new-token: 1334, #cached-token: 99, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:30] INFO:     127.0.0.1:37294 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:32] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:33] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.82, #queue-req: 0, 
[2025-12-17 20:02:33] INFO:     127.0.0.1:37298 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:33] Prefill batch, #new-seq: 1, #new-token: 935, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:33] INFO:     127.0.0.1:37302 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:34] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:35] INFO:     127.0.0.1:37306 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:35] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 855, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:35] Decode batch, #running-req: 1, #token: 902, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.74, #queue-req: 0, 
[2025-12-17 20:02:35] INFO:     127.0.0.1:37310 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:36] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:36] INFO:     127.0.0.1:37316 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:36] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 1058, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:37] INFO:     127.0.0.1:37320 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:37] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.44, #queue-req: 0, 
[2025-12-17 20:02:38] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:38] INFO:     127.0.0.1:37328 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:38] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 932, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:38] INFO:     127.0.0.1:37332 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:40] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:40] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.88, #queue-req: 0, 
[2025-12-17 20:02:40] INFO:     127.0.0.1:37336 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:40] Prefill batch, #new-seq: 1, #new-token: 1070, #cached-token: 161, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:40] INFO:     127.0.0.1:37340 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:42] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:42] INFO:     127.0.0.1:37344 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:42] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 1028, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:42] Decode batch, #running-req: 1, #token: 1070, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.14, #queue-req: 0, 
[2025-12-17 20:02:42] INFO:     127.0.0.1:37348 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:44] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:44] INFO:     127.0.0.1:37352 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:44] Prefill batch, #new-seq: 1, #new-token: 1299, #cached-token: 37, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:44] Decode batch, #running-req: 1, #token: 1343, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.66, #queue-req: 0, 
[2025-12-17 20:02:44] INFO:     127.0.0.1:37356 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:50] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:50] INFO:     127.0.0.1:37360 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:50] Prefill batch, #new-seq: 1, #new-token: 1111, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:50] INFO:     127.0.0.1:37364 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:53] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:53] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 4.57, #queue-req: 0, 
[2025-12-17 20:02:53] INFO:     127.0.0.1:37370 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:53] Prefill batch, #new-seq: 1, #new-token: 845, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:53] INFO:     127.0.0.1:37374 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:55] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:55] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.60, #queue-req: 0, 
[2025-12-17 20:02:55] INFO:     127.0.0.1:37378 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:55] Prefill batch, #new-seq: 1, #new-token: 830, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:55] INFO:     127.0.0.1:37382 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:57] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:57] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.53, #queue-req: 0, 
[2025-12-17 20:02:57] INFO:     127.0.0.1:37386 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:57] Prefill batch, #new-seq: 1, #new-token: 644, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:57] INFO:     127.0.0.1:37390 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:59] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:59] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.56, #queue-req: 0, 
[2025-12-17 20:02:59] INFO:     127.0.0.1:37394 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:02:59] Prefill batch, #new-seq: 1, #new-token: 1180, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:02:59] Decode batch, #running-req: 1, #token: 1219, token usage: 0.00, cuda graph: True, gen throughput (token/s): 189.68, #queue-req: 0, 
[2025-12-17 20:02:59] INFO:     127.0.0.1:37398 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:01] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:01] INFO:     127.0.0.1:37402 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:01] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 827, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:01] INFO:     127.0.0.1:37406 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:03] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:03] INFO:     127.0.0.1:37410 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:03] Prefill batch, #new-seq: 1, #new-token: 1173, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:03] Decode batch, #running-req: 1, #token: 1186, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.82, #queue-req: 0, 
[2025-12-17 20:03:03] INFO:     127.0.0.1:37416 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:04] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:04] INFO:     127.0.0.1:37422 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:04] Prefill batch, #new-seq: 1, #new-token: 1146, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:05] INFO:     127.0.0.1:37426 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:06] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:06] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.81, #queue-req: 0, 
[2025-12-17 20:03:06] INFO:     127.0.0.1:37430 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:06] Prefill batch, #new-seq: 1, #new-token: 1059, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:06] INFO:     127.0.0.1:37434 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:08] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:08] INFO:     127.0.0.1:37438 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:08] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 826, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:08] INFO:     127.0.0.1:37442 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:10] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:10] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.80, #queue-req: 0, 
[2025-12-17 20:03:10] INFO:     127.0.0.1:37446 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:10] Prefill batch, #new-seq: 1, #new-token: 1287, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:10] INFO:     127.0.0.1:37450 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:12] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:12] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.55, #queue-req: 0, 
[2025-12-17 20:03:12] INFO:     127.0.0.1:37456 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:12] Prefill batch, #new-seq: 1, #new-token: 781, #cached-token: 58, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:12] INFO:     127.0.0.1:37460 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:14] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:14] INFO:     127.0.0.1:37464 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:14] Prefill batch, #new-seq: 1, #new-token: 1154, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:14] Decode batch, #running-req: 1, #token: 1199, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.25, #queue-req: 0, 
[2025-12-17 20:03:14] INFO:     127.0.0.1:37468 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:16] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:16] INFO:     127.0.0.1:37472 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:16] Prefill batch, #new-seq: 1, #new-token: 1268, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:16] INFO:     127.0.0.1:37476 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:18] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:18] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.87, #queue-req: 0, 
[2025-12-17 20:03:18] INFO:     127.0.0.1:37480 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:18] Prefill batch, #new-seq: 1, #new-token: 662, #cached-token: 198, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:18] INFO:     127.0.0.1:37484 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:20] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:20] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.54, #queue-req: 0, 
[2025-12-17 20:03:20] INFO:     127.0.0.1:37488 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:20] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 845, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:20] INFO:     127.0.0.1:37492 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:21] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:22] INFO:     127.0.0.1:37496 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:22] Prefill batch, #new-seq: 1, #new-token: 1318, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:22] INFO:     127.0.0.1:37500 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:22] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.21, #queue-req: 0, 
[2025-12-17 20:03:23] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:23] INFO:     127.0.0.1:37506 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:23] Prefill batch, #new-seq: 1, #new-token: 1170, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:23] INFO:     127.0.0.1:37510 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:25] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:25] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.83, #queue-req: 0, 
[2025-12-17 20:03:25] INFO:     127.0.0.1:37518 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:25] Prefill batch, #new-seq: 1, #new-token: 539, #cached-token: 288, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:25] INFO:     127.0.0.1:37522 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:27] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:27] INFO:     127.0.0.1:37526 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:27] Prefill batch, #new-seq: 1, #new-token: 552, #cached-token: 290, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:27] Decode batch, #running-req: 1, #token: 855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.51, #queue-req: 0, 
[2025-12-17 20:03:27] INFO:     127.0.0.1:37530 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:29] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:29] INFO:     127.0.0.1:37534 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:29] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 846, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:29] Decode batch, #running-req: 1, #token: 872, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.16, #queue-req: 0, 
[2025-12-17 20:03:29] INFO:     127.0.0.1:37538 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:31] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:31] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.50, #queue-req: 0, 
[2025-12-17 20:03:31] INFO:     127.0.0.1:37542 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:31] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 848, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:31] INFO:     127.0.0.1:37546 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:33] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:33] INFO:     127.0.0.1:37550 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:33] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 846, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:33] INFO:     127.0.0.1:37558 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:35] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:35] Decode batch, #running-req: 1, #token: 70, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.11, #queue-req: 0, 
[2025-12-17 20:03:35] INFO:     127.0.0.1:37564 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:35] Prefill batch, #new-seq: 1, #new-token: 1017, #cached-token: 403, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:35] Decode batch, #running-req: 1, #token: 1449, token usage: 0.00, cuda graph: True, gen throughput (token/s): 188.60, #queue-req: 0, 
[2025-12-17 20:03:35] INFO:     127.0.0.1:37568 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:37] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:37] INFO:     127.0.0.1:37572 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:37] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 811, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:37] INFO:     127.0.0.1:37576 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:39] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:39] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.74, #queue-req: 0, 
[2025-12-17 20:03:39] INFO:     127.0.0.1:37580 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:39] Prefill batch, #new-seq: 1, #new-token: 1048, #cached-token: 9, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:39] INFO:     127.0.0.1:37584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:41] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:41] INFO:     127.0.0.1:37588 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:41] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 847, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:41] Decode batch, #running-req: 1, #token: 870, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.20, #queue-req: 0, 
[2025-12-17 20:03:41] INFO:     127.0.0.1:37592 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:43] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:43] INFO:     127.0.0.1:37596 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:43] Prefill batch, #new-seq: 1, #new-token: 1371, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:43] INFO:     127.0.0.1:37600 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:45] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:45] INFO:     127.0.0.1:37604 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:45] Prefill batch, #new-seq: 1, #new-token: 1005, #cached-token: 118, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:45] Decode batch, #running-req: 1, #token: 1125, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.44, #queue-req: 0, 
[2025-12-17 20:03:45] INFO:     127.0.0.1:37608 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:47] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:47] INFO:     127.0.0.1:37612 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:47] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 827, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:47] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.10, #queue-req: 0, 
[2025-12-17 20:03:47] INFO:     127.0.0.1:37616 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:49] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:49] INFO:     127.0.0.1:37620 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:49] Prefill batch, #new-seq: 1, #new-token: 1066, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:49] INFO:     127.0.0.1:37624 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:51] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:51] INFO:     127.0.0.1:37628 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:51] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 1045, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:51] Decode batch, #running-req: 1, #token: 1067, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.86, #queue-req: 0, 
[2025-12-17 20:03:51] INFO:     127.0.0.1:37632 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:53] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:53] INFO:     127.0.0.1:37636 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:53] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 847, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:53] INFO:     127.0.0.1:37640 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:55] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:55] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.78, #queue-req: 0, 
[2025-12-17 20:03:55] INFO:     127.0.0.1:37644 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:55] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 847, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:55] INFO:     127.0.0.1:37648 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:57] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:57] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.81, #queue-req: 0, 
[2025-12-17 20:03:57] INFO:     127.0.0.1:37656 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:03:57] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 832, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:03:57] Decode batch, #running-req: 1, #token: 882, token usage: 0.00, cuda graph: True, gen throughput (token/s): 192.66, #queue-req: 0, 
[2025-12-17 20:03:57] Decode batch, #running-req: 1, #token: 922, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.33, #queue-req: 0, 
[2025-12-17 20:03:57] Decode batch, #running-req: 1, #token: 962, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.50, #queue-req: 0, 
[2025-12-17 20:03:57] Decode batch, #running-req: 1, #token: 1002, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.24, #queue-req: 0, 
[2025-12-17 20:03:58] Decode batch, #running-req: 1, #token: 1042, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.09, #queue-req: 0, 
[2025-12-17 20:03:58] Decode batch, #running-req: 1, #token: 1082, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:03:58] Decode batch, #running-req: 1, #token: 1122, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 20:03:58] Decode batch, #running-req: 1, #token: 1162, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:03:58] Decode batch, #running-req: 1, #token: 1202, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 20:03:58] Decode batch, #running-req: 1, #token: 1242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:03:59] Decode batch, #running-req: 1, #token: 1282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 20:03:59] Decode batch, #running-req: 1, #token: 1322, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 20:03:59] Decode batch, #running-req: 1, #token: 1362, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:03:59] Decode batch, #running-req: 1, #token: 1402, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.40, #queue-req: 0, 
[2025-12-17 20:03:59] Decode batch, #running-req: 1, #token: 1442, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 20:04:00] Decode batch, #running-req: 1, #token: 1482, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:04:00] Decode batch, #running-req: 1, #token: 1522, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:04:00] Decode batch, #running-req: 1, #token: 1562, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.43, #queue-req: 0, 
[2025-12-17 20:04:00] Decode batch, #running-req: 1, #token: 1602, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.46, #queue-req: 0, 
[2025-12-17 20:04:00] Decode batch, #running-req: 1, #token: 1642, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.45, #queue-req: 0, 
[2025-12-17 20:04:00] Decode batch, #running-req: 1, #token: 1682, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.27, #queue-req: 0, 
[2025-12-17 20:04:01] Decode batch, #running-req: 1, #token: 1722, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 20:04:01] Decode batch, #running-req: 1, #token: 1762, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.31, #queue-req: 0, 
[2025-12-17 20:04:01] Decode batch, #running-req: 1, #token: 1802, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.40, #queue-req: 0, 
[2025-12-17 20:04:01] Decode batch, #running-req: 1, #token: 1842, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.35, #queue-req: 0, 
[2025-12-17 20:04:01] INFO:     127.0.0.1:37660 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:03] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:03] INFO:     127.0.0.1:37664 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:03] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 848, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:03] INFO:     127.0.0.1:37668 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:05] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:05] Decode batch, #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.15, #queue-req: 0, 
[2025-12-17 20:04:05] INFO:     127.0.0.1:37672 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:05] Prefill batch, #new-seq: 1, #new-token: 925, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:05] INFO:     127.0.0.1:37676 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:07] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:07] INFO:     127.0.0.1:37680 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:07] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 847, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:07] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.13, #queue-req: 0, 
[2025-12-17 20:04:07] INFO:     127.0.0.1:37684 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:09] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:09] INFO:     127.0.0.1:37688 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:09] Prefill batch, #new-seq: 1, #new-token: 1137, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:09] INFO:     127.0.0.1:37692 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:10] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:10] INFO:     127.0.0.1:37696 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:10] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 1046, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:11] Decode batch, #running-req: 1, #token: 1065, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.16, #queue-req: 0, 
[2025-12-17 20:04:11] INFO:     127.0.0.1:37700 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:12] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:12] INFO:     127.0.0.1:37704 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:12] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 827, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:12] INFO:     127.0.0.1:37708 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:14] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:14] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.15, #queue-req: 0, 
[2025-12-17 20:04:14] INFO:     127.0.0.1:37714 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:15] Prefill batch, #new-seq: 1, #new-token: 1304, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:15] INFO:     127.0.0.1:37718 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:16] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:16] Decode batch, #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.47, #queue-req: 0, 
[2025-12-17 20:04:16] INFO:     127.0.0.1:37722 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:16] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 826, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:17] INFO:     127.0.0.1:37726 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:18] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:18] INFO:     127.0.0.1:37730 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:18] Prefill batch, #new-seq: 1, #new-token: 1383, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:18] Decode batch, #running-req: 1, #token: 1422, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.44, #queue-req: 0, 
[2025-12-17 20:04:18] INFO:     127.0.0.1:37734 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:20] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:20] INFO:     127.0.0.1:37738 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:20] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 827, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:20] Decode batch, #running-req: 1, #token: 855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.82, #queue-req: 0, 
[2025-12-17 20:04:20] INFO:     127.0.0.1:37742 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:22] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:22] INFO:     127.0.0.1:37746 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:22] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 830, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:22] INFO:     127.0.0.1:37750 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:24] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:24] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.79, #queue-req: 0, 
[2025-12-17 20:04:24] INFO:     127.0.0.1:37754 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:24] Prefill batch, #new-seq: 1, #new-token: 1412, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:24] INFO:     127.0.0.1:37758 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:26] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:26] INFO:     127.0.0.1:37762 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:26] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 827, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:26] Decode batch, #running-req: 1, #token: 856, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.65, #queue-req: 0, 
[2025-12-17 20:04:26] INFO:     127.0.0.1:37766 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:28] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:28] INFO:     127.0.0.1:37772 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:28] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 829, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:28] Decode batch, #running-req: 1, #token: 846, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.74, #queue-req: 0, 
[2025-12-17 20:04:28] INFO:     127.0.0.1:37776 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:30] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:30] INFO:     127.0.0.1:37780 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:30] Prefill batch, #new-seq: 1, #new-token: 1102, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:30] INFO:     127.0.0.1:37784 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:32] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:32] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.54, #queue-req: 0, 
[2025-12-17 20:04:32] INFO:     127.0.0.1:37788 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:32] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 828, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:32] INFO:     127.0.0.1:37792 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:34] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:34] INFO:     127.0.0.1:37796 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:34] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.69, #queue-req: 0, 
[2025-12-17 20:04:34] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 827, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:34] INFO:     127.0.0.1:37800 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:35] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:36] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.73, #queue-req: 0, 
[2025-12-17 20:04:36] INFO:     127.0.0.1:37804 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:36] Prefill batch, #new-seq: 1, #new-token: 1119, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:36] Decode batch, #running-req: 1, #token: 1165, token usage: 0.00, cuda graph: True, gen throughput (token/s): 189.83, #queue-req: 0, 
[2025-12-17 20:04:36] Decode batch, #running-req: 1, #token: 1205, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:04:36] Decode batch, #running-req: 1, #token: 1245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:04:36] Decode batch, #running-req: 1, #token: 1285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:04:36] Decode batch, #running-req: 1, #token: 1325, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:04:37] Decode batch, #running-req: 1, #token: 1365, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.62, #queue-req: 0, 
[2025-12-17 20:04:37] Decode batch, #running-req: 1, #token: 1405, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.42, #queue-req: 0, 
[2025-12-17 20:04:37] Decode batch, #running-req: 1, #token: 1445, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.55, #queue-req: 0, 
[2025-12-17 20:04:37] Decode batch, #running-req: 1, #token: 1485, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:04:37] Decode batch, #running-req: 1, #token: 1525, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 20:04:38] Decode batch, #running-req: 1, #token: 1565, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 20:04:38] Decode batch, #running-req: 1, #token: 1605, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.35, #queue-req: 0, 
[2025-12-17 20:04:38] Decode batch, #running-req: 1, #token: 1645, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 20:04:38] Decode batch, #running-req: 1, #token: 1685, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.62, #queue-req: 0, 
[2025-12-17 20:04:38] Decode batch, #running-req: 1, #token: 1725, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 20:04:38] Decode batch, #running-req: 1, #token: 1765, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.40, #queue-req: 0, 
[2025-12-17 20:04:39] Decode batch, #running-req: 1, #token: 1805, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.32, #queue-req: 0, 
[2025-12-17 20:04:39] Decode batch, #running-req: 1, #token: 1845, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 20:04:39] Decode batch, #running-req: 1, #token: 1885, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 20:04:39] Decode batch, #running-req: 1, #token: 1925, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.43, #queue-req: 0, 
[2025-12-17 20:04:39] Decode batch, #running-req: 1, #token: 1965, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 20:04:40] Decode batch, #running-req: 1, #token: 2005, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.42, #queue-req: 0, 
[2025-12-17 20:04:40] Decode batch, #running-req: 1, #token: 2045, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 20:04:40] Decode batch, #running-req: 1, #token: 2085, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.16, #queue-req: 0, 
[2025-12-17 20:04:40] Decode batch, #running-req: 1, #token: 2125, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.88, #queue-req: 0, 
[2025-12-17 20:04:40] INFO:     127.0.0.1:37808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:42] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:42] INFO:     127.0.0.1:37818 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:42] Prefill batch, #new-seq: 1, #new-token: 1100, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:42] Decode batch, #running-req: 1, #token: 1136, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.88, #queue-req: 0, 
[2025-12-17 20:04:42] INFO:     127.0.0.1:37822 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:44] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:44] INFO:     127.0.0.1:37828 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:44] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 1046, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:44] Decode batch, #running-req: 1, #token: 1067, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.01, #queue-req: 0, 
[2025-12-17 20:04:44] INFO:     127.0.0.1:37832 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:46] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:46] INFO:     127.0.0.1:37836 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:46] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 829, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:46] INFO:     127.0.0.1:37840 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:48] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:48] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.76, #queue-req: 0, 
[2025-12-17 20:04:48] INFO:     127.0.0.1:37844 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:48] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 829, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:48] INFO:     127.0.0.1:37848 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:50] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:50] INFO:     127.0.0.1:37852 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:50] Prefill batch, #new-seq: 1, #new-token: 1297, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:50] Decode batch, #running-req: 1, #token: 1336, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.51, #queue-req: 0, 
[2025-12-17 20:04:50] INFO:     127.0.0.1:37856 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:50] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.52, #queue-req: 0, 
[2025-12-17 20:04:52] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:52] INFO:     127.0.0.1:37860 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:52] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 826, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:53] Decode batch, #running-req: 1, #token: 866, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.71, #queue-req: 0, 
[2025-12-17 20:04:53] INFO:     127.0.0.1:37864 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:54] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:54] INFO:     127.0.0.1:37870 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:54] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 1045, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:54] Decode batch, #running-req: 1, #token: 1079, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.90, #queue-req: 0, 
[2025-12-17 20:04:55] INFO:     127.0.0.1:37874 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:56] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:57] INFO:     127.0.0.1:37878 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:57] Prefill batch, #new-seq: 1, #new-token: 1182, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:57] Decode batch, #running-req: 1, #token: 1223, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.44, #queue-req: 0, 
[2025-12-17 20:04:57] INFO:     127.0.0.1:37882 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:58] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:58] INFO:     127.0.0.1:37886 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:04:58] Prefill batch, #new-seq: 1, #new-token: 1303, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:04:58] INFO:     127.0.0.1:37890 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:00] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:00] INFO:     127.0.0.1:37894 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:00] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.92, #queue-req: 0, 
[2025-12-17 20:05:00] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 826, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:00] INFO:     127.0.0.1:37898 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:02] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:02] INFO:     127.0.0.1:37904 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:02] Prefill batch, #new-seq: 1, #new-token: 25, #cached-token: 827, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:02] Decode batch, #running-req: 1, #token: 866, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.48, #queue-req: 0, 
[2025-12-17 20:05:02] INFO:     127.0.0.1:37908 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:04] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:04] INFO:     127.0.0.1:37912 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:04] Prefill batch, #new-seq: 1, #new-token: 1453, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:04] INFO:     127.0.0.1:37916 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:06] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:06] INFO:     127.0.0.1:37922 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:06] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.03, #queue-req: 0, 
[2025-12-17 20:05:06] Prefill batch, #new-seq: 1, #new-token: 982, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:06] INFO:     127.0.0.1:37926 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:08] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:08] INFO:     127.0.0.1:37930 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:08] Prefill batch, #new-seq: 1, #new-token: 1124, #cached-token: 138, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:08] INFO:     127.0.0.1:37934 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:10] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:10] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.92, #queue-req: 0, 
[2025-12-17 20:05:10] INFO:     127.0.0.1:37938 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:10] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 1046, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:10] INFO:     127.0.0.1:37942 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:11] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:11] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.65, #queue-req: 0, 
[2025-12-17 20:05:12] INFO:     127.0.0.1:37946 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:12] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 828, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:12] INFO:     127.0.0.1:37950 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:13] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:13] INFO:     127.0.0.1:37956 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:13] Prefill batch, #new-seq: 1, #new-token: 997, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:13] Decode batch, #running-req: 1, #token: 1040, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.09, #queue-req: 0, 
[2025-12-17 20:05:13] INFO:     127.0.0.1:37960 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:15] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:15] INFO:     127.0.0.1:37964 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:15] Prefill batch, #new-seq: 1, #new-token: 8, #cached-token: 829, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:15] INFO:     127.0.0.1:37968 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:17] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:17] INFO:     127.0.0.1:37972 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:17] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.68, #queue-req: 0, 
[2025-12-17 20:05:17] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 811, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:17] INFO:     127.0.0.1:37976 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:19] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:19] INFO:     127.0.0.1:37982 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:19] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 813, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:19] Decode batch, #running-req: 1, #token: 844, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.46, #queue-req: 0, 
[2025-12-17 20:05:19] INFO:     127.0.0.1:37986 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:21] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:21] INFO:     127.0.0.1:37990 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:21] Prefill batch, #new-seq: 1, #new-token: 461, #cached-token: 366, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:21] INFO:     127.0.0.1:37994 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:23] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:23] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.33, #queue-req: 0, 
[2025-12-17 20:05:23] INFO:     127.0.0.1:38000 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:23] Prefill batch, #new-seq: 1, #new-token: 1020, #cached-token: 141, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:23] INFO:     127.0.0.1:38004 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:25] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:25] INFO:     127.0.0.1:38008 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:25] Prefill batch, #new-seq: 1, #new-token: 1136, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:25] Decode batch, #running-req: 1, #token: 1181, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.26, #queue-req: 0, 
[2025-12-17 20:05:25] INFO:     127.0.0.1:38012 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:27] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:27] INFO:     127.0.0.1:38018 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:27] Prefill batch, #new-seq: 1, #new-token: 1002, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:27] INFO:     127.0.0.1:38022 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:29] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:29] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.02, #queue-req: 0, 
[2025-12-17 20:05:29] INFO:     127.0.0.1:38026 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:29] Prefill batch, #new-seq: 1, #new-token: 1079, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:29] INFO:     127.0.0.1:38030 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:31] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:31] INFO:     127.0.0.1:38034 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:31] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.99, #queue-req: 0, 
[2025-12-17 20:05:31] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 813, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:31] INFO:     127.0.0.1:38038 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:33] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:33] INFO:     127.0.0.1:38042 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:33] Prefill batch, #new-seq: 1, #new-token: 1097, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:33] INFO:     127.0.0.1:38046 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:33] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.74, #queue-req: 0, 
[2025-12-17 20:05:35] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:35] INFO:     127.0.0.1:38050 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:35] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 827, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:35] INFO:     127.0.0.1:38054 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:37] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:37] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.80, #queue-req: 0, 
[2025-12-17 20:05:37] INFO:     127.0.0.1:38058 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:37] Prefill batch, #new-seq: 1, #new-token: 1038, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:37] INFO:     127.0.0.1:38062 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:39] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:39] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.65, #queue-req: 0, 
[2025-12-17 20:05:39] INFO:     127.0.0.1:38066 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:39] Prefill batch, #new-seq: 1, #new-token: 1205, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:39] INFO:     127.0.0.1:38070 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:41] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:41] INFO:     127.0.0.1:38076 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:41] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 805, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:41] Decode batch, #running-req: 1, #token: 853, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.38, #queue-req: 0, 
[2025-12-17 20:05:41] INFO:     127.0.0.1:38080 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:42] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:43] INFO:     127.0.0.1:38084 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:43] Prefill batch, #new-seq: 1, #new-token: 1128, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:43] INFO:     127.0.0.1:38088 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:44] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:44] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.00, #queue-req: 0, 
[2025-12-17 20:05:44] INFO:     127.0.0.1:38092 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:44] Prefill batch, #new-seq: 1, #new-token: 1471, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:44] INFO:     127.0.0.1:38096 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:46] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:46] INFO:     127.0.0.1:38100 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:46] Prefill batch, #new-seq: 1, #new-token: 1490, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:46] INFO:     127.0.0.1:38104 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:48] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:48] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.81, #queue-req: 0, 
[2025-12-17 20:05:48] INFO:     127.0.0.1:38108 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:48] Prefill batch, #new-seq: 1, #new-token: 1108, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:48] INFO:     127.0.0.1:38112 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:50] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:50] INFO:     127.0.0.1:38118 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:50] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 806, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:50] Decode batch, #running-req: 1, #token: 844, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.16, #queue-req: 0, 
[2025-12-17 20:05:50] INFO:     127.0.0.1:38122 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:52] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:52] INFO:     127.0.0.1:38126 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:52] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 1024, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:52] INFO:     127.0.0.1:38130 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:54] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:54] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.44, #queue-req: 0, 
[2025-12-17 20:05:54] INFO:     127.0.0.1:38134 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:54] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 806, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:54] INFO:     127.0.0.1:38138 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:56] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:56] INFO:     127.0.0.1:38144 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:56] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 805, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:56] Decode batch, #running-req: 1, #token: 842, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.22, #queue-req: 0, 
[2025-12-17 20:05:56] INFO:     127.0.0.1:38148 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:58] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:58] INFO:     127.0.0.1:38152 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:05:58] Prefill batch, #new-seq: 1, #new-token: 1151, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:05:58] INFO:     127.0.0.1:38156 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:00] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:00] Decode batch, #running-req: 1, #token: 72, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.84, #queue-req: 0, 
[2025-12-17 20:06:00] INFO:     127.0.0.1:38160 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:00] Prefill batch, #new-seq: 1, #new-token: 31, #cached-token: 805, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:00] INFO:     127.0.0.1:38164 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:02] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:02] INFO:     127.0.0.1:38168 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:02] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.63, #queue-req: 0, 
[2025-12-17 20:06:02] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 805, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:02] INFO:     127.0.0.1:38172 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:04] Prefill batch, #new-seq: 1, #new-token: 1, #cached-token: 68, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:04] INFO:     127.0.0.1:38176 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:04] Prefill batch, #new-seq: 1, #new-token: 1347, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:04] Decode batch, #running-req: 1, #token: 1389, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.47, #queue-req: 0, 
[2025-12-17 20:06:04] INFO:     127.0.0.1:38180 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:06] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:06] INFO:     127.0.0.1:38188 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:06] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 806, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:06] INFO:     127.0.0.1:38192 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:07] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:07] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.04, #queue-req: 0, 
[2025-12-17 20:06:07] INFO:     127.0.0.1:38196 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:07] Prefill batch, #new-seq: 1, #new-token: 1155, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:08] INFO:     127.0.0.1:38200 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:09] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:09] INFO:     127.0.0.1:38204 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:09] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 805, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:09] Decode batch, #running-req: 1, #token: 847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.28, #queue-req: 0, 
[2025-12-17 20:06:09] INFO:     127.0.0.1:38208 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:11] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:12] INFO:     127.0.0.1:38212 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:12] Prefill batch, #new-seq: 1, #new-token: 1101, #cached-token: 39, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:12] INFO:     127.0.0.1:38216 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:13] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:13] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.21, #queue-req: 0, 
[2025-12-17 20:06:13] INFO:     127.0.0.1:38220 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:13] Prefill batch, #new-seq: 1, #new-token: 1085, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:13] INFO:     127.0.0.1:38224 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:15] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:15] INFO:     127.0.0.1:38230 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:15] Prefill batch, #new-seq: 1, #new-token: 30, #cached-token: 808, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:15] Decode batch, #running-req: 1, #token: 844, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.28, #queue-req: 0, 
[2025-12-17 20:06:15] INFO:     127.0.0.1:38234 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:17] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:17] INFO:     127.0.0.1:38238 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:17] Prefill batch, #new-seq: 1, #new-token: 28, #cached-token: 808, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:17] INFO:     127.0.0.1:38242 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:19] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:19] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.94, #queue-req: 0, 
[2025-12-17 20:06:19] INFO:     127.0.0.1:38246 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:19] Prefill batch, #new-seq: 1, #new-token: 30, #cached-token: 806, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:19] INFO:     127.0.0.1:38250 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:21] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:21] INFO:     127.0.0.1:38254 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:21] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 806, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:21] Decode batch, #running-req: 1, #token: 870, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.65, #queue-req: 0, 
[2025-12-17 20:06:21] INFO:     127.0.0.1:38258 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:28] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:28] INFO:     127.0.0.1:38262 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:28] Prefill batch, #new-seq: 1, #new-token: 889, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:28] INFO:     127.0.0.1:38266 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:29] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:29] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 4.83, #queue-req: 0, 
[2025-12-17 20:06:29] INFO:     127.0.0.1:38270 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:30] Prefill batch, #new-seq: 1, #new-token: 846, #cached-token: 81, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:30] INFO:     127.0.0.1:38274 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:31] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:31] INFO:     127.0.0.1:38278 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:31] Prefill batch, #new-seq: 1, #new-token: 1169, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:31] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.29, #queue-req: 0, 
[2025-12-17 20:06:31] INFO:     127.0.0.1:38282 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:33] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:33] INFO:     127.0.0.1:38286 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:33] Prefill batch, #new-seq: 1, #new-token: 866, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:33] INFO:     127.0.0.1:38290 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:35] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:35] INFO:     127.0.0.1:38294 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:35] Prefill batch, #new-seq: 1, #new-token: 1206, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:35] Decode batch, #running-req: 1, #token: 1222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.97, #queue-req: 0, 
[2025-12-17 20:06:36] INFO:     127.0.0.1:38298 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:37] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:37] INFO:     127.0.0.1:38304 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:37] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 1208, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:37] INFO:     127.0.0.1:38308 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:39] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:39] Decode batch, #running-req: 1, #token: 72, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.91, #queue-req: 0, 
[2025-12-17 20:06:39] INFO:     127.0.0.1:38312 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:39] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 863, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:39] INFO:     127.0.0.1:38316 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:41] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:41] INFO:     127.0.0.1:38320 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:41] Prefill batch, #new-seq: 1, #new-token: 817, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:41] Decode batch, #running-req: 1, #token: 897, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.82, #queue-req: 0, 
[2025-12-17 20:06:41] INFO:     127.0.0.1:38324 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:43] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:43] INFO:     127.0.0.1:38328 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:43] Prefill batch, #new-seq: 1, #new-token: 815, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:43] Decode batch, #running-req: 1, #token: 915, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.81, #queue-req: 0, 
[2025-12-17 20:06:43] INFO:     127.0.0.1:38332 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:45] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:45] INFO:     127.0.0.1:38340 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:45] Prefill batch, #new-seq: 1, #new-token: 23, #cached-token: 863, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:45] INFO:     127.0.0.1:38344 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:47] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:47] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.13, #queue-req: 0, 
[2025-12-17 20:06:47] INFO:     127.0.0.1:38348 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:47] Prefill batch, #new-seq: 1, #new-token: 1202, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:47] INFO:     127.0.0.1:38352 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:48] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:49] INFO:     127.0.0.1:38356 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:49] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:49] Decode batch, #running-req: 1, #token: 903, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.47, #queue-req: 0, 
[2025-12-17 20:06:49] INFO:     127.0.0.1:38360 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:51] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:51] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.26, #queue-req: 0, 
[2025-12-17 20:06:51] INFO:     127.0.0.1:38366 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:51] Prefill batch, #new-seq: 1, #new-token: 831, #cached-token: 79, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:51] INFO:     127.0.0.1:38370 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:53] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:53] INFO:     127.0.0.1:38376 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:53] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 854, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:53] INFO:     127.0.0.1:38380 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:55] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:55] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.19, #queue-req: 0, 
[2025-12-17 20:06:55] INFO:     127.0.0.1:38384 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:55] Prefill batch, #new-seq: 1, #new-token: 1182, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:55] Decode batch, #running-req: 1, #token: 1226, token usage: 0.00, cuda graph: True, gen throughput (token/s): 169.92, #queue-req: 0, 
[2025-12-17 20:06:55] INFO:     127.0.0.1:38388 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:57] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:57] INFO:     127.0.0.1:38392 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:57] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:57] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.78, #queue-req: 0, 
[2025-12-17 20:06:57] INFO:     127.0.0.1:38396 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:59] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:59] INFO:     127.0.0.1:38406 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:06:59] Prefill batch, #new-seq: 1, #new-token: 1225, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:06:59] INFO:     127.0.0.1:38410 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:01] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:01] INFO:     127.0.0.1:38414 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:01] Prefill batch, #new-seq: 1, #new-token: 8, #cached-token: 886, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:01] Decode batch, #running-req: 1, #token: 902, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.67, #queue-req: 0, 
[2025-12-17 20:07:01] INFO:     127.0.0.1:38418 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:03] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:03] INFO:     127.0.0.1:38422 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:03] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 880, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:03] INFO:     127.0.0.1:38426 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:05] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:05] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.03, #queue-req: 0, 
[2025-12-17 20:07:05] INFO:     127.0.0.1:38430 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:05] Prefill batch, #new-seq: 1, #new-token: 1261, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:05] INFO:     127.0.0.1:38434 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:07] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:07] INFO:     127.0.0.1:38438 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:07] Prefill batch, #new-seq: 1, #new-token: 1417, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:07] Decode batch, #running-req: 1, #token: 1436, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.37, #queue-req: 0, 
[2025-12-17 20:07:07] INFO:     127.0.0.1:38442 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:08] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:08] INFO:     127.0.0.1:38446 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:08] Prefill batch, #new-seq: 1, #new-token: 21, #cached-token: 899, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:09] Decode batch, #running-req: 1, #token: 942, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.62, #queue-req: 0, 
[2025-12-17 20:07:09] INFO:     127.0.0.1:38450 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:11] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:11] INFO:     127.0.0.1:38456 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:11] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 1209, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:11] INFO:     127.0.0.1:38460 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:13] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:13] Decode batch, #running-req: 1, #token: 71, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.07, #queue-req: 0, 
[2025-12-17 20:07:13] INFO:     127.0.0.1:38464 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:13] Prefill batch, #new-seq: 1, #new-token: 1206, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:13] INFO:     127.0.0.1:38470 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:15] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:15] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.49, #queue-req: 0, 
[2025-12-17 20:07:15] INFO:     127.0.0.1:38474 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:15] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 900, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:15] Decode batch, #running-req: 1, #token: 952, token usage: 0.00, cuda graph: True, gen throughput (token/s): 195.81, #queue-req: 0, 
[2025-12-17 20:07:15] Decode batch, #running-req: 1, #token: 992, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.40, #queue-req: 0, 
[2025-12-17 20:07:16] Decode batch, #running-req: 1, #token: 1032, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.27, #queue-req: 0, 
[2025-12-17 20:07:16] Decode batch, #running-req: 1, #token: 1072, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:07:16] Decode batch, #running-req: 1, #token: 1112, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:07:16] Decode batch, #running-req: 1, #token: 1152, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:07:16] Decode batch, #running-req: 1, #token: 1192, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 20:07:16] Decode batch, #running-req: 1, #token: 1232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.49, #queue-req: 0, 
[2025-12-17 20:07:17] Decode batch, #running-req: 1, #token: 1272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.63, #queue-req: 0, 
[2025-12-17 20:07:17] Decode batch, #running-req: 1, #token: 1312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 20:07:17] Decode batch, #running-req: 1, #token: 1352, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:07:17] Decode batch, #running-req: 1, #token: 1392, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:07:17] Decode batch, #running-req: 1, #token: 1432, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 20:07:18] Decode batch, #running-req: 1, #token: 1472, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:07:18] Decode batch, #running-req: 1, #token: 1512, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:07:18] Decode batch, #running-req: 1, #token: 1552, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:07:18] Decode batch, #running-req: 1, #token: 1592, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.45, #queue-req: 0, 
[2025-12-17 20:07:18] Decode batch, #running-req: 1, #token: 1632, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.45, #queue-req: 0, 
[2025-12-17 20:07:18] Decode batch, #running-req: 1, #token: 1672, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.27, #queue-req: 0, 
[2025-12-17 20:07:19] Decode batch, #running-req: 1, #token: 1712, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.36, #queue-req: 0, 
[2025-12-17 20:07:19] Decode batch, #running-req: 1, #token: 1752, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:07:19] Decode batch, #running-req: 1, #token: 1792, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.43, #queue-req: 0, 
[2025-12-17 20:07:19] Decode batch, #running-req: 1, #token: 1832, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.42, #queue-req: 0, 
[2025-12-17 20:07:19] Decode batch, #running-req: 1, #token: 1872, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 20:07:19] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.07, #queue-req: 0, 
[2025-12-17 20:07:20] INFO:     127.0.0.1:38478 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:21] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:21] INFO:     127.0.0.1:38484 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:21] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:21] INFO:     127.0.0.1:38488 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:23] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:23] INFO:     127.0.0.1:38492 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:23] Prefill batch, #new-seq: 1, #new-token: 1085, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:23] Decode batch, #running-req: 1, #token: 1116, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.86, #queue-req: 0, 
[2025-12-17 20:07:23] INFO:     127.0.0.1:38496 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:25] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:25] INFO:     127.0.0.1:38500 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:25] Prefill batch, #new-seq: 1, #new-token: 1242, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:25] INFO:     127.0.0.1:38504 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:27] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:27] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.74, #queue-req: 0, 
[2025-12-17 20:07:27] INFO:     127.0.0.1:38508 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:27] Prefill batch, #new-seq: 1, #new-token: 1127, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:27] INFO:     127.0.0.1:38512 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:29] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:29] INFO:     127.0.0.1:38516 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:29] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:29] Decode batch, #running-req: 1, #token: 900, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.34, #queue-req: 0, 
[2025-12-17 20:07:29] INFO:     127.0.0.1:38520 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:31] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:31] INFO:     127.0.0.1:38526 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:31] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 899, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:31] Decode batch, #running-req: 1, #token: 922, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.95, #queue-req: 0, 
[2025-12-17 20:07:31] INFO:     127.0.0.1:38530 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:32] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:33] INFO:     127.0.0.1:38536 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:33] Prefill batch, #new-seq: 1, #new-token: 1209, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:33] INFO:     127.0.0.1:38540 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:34] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:34] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.95, #queue-req: 0, 
[2025-12-17 20:07:34] INFO:     127.0.0.1:38546 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:34] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 899, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:35] INFO:     127.0.0.1:38550 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:36] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:36] INFO:     127.0.0.1:38554 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:36] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:36] Decode batch, #running-req: 1, #token: 898, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.57, #queue-req: 0, 
[2025-12-17 20:07:36] INFO:     127.0.0.1:38558 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:38] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:38] INFO:     127.0.0.1:38562 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:38] Prefill batch, #new-seq: 1, #new-token: 8, #cached-token: 901, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:39] INFO:     127.0.0.1:38566 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:40] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:40] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.17, #queue-req: 0, 
[2025-12-17 20:07:40] INFO:     127.0.0.1:38570 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:40] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:40] INFO:     127.0.0.1:38574 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:42] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:42] INFO:     127.0.0.1:38578 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:42] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:42] Decode batch, #running-req: 1, #token: 899, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.16, #queue-req: 0, 
[2025-12-17 20:07:42] INFO:     127.0.0.1:38582 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:44] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:45] INFO:     127.0.0.1:38586 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:45] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 882, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:45] INFO:     127.0.0.1:38590 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:46] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:46] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.66, #queue-req: 0, 
[2025-12-17 20:07:46] INFO:     127.0.0.1:38596 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:46] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 901, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:47] INFO:     127.0.0.1:38600 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:48] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:48] INFO:     127.0.0.1:38604 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:48] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 882, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:48] Decode batch, #running-req: 1, #token: 911, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.39, #queue-req: 0, 
[2025-12-17 20:07:48] INFO:     127.0.0.1:38608 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:50] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:50] INFO:     127.0.0.1:38612 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:50] Prefill batch, #new-seq: 1, #new-token: 1138, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:50] INFO:     127.0.0.1:38616 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:53] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:53] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.05, #queue-req: 0, 
[2025-12-17 20:07:53] INFO:     127.0.0.1:38620 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:53] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 882, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:53] INFO:     127.0.0.1:38624 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:55] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:55] INFO:     127.0.0.1:38628 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:55] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:55] INFO:     127.0.0.1:38632 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:56] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:57] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.85, #queue-req: 0, 
[2025-12-17 20:07:57] INFO:     127.0.0.1:38636 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:57] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 899, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:57] INFO:     127.0.0.1:38640 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:58] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:58] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.69, #queue-req: 0, 
[2025-12-17 20:07:58] INFO:     127.0.0.1:38644 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:07:58] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:07:59] INFO:     127.0.0.1:38648 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:00] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:00] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.36, #queue-req: 0, 
[2025-12-17 20:08:00] INFO:     127.0.0.1:38652 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:00] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 1162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:00] INFO:     127.0.0.1:38656 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:02] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:02] INFO:     127.0.0.1:38660 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:03] Prefill batch, #new-seq: 1, #new-token: 1248, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:03] INFO:     127.0.0.1:38664 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:04] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:04] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.08, #queue-req: 0, 
[2025-12-17 20:08:04] INFO:     127.0.0.1:38668 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:04] Prefill batch, #new-seq: 1, #new-token: 1225, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:05] INFO:     127.0.0.1:38672 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:06] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:06] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.64, #queue-req: 0, 
[2025-12-17 20:08:06] INFO:     127.0.0.1:38676 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:06] Prefill batch, #new-seq: 1, #new-token: 1288, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:06] INFO:     127.0.0.1:38680 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:08] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:08] INFO:     127.0.0.1:38684 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:08] Prefill batch, #new-seq: 1, #new-token: 1339, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:08] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.32, #queue-req: 0, 
[2025-12-17 20:08:08] INFO:     127.0.0.1:38688 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:10] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:10] INFO:     127.0.0.1:38696 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:10] Prefill batch, #new-seq: 1, #new-token: 8, #cached-token: 883, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:10] INFO:     127.0.0.1:38700 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:12] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:12] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.95, #queue-req: 0, 
[2025-12-17 20:08:12] INFO:     127.0.0.1:38704 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:12] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:12] INFO:     127.0.0.1:38708 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:14] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:14] INFO:     127.0.0.1:38712 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:14] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 898, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:14] Decode batch, #running-req: 1, #token: 914, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.86, #queue-req: 0, 
[2025-12-17 20:08:14] INFO:     127.0.0.1:38716 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:16] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:16] INFO:     127.0.0.1:38720 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:16] Prefill batch, #new-seq: 1, #new-token: 1289, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:16] INFO:     127.0.0.1:38724 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:18] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:18] INFO:     127.0.0.1:38728 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:18] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.85, #queue-req: 0, 
[2025-12-17 20:08:18] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 901, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:18] INFO:     127.0.0.1:38732 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:19] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:20] INFO:     127.0.0.1:38738 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:20] Prefill batch, #new-seq: 1, #new-token: 769, #cached-token: 127, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:20] Decode batch, #running-req: 1, #token: 903, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.47, #queue-req: 0, 
[2025-12-17 20:08:20] INFO:     127.0.0.1:38742 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:21] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:21] INFO:     127.0.0.1:38746 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:21] Prefill batch, #new-seq: 1, #new-token: 833, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:22] Decode batch, #running-req: 1, #token: 996, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.70, #queue-req: 0, 
[2025-12-17 20:08:22] INFO:     127.0.0.1:38750 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:23] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:23] INFO:     127.0.0.1:38754 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:23] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:23] INFO:     127.0.0.1:38758 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:25] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:25] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.86, #queue-req: 0, 
[2025-12-17 20:08:25] INFO:     127.0.0.1:38762 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:25] Prefill batch, #new-seq: 1, #new-token: 6, #cached-token: 902, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:25] INFO:     127.0.0.1:38766 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:27] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:27] INFO:     127.0.0.1:38770 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:27] Prefill batch, #new-seq: 1, #new-token: 1138, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:27] Decode batch, #running-req: 1, #token: 1163, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.97, #queue-req: 0, 
[2025-12-17 20:08:27] INFO:     127.0.0.1:38774 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:29] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:29] INFO:     127.0.0.1:38778 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:29] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 899, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:29] INFO:     127.0.0.1:38782 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:31] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:31] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.00, #queue-req: 0, 
[2025-12-17 20:08:31] INFO:     127.0.0.1:40614 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:31] Prefill batch, #new-seq: 1, #new-token: 7, #cached-token: 884, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:31] INFO:     127.0.0.1:40618 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:33] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:33] INFO:     127.0.0.1:40622 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:33] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 863, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:33] Decode batch, #running-req: 1, #token: 884, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.15, #queue-req: 0, 
[2025-12-17 20:08:33] INFO:     127.0.0.1:40626 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:35] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:35] INFO:     127.0.0.1:40630 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:35] Prefill batch, #new-seq: 1, #new-token: 1315, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:35] INFO:     127.0.0.1:40634 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:37] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:37] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.75, #queue-req: 0, 
[2025-12-17 20:08:37] INFO:     127.0.0.1:40638 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:37] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 883, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:37] INFO:     127.0.0.1:40642 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:39] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:39] INFO:     127.0.0.1:40646 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:39] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 864, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:39] INFO:     127.0.0.1:40650 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:40] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:40] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.89, #queue-req: 0, 
[2025-12-17 20:08:40] INFO:     127.0.0.1:40654 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:40] Prefill batch, #new-seq: 1, #new-token: 1113, #cached-token: 93, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:41] Decode batch, #running-req: 1, #token: 1236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 187.30, #queue-req: 0, 
[2025-12-17 20:08:41] INFO:     127.0.0.1:40658 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:42] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:42] INFO:     127.0.0.1:40662 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:42] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 1188, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:43] Decode batch, #running-req: 1, #token: 1229, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.55, #queue-req: 0, 
[2025-12-17 20:08:43] INFO:     127.0.0.1:40666 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:44] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:44] INFO:     127.0.0.1:40670 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:44] Prefill batch, #new-seq: 1, #new-token: 1309, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:45] Decode batch, #running-req: 1, #token: 1350, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.72, #queue-req: 0, 
[2025-12-17 20:08:45] INFO:     127.0.0.1:40674 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:46] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:46] INFO:     127.0.0.1:40678 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:46] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 1227, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:46] INFO:     127.0.0.1:40684 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:48] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:48] Decode batch, #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.97, #queue-req: 0, 
[2025-12-17 20:08:48] INFO:     127.0.0.1:40688 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:48] Prefill batch, #new-seq: 1, #new-token: 21, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:48] INFO:     127.0.0.1:40692 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:50] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:50] INFO:     127.0.0.1:40696 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:50] Prefill batch, #new-seq: 1, #new-token: 1141, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:50] Decode batch, #running-req: 1, #token: 1158, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.66, #queue-req: 0, 
[2025-12-17 20:08:50] INFO:     127.0.0.1:40700 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:52] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:52] INFO:     127.0.0.1:40704 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:52] Prefill batch, #new-seq: 1, #new-token: 24, #cached-token: 1189, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:52] Decode batch, #running-req: 1, #token: 1234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.96, #queue-req: 0, 
[2025-12-17 20:08:52] INFO:     127.0.0.1:40708 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:54] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:54] INFO:     127.0.0.1:40712 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:54] Prefill batch, #new-seq: 1, #new-token: 1252, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:54] INFO:     127.0.0.1:40716 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:56] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:56] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.01, #queue-req: 0, 
[2025-12-17 20:08:56] INFO:     127.0.0.1:40722 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:56] Prefill batch, #new-seq: 1, #new-token: 24, #cached-token: 898, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:56] Decode batch, #running-req: 1, #token: 951, token usage: 0.00, cuda graph: True, gen throughput (token/s): 179.63, #queue-req: 0, 
[2025-12-17 20:08:56] INFO:     127.0.0.1:40726 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:58] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:58] INFO:     127.0.0.1:40730 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:08:58] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 1189, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:08:58] INFO:     127.0.0.1:40734 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:00] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:00] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.23, #queue-req: 0, 
[2025-12-17 20:09:00] INFO:     127.0.0.1:40738 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:00] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 880, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:00] INFO:     127.0.0.1:40742 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:02] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:02] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.93, #queue-req: 0, 
[2025-12-17 20:09:02] INFO:     127.0.0.1:40748 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:02] Prefill batch, #new-seq: 1, #new-token: 1075, #cached-token: 196, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:02] INFO:     127.0.0.1:40752 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:04] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:04] INFO:     127.0.0.1:40760 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:04] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:04] INFO:     127.0.0.1:40764 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:06] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:06] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.24, #queue-req: 0, 
[2025-12-17 20:09:06] INFO:     127.0.0.1:40770 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:06] Prefill batch, #new-seq: 1, #new-token: 1211, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:06] INFO:     127.0.0.1:40776 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:07] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:08] INFO:     127.0.0.1:40780 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:08] Prefill batch, #new-seq: 1, #new-token: 1271, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:08] Decode batch, #running-req: 1, #token: 1284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.53, #queue-req: 0, 
[2025-12-17 20:09:08] INFO:     127.0.0.1:40784 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:09] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:09] INFO:     127.0.0.1:40790 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:09] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 880, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:09] Decode batch, #running-req: 1, #token: 903, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.73, #queue-req: 0, 
[2025-12-17 20:09:10] INFO:     127.0.0.1:40794 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:12] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:12] INFO:     127.0.0.1:40800 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:12] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:12] INFO:     127.0.0.1:40804 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:14] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:14] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.77, #queue-req: 0, 
[2025-12-17 20:09:14] INFO:     127.0.0.1:40808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:14] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:14] INFO:     127.0.0.1:40812 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:15] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:15] INFO:     127.0.0.1:40816 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:15] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 864, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:16] Decode batch, #running-req: 1, #token: 890, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.69, #queue-req: 0, 
[2025-12-17 20:09:16] INFO:     127.0.0.1:40820 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:17] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:17] INFO:     127.0.0.1:40824 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:17] Prefill batch, #new-seq: 1, #new-token: 1357, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:17] Decode batch, #running-req: 1, #token: 1372, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.51, #queue-req: 0, 
[2025-12-17 20:09:18] INFO:     127.0.0.1:40828 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:19] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:19] INFO:     127.0.0.1:40834 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:19] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 899, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:19] INFO:     127.0.0.1:40838 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:21] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:21] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.29, #queue-req: 0, 
[2025-12-17 20:09:21] INFO:     127.0.0.1:40842 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:21] Prefill batch, #new-seq: 1, #new-token: 1494, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:21] INFO:     127.0.0.1:40846 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:23] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:23] INFO:     127.0.0.1:40850 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:23] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:23] Decode batch, #running-req: 1, #token: 896, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.29, #queue-req: 0, 
[2025-12-17 20:09:23] INFO:     127.0.0.1:40854 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:25] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:25] INFO:     127.0.0.1:40858 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:25] Prefill batch, #new-seq: 1, #new-token: 752, #cached-token: 125, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:25] Decode batch, #running-req: 1, #token: 893, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.66, #queue-req: 0, 
[2025-12-17 20:09:25] INFO:     127.0.0.1:40862 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:27] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:27] INFO:     127.0.0.1:40866 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:27] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:27] INFO:     127.0.0.1:40870 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:29] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:29] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.90, #queue-req: 0, 
[2025-12-17 20:09:29] INFO:     127.0.0.1:40874 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:29] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 898, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:29] INFO:     127.0.0.1:40878 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:31] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:31] INFO:     127.0.0.1:40882 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:31] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 880, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:31] Decode batch, #running-req: 1, #token: 901, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.45, #queue-req: 0, 
[2025-12-17 20:09:31] INFO:     127.0.0.1:40886 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:33] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:33] INFO:     127.0.0.1:40890 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:33] Prefill batch, #new-seq: 1, #new-token: 1232, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:33] Decode batch, #running-req: 1, #token: 1282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.34, #queue-req: 0, 
[2025-12-17 20:09:33] INFO:     127.0.0.1:40894 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:35] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:35] INFO:     127.0.0.1:40898 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:35] Prefill batch, #new-seq: 1, #new-token: 1117, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:35] INFO:     127.0.0.1:40902 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:37] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:37] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.16, #queue-req: 0, 
[2025-12-17 20:09:37] INFO:     127.0.0.1:40906 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:37] Prefill batch, #new-seq: 1, #new-token: 1217, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:37] INFO:     127.0.0.1:40910 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:39] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:39] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.72, #queue-req: 0, 
[2025-12-17 20:09:39] INFO:     127.0.0.1:40916 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:39] Prefill batch, #new-seq: 1, #new-token: 1106, #cached-token: 150, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:39] INFO:     127.0.0.1:40920 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:41] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:41] INFO:     127.0.0.1:40924 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:41] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 1188, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:41] Decode batch, #running-req: 1, #token: 1205, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.72, #queue-req: 0, 
[2025-12-17 20:09:41] Decode batch, #running-req: 1, #token: 1245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.59, #queue-req: 0, 
[2025-12-17 20:09:41] INFO:     127.0.0.1:40928 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:43] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:43] INFO:     127.0.0.1:40932 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:43] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 1190, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:43] INFO:     127.0.0.1:40936 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:45] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:45] INFO:     127.0.0.1:40940 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:45] Prefill batch, #new-seq: 1, #new-token: 1273, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:45] Decode batch, #running-req: 1, #token: 1290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.80, #queue-req: 0, 
[2025-12-17 20:09:45] INFO:     127.0.0.1:40944 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:46] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:47] INFO:     127.0.0.1:40948 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:47] Prefill batch, #new-seq: 1, #new-token: 1172, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:47] Decode batch, #running-req: 1, #token: 1192, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.62, #queue-req: 0, 
[2025-12-17 20:09:47] INFO:     127.0.0.1:40952 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:48] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:48] INFO:     127.0.0.1:40956 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:49] Prefill batch, #new-seq: 1, #new-token: 1109, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:49] Decode batch, #running-req: 1, #token: 1146, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.61, #queue-req: 0, 
[2025-12-17 20:09:49] INFO:     127.0.0.1:40960 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:50] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:50] INFO:     127.0.0.1:40964 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:50] Prefill batch, #new-seq: 1, #new-token: 893, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:50] Decode batch, #running-req: 1, #token: 923, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.63, #queue-req: 0, 
[2025-12-17 20:09:50] INFO:     127.0.0.1:40968 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:52] Prefill batch, #new-seq: 1, #new-token: 61, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:53] INFO:     127.0.0.1:40972 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:53] Prefill batch, #new-seq: 1, #new-token: 1247, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:53] INFO:     127.0.0.1:40976 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:54] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:54] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.23, #queue-req: 0, 
[2025-12-17 20:09:54] INFO:     127.0.0.1:40980 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:54] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 864, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:54] INFO:     127.0.0.1:40984 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:56] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:56] INFO:     127.0.0.1:40990 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:56] Prefill batch, #new-seq: 1, #new-token: 1334, #cached-token: 10, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:56] Decode batch, #running-req: 1, #token: 1347, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.34, #queue-req: 0, 
[2025-12-17 20:09:56] INFO:     127.0.0.1:40994 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:58] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:59] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.32, #queue-req: 0, 
[2025-12-17 20:09:59] INFO:     127.0.0.1:40998 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:09:59] Prefill batch, #new-seq: 1, #new-token: 1357, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:09:59] INFO:     127.0.0.1:41002 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:01] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:01] INFO:     127.0.0.1:41008 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:01] Prefill batch, #new-seq: 1, #new-token: 24, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:01] INFO:     127.0.0.1:41012 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:01] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.65, #queue-req: 0, 
[2025-12-17 20:10:03] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:03] INFO:     127.0.0.1:41016 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:03] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 900, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:03] INFO:     127.0.0.1:41020 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:04] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:04] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.04, #queue-req: 0, 
[2025-12-17 20:10:04] INFO:     127.0.0.1:41024 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:04] Prefill batch, #new-seq: 1, #new-token: 1262, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:05] INFO:     127.0.0.1:41028 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:06] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:06] Decode batch, #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.41, #queue-req: 0, 
[2025-12-17 20:10:06] INFO:     127.0.0.1:41032 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:06] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 863, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:06] INFO:     127.0.0.1:41036 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:08] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:08] INFO:     127.0.0.1:41040 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:08] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:08] INFO:     127.0.0.1:41044 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:10] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:10] Decode batch, #running-req: 1, #token: 70, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.92, #queue-req: 0, 
[2025-12-17 20:10:10] INFO:     127.0.0.1:41048 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:10] Prefill batch, #new-seq: 1, #new-token: 1071, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:10] INFO:     127.0.0.1:41052 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:12] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:12] INFO:     127.0.0.1:41056 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:12] Prefill batch, #new-seq: 1, #new-token: 1202, #cached-token: 117, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:12] Decode batch, #running-req: 1, #token: 1329, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.33, #queue-req: 0, 
[2025-12-17 20:10:12] INFO:     127.0.0.1:41060 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:14] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:14] INFO:     127.0.0.1:41064 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:14] Prefill batch, #new-seq: 1, #new-token: 1157, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:14] INFO:     127.0.0.1:41068 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:16] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:16] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.94, #queue-req: 0, 
[2025-12-17 20:10:16] INFO:     127.0.0.1:41072 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:16] Prefill batch, #new-seq: 1, #new-token: 756, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:16] INFO:     127.0.0.1:41076 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:18] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:18] INFO:     127.0.0.1:41080 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:18] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.95, #queue-req: 0, 
[2025-12-17 20:10:18] Prefill batch, #new-seq: 1, #new-token: 1111, #cached-token: 112, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:18] INFO:     127.0.0.1:41084 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:20] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:20] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.38, #queue-req: 0, 
[2025-12-17 20:10:20] INFO:     127.0.0.1:41088 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:20] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 864, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:20] INFO:     127.0.0.1:41092 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:22] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:22] Decode batch, #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.55, #queue-req: 0, 
[2025-12-17 20:10:22] INFO:     127.0.0.1:41096 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:22] Prefill batch, #new-seq: 1, #new-token: 1336, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:22] INFO:     127.0.0.1:41100 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:24] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:24] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.60, #queue-req: 0, 
[2025-12-17 20:10:24] INFO:     127.0.0.1:41104 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:24] Prefill batch, #new-seq: 1, #new-token: 21, #cached-token: 863, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:24] INFO:     127.0.0.1:41108 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:26] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:26] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.36, #queue-req: 0, 
[2025-12-17 20:10:26] INFO:     127.0.0.1:41112 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:26] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:26] INFO:     127.0.0.1:41116 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:28] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:28] INFO:     127.0.0.1:41120 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:28] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 898, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:28] Decode batch, #running-req: 1, #token: 922, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.40, #queue-req: 0, 
[2025-12-17 20:10:28] INFO:     127.0.0.1:41124 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:30] Prefill batch, #new-seq: 1, #new-token: 60, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:30] Decode batch, #running-req: 1, #token: 114, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.87, #queue-req: 0, 
[2025-12-17 20:10:30] INFO:     127.0.0.1:41128 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:30] Prefill batch, #new-seq: 1, #new-token: 1183, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:30] INFO:     127.0.0.1:41132 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:32] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:32] INFO:     127.0.0.1:41138 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:32] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 901, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:32] INFO:     127.0.0.1:41142 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:34] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:34] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.21, #queue-req: 0, 
[2025-12-17 20:10:34] INFO:     127.0.0.1:41146 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:34] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 883, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:34] INFO:     127.0.0.1:41150 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:36] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:36] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.80, #queue-req: 0, 
[2025-12-17 20:10:36] INFO:     127.0.0.1:41154 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:36] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 1189, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:36] INFO:     127.0.0.1:41158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:38] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:38] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.80, #queue-req: 0, 
[2025-12-17 20:10:38] INFO:     127.0.0.1:41164 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:38] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 883, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:38] INFO:     127.0.0.1:41168 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:40] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:40] INFO:     127.0.0.1:41174 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:40] Prefill batch, #new-seq: 1, #new-token: 1080, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:40] Decode batch, #running-req: 1, #token: 1095, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.32, #queue-req: 0, 
[2025-12-17 20:10:40] INFO:     127.0.0.1:41178 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:42] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:42] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.52, #queue-req: 0, 
[2025-12-17 20:10:42] INFO:     127.0.0.1:41184 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:42] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 863, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:42] INFO:     127.0.0.1:41188 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:44] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:44] Decode batch, #running-req: 1, #token: 92, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.72, #queue-req: 0, 
[2025-12-17 20:10:44] INFO:     127.0.0.1:41192 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:44] Prefill batch, #new-seq: 1, #new-token: 1164, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:44] INFO:     127.0.0.1:41196 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:46] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:46] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.52, #queue-req: 0, 
[2025-12-17 20:10:46] INFO:     127.0.0.1:41202 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:46] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 898, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:46] INFO:     127.0.0.1:41206 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:48] Prefill batch, #new-seq: 1, #new-token: 61, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:48] INFO:     127.0.0.1:41212 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:48] Prefill batch, #new-seq: 1, #new-token: 26, #cached-token: 864, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:48] Decode batch, #running-req: 1, #token: 896, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.43, #queue-req: 0, 
[2025-12-17 20:10:48] INFO:     127.0.0.1:41216 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:50] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:50] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.25, #queue-req: 0, 
[2025-12-17 20:10:50] INFO:     127.0.0.1:41220 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:50] Prefill batch, #new-seq: 1, #new-token: 1180, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:50] INFO:     127.0.0.1:41224 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:52] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:52] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.85, #queue-req: 0, 
[2025-12-17 20:10:52] INFO:     127.0.0.1:41228 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:52] Prefill batch, #new-seq: 1, #new-token: 21, #cached-token: 1191, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:52] INFO:     127.0.0.1:41232 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:54] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:54] INFO:     127.0.0.1:41236 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:54] Prefill batch, #new-seq: 1, #new-token: 881, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:54] Decode batch, #running-req: 1, #token: 928, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.60, #queue-req: 0, 
[2025-12-17 20:10:54] INFO:     127.0.0.1:41242 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:56] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:56] INFO:     127.0.0.1:41246 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:56] Prefill batch, #new-seq: 1, #new-token: 1294, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:56] Decode batch, #running-req: 1, #token: 1332, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.03, #queue-req: 0, 
[2025-12-17 20:10:56] INFO:     127.0.0.1:41250 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:58] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:58] INFO:     127.0.0.1:41254 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:58] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:10:58] Decode batch, #running-req: 1, #token: 901, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.77, #queue-req: 0, 
[2025-12-17 20:10:58] INFO:     127.0.0.1:41258 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:10:59] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:00] INFO:     127.0.0.1:41262 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:00] Prefill batch, #new-seq: 1, #new-token: 1087, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:00] Decode batch, #running-req: 1, #token: 1127, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.63, #queue-req: 0, 
[2025-12-17 20:11:00] INFO:     127.0.0.1:41266 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:01] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:01] INFO:     127.0.0.1:41272 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:02] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 881, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:02] INFO:     127.0.0.1:41276 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:03] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:03] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.83, #queue-req: 0, 
[2025-12-17 20:11:03] INFO:     127.0.0.1:41280 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:03] Prefill batch, #new-seq: 1, #new-token: 1144, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:04] INFO:     127.0.0.1:41284 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:04] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 189.55, #queue-req: 0, 
[2025-12-17 20:11:05] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:05] INFO:     127.0.0.1:41288 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:05] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 1189, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:05] INFO:     127.0.0.1:41292 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:07] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:07] INFO:     127.0.0.1:41296 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:07] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 1188, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:07] Decode batch, #running-req: 1, #token: 1217, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.86, #queue-req: 0, 
[2025-12-17 20:11:07] INFO:     127.0.0.1:41300 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:09] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:10] INFO:     127.0.0.1:41304 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:10] Prefill batch, #new-seq: 1, #new-token: 1191, #cached-token: 168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:10] Decode batch, #running-req: 1, #token: 1384, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.41, #queue-req: 0, 
[2025-12-17 20:11:10] INFO:     127.0.0.1:41308 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:11] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:12] INFO:     127.0.0.1:41312 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:12] Prefill batch, #new-seq: 1, #new-token: 27, #cached-token: 1227, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:12] INFO:     127.0.0.1:41316 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:13] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:13] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.98, #queue-req: 0, 
[2025-12-17 20:11:13] INFO:     127.0.0.1:41320 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:13] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 1189, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:13] INFO:     127.0.0.1:41324 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:15] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:15] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.49, #queue-req: 0, 
[2025-12-17 20:11:15] INFO:     127.0.0.1:41328 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:15] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 1226, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:15] INFO:     127.0.0.1:41332 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:17] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:17] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.62, #queue-req: 0, 
[2025-12-17 20:11:17] INFO:     127.0.0.1:41336 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:17] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 899, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:17] INFO:     127.0.0.1:41340 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:19] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:19] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.72, #queue-req: 0, 
[2025-12-17 20:11:19] INFO:     127.0.0.1:41346 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:19] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 885, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:19] INFO:     127.0.0.1:41350 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:21] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:21] INFO:     127.0.0.1:41354 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:21] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 1189, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:21] Decode batch, #running-req: 1, #token: 1217, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.42, #queue-req: 0, 
[2025-12-17 20:11:21] INFO:     127.0.0.1:41358 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:23] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:23] INFO:     127.0.0.1:41362 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:23] Prefill batch, #new-seq: 1, #new-token: 1294, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:23] Decode batch, #running-req: 1, #token: 1335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.75, #queue-req: 0, 
[2025-12-17 20:11:23] Decode batch, #running-req: 1, #token: 1375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 217.47, #queue-req: 0, 
[2025-12-17 20:11:23] Decode batch, #running-req: 1, #token: 1415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 20:11:24] Decode batch, #running-req: 1, #token: 1455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 20:11:24] Decode batch, #running-req: 1, #token: 1495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:11:24] Decode batch, #running-req: 1, #token: 1535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:11:24] Decode batch, #running-req: 1, #token: 1575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:11:24] Decode batch, #running-req: 1, #token: 1615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.62, #queue-req: 0, 
[2025-12-17 20:11:24] Decode batch, #running-req: 1, #token: 1655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.63, #queue-req: 0, 
[2025-12-17 20:11:25] Decode batch, #running-req: 1, #token: 1695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:11:25] Decode batch, #running-req: 1, #token: 1735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:11:25] Decode batch, #running-req: 1, #token: 1775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:11:25] Decode batch, #running-req: 1, #token: 1815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 20:11:25] Decode batch, #running-req: 1, #token: 1855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 20:11:26] Decode batch, #running-req: 1, #token: 1895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.49, #queue-req: 0, 
[2025-12-17 20:11:26] Decode batch, #running-req: 1, #token: 1935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:11:26] Decode batch, #running-req: 1, #token: 1975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:11:26] Decode batch, #running-req: 1, #token: 2015, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:11:26] Decode batch, #running-req: 1, #token: 2055, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.62, #queue-req: 0, 
[2025-12-17 20:11:26] Decode batch, #running-req: 1, #token: 2095, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.26, #queue-req: 0, 
[2025-12-17 20:11:27] Decode batch, #running-req: 1, #token: 2135, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.24, #queue-req: 0, 
[2025-12-17 20:11:27] Decode batch, #running-req: 1, #token: 2175, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.25, #queue-req: 0, 
[2025-12-17 20:11:27] Decode batch, #running-req: 1, #token: 2215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.24, #queue-req: 0, 
[2025-12-17 20:11:27] Decode batch, #running-req: 1, #token: 2255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.23, #queue-req: 0, 
[2025-12-17 20:11:27] Decode batch, #running-req: 1, #token: 2295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.21, #queue-req: 0, 
[2025-12-17 20:11:28] INFO:     127.0.0.1:41366 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:29] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:29] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.38, #queue-req: 0, 
[2025-12-17 20:11:29] INFO:     127.0.0.1:41372 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:29] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 1189, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:29] INFO:     127.0.0.1:41376 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:31] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:32] INFO:     127.0.0.1:41380 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:32] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.91, #queue-req: 0, 
[2025-12-17 20:11:32] Prefill batch, #new-seq: 1, #new-token: 1462, #cached-token: 38, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:32] INFO:     127.0.0.1:41384 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:33] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:33] INFO:     127.0.0.1:41388 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:33] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 1208, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:34] INFO:     127.0.0.1:41392 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:35] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:35] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.82, #queue-req: 0, 
[2025-12-17 20:11:35] INFO:     127.0.0.1:41398 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:35] Prefill batch, #new-seq: 1, #new-token: 1322, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:35] INFO:     127.0.0.1:41402 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:37] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:37] INFO:     127.0.0.1:41406 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:37] Prefill batch, #new-seq: 1, #new-token: 1162, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:37] Decode batch, #running-req: 1, #token: 1185, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.05, #queue-req: 0, 
[2025-12-17 20:11:37] INFO:     127.0.0.1:41410 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:39] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:39] INFO:     127.0.0.1:41414 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:39] Prefill batch, #new-seq: 1, #new-token: 1221, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:39] INFO:     127.0.0.1:41418 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:41] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:41] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.79, #queue-req: 0, 
[2025-12-17 20:11:41] INFO:     127.0.0.1:41422 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:41] Prefill batch, #new-seq: 1, #new-token: 1084, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:41] INFO:     127.0.0.1:41426 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:43] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:43] INFO:     127.0.0.1:41430 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:43] Prefill batch, #new-seq: 1, #new-token: 1233, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:43] Decode batch, #running-req: 1, #token: 1252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.87, #queue-req: 0, 
[2025-12-17 20:11:43] INFO:     127.0.0.1:41434 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:45] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:45] INFO:     127.0.0.1:41438 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:45] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 842, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:45] INFO:     127.0.0.1:41442 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:45] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.47, #queue-req: 0, 
[2025-12-17 20:11:47] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:47] INFO:     127.0.0.1:41446 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:47] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 1167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:47] INFO:     127.0.0.1:41450 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:49] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:49] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.70, #queue-req: 0, 
[2025-12-17 20:11:49] INFO:     127.0.0.1:41454 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:49] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 859, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:49] INFO:     127.0.0.1:41458 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:50] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:50] INFO:     127.0.0.1:41462 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:50] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 859, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:51] INFO:     127.0.0.1:41466 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:52] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:52] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.93, #queue-req: 0, 
[2025-12-17 20:11:52] INFO:     127.0.0.1:41470 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:52] Prefill batch, #new-seq: 1, #new-token: 1029, #cached-token: 149, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:52] INFO:     127.0.0.1:41474 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:54] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:54] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.69, #queue-req: 0, 
[2025-12-17 20:11:54] INFO:     127.0.0.1:41478 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:54] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 842, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:54] INFO:     127.0.0.1:41482 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:56] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:56] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.75, #queue-req: 0, 
[2025-12-17 20:11:56] INFO:     127.0.0.1:41488 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:56] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 860, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:56] INFO:     127.0.0.1:41492 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:58] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:58] INFO:     127.0.0.1:41496 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:58] Prefill batch, #new-seq: 1, #new-token: 1202, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:11:58] INFO:     127.0.0.1:41500 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:11:58] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.52, #queue-req: 0, 
[2025-12-17 20:12:00] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:00] INFO:     127.0.0.1:41504 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:00] Prefill batch, #new-seq: 1, #new-token: 1167, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:00] INFO:     127.0.0.1:41508 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:02] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:03] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.99, #queue-req: 0, 
[2025-12-17 20:12:03] INFO:     127.0.0.1:41512 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:03] Prefill batch, #new-seq: 1, #new-token: 1223, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:03] INFO:     127.0.0.1:41516 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:04] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:04] Decode batch, #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.55, #queue-req: 0, 
[2025-12-17 20:12:04] INFO:     127.0.0.1:41520 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:04] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 842, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:05] INFO:     127.0.0.1:41524 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:06] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:06] INFO:     127.0.0.1:41528 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:06] Prefill batch, #new-seq: 1, #new-token: 1095, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:07] Decode batch, #running-req: 1, #token: 1142, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.01, #queue-req: 0, 
[2025-12-17 20:12:07] INFO:     127.0.0.1:41532 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:08] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:08] INFO:     127.0.0.1:41536 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:08] Prefill batch, #new-seq: 1, #new-token: 1201, #cached-token: 19, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:08] INFO:     127.0.0.1:41540 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:10] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:10] INFO:     127.0.0.1:41546 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:10] Prefill batch, #new-seq: 1, #new-token: 1332, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:10] Decode batch, #running-req: 1, #token: 1348, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.74, #queue-req: 0, 
[2025-12-17 20:12:10] INFO:     127.0.0.1:41550 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:12] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:12] INFO:     127.0.0.1:41554 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:12] Prefill batch, #new-seq: 1, #new-token: 918, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:12] Decode batch, #running-req: 1, #token: 953, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.52, #queue-req: 0, 
[2025-12-17 20:12:12] INFO:     127.0.0.1:41558 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:14] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:14] INFO:     127.0.0.1:41562 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:14] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 862, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:14] INFO:     127.0.0.1:41566 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:16] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:16] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.05, #queue-req: 0, 
[2025-12-17 20:12:16] INFO:     127.0.0.1:41572 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:16] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 860, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:16] INFO:     127.0.0.1:41576 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:18] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:18] INFO:     127.0.0.1:41582 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:18] Prefill batch, #new-seq: 1, #new-token: 1202, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:18] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.30, #queue-req: 0, 
[2025-12-17 20:12:18] INFO:     127.0.0.1:41586 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:20] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:20] INFO:     127.0.0.1:41590 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:20] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 843, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:20] INFO:     127.0.0.1:41594 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:21] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:21] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.01, #queue-req: 0, 
[2025-12-17 20:12:22] INFO:     127.0.0.1:41598 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:22] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 844, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:22] INFO:     127.0.0.1:41602 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:23] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:23] INFO:     127.0.0.1:41606 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:23] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 860, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:23] Decode batch, #running-req: 1, #token: 899, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.55, #queue-req: 0, 
[2025-12-17 20:12:23] INFO:     127.0.0.1:41610 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:25] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:25] INFO:     127.0.0.1:41616 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:25] Prefill batch, #new-seq: 1, #new-token: 1413, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:25] INFO:     127.0.0.1:41620 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:27] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:27] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.13, #queue-req: 0, 
[2025-12-17 20:12:27] INFO:     127.0.0.1:41624 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:27] Prefill batch, #new-seq: 1, #new-token: 1231, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:27] INFO:     127.0.0.1:41628 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:29] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:29] INFO:     127.0.0.1:41632 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:29] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 861, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:29] Decode batch, #running-req: 1, #token: 898, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.98, #queue-req: 0, 
[2025-12-17 20:12:29] INFO:     127.0.0.1:41636 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:31] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:31] INFO:     127.0.0.1:41642 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:31] Prefill batch, #new-seq: 1, #new-token: 1214, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:31] INFO:     127.0.0.1:41646 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:33] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:33] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.35, #queue-req: 0, 
[2025-12-17 20:12:33] INFO:     127.0.0.1:41650 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:33] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 843, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:33] INFO:     127.0.0.1:41654 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:35] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:35] INFO:     127.0.0.1:41658 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:35] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 859, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:35] Decode batch, #running-req: 1, #token: 904, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.46, #queue-req: 0, 
[2025-12-17 20:12:35] INFO:     127.0.0.1:41662 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:37] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:37] INFO:     127.0.0.1:41668 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:37] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 860, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:37] INFO:     127.0.0.1:41672 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:39] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:39] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.25, #queue-req: 0, 
[2025-12-17 20:12:39] INFO:     127.0.0.1:41678 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:39] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 860, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:39] INFO:     127.0.0.1:41682 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:41] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:41] INFO:     127.0.0.1:41686 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:41] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 859, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:41] Decode batch, #running-req: 1, #token: 898, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.41, #queue-req: 0, 
[2025-12-17 20:12:41] INFO:     127.0.0.1:41690 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:43] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:43] INFO:     127.0.0.1:41696 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:43] Prefill batch, #new-seq: 1, #new-token: 1246, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:43] Decode batch, #running-req: 1, #token: 1293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.97, #queue-req: 0, 
[2025-12-17 20:12:43] INFO:     127.0.0.1:41700 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:45] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:45] INFO:     127.0.0.1:41704 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:45] Prefill batch, #new-seq: 1, #new-token: 1212, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:45] INFO:     127.0.0.1:41708 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:45] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.72, #queue-req: 0, 
[2025-12-17 20:12:46] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:47] INFO:     127.0.0.1:41712 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:47] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 859, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:47] INFO:     127.0.0.1:41716 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:48] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:48] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.17, #queue-req: 0, 
[2025-12-17 20:12:48] INFO:     127.0.0.1:41722 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:48] Prefill batch, #new-seq: 1, #new-token: 29, #cached-token: 860, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:48] INFO:     127.0.0.1:41726 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:50] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:50] INFO:     127.0.0.1:41730 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:50] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 1167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:50] INFO:     127.0.0.1:41734 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:56] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:56] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 5.02, #queue-req: 0, 
[2025-12-17 20:12:56] INFO:     127.0.0.1:41740 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:56] Prefill batch, #new-seq: 1, #new-token: 789, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:57] INFO:     127.0.0.1:41744 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:58] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:58] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.24, #queue-req: 0, 
[2025-12-17 20:12:58] INFO:     127.0.0.1:41748 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:12:58] Prefill batch, #new-seq: 1, #new-token: 810, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:12:59] Decode batch, #running-req: 1, #token: 850, token usage: 0.00, cuda graph: True, gen throughput (token/s): 193.86, #queue-req: 0, 
[2025-12-17 20:12:59] Decode batch, #running-req: 1, #token: 890, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.25, #queue-req: 0, 
[2025-12-17 20:12:59] Decode batch, #running-req: 1, #token: 930, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.40, #queue-req: 0, 
[2025-12-17 20:12:59] Decode batch, #running-req: 1, #token: 970, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.44, #queue-req: 0, 
[2025-12-17 20:12:59] Decode batch, #running-req: 1, #token: 1010, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.28, #queue-req: 0, 
[2025-12-17 20:12:59] Decode batch, #running-req: 1, #token: 1050, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.06, #queue-req: 0, 
[2025-12-17 20:13:00] Decode batch, #running-req: 1, #token: 1090, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:13:00] Decode batch, #running-req: 1, #token: 1130, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:13:00] Decode batch, #running-req: 1, #token: 1170, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 20:13:00] Decode batch, #running-req: 1, #token: 1210, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:13:00] Decode batch, #running-req: 1, #token: 1250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:13:01] Decode batch, #running-req: 1, #token: 1290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:13:01] Decode batch, #running-req: 1, #token: 1330, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 20:13:01] Decode batch, #running-req: 1, #token: 1370, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:13:01] Decode batch, #running-req: 1, #token: 1410, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:13:01] Decode batch, #running-req: 1, #token: 1450, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 20:13:01] Decode batch, #running-req: 1, #token: 1490, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:13:02] Decode batch, #running-req: 1, #token: 1530, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:13:02] Decode batch, #running-req: 1, #token: 1570, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.45, #queue-req: 0, 
[2025-12-17 20:13:02] Decode batch, #running-req: 1, #token: 1610, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.53, #queue-req: 0, 
[2025-12-17 20:13:02] Decode batch, #running-req: 1, #token: 1650, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 20:13:02] Decode batch, #running-req: 1, #token: 1690, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.26, #queue-req: 0, 
[2025-12-17 20:13:02] Decode batch, #running-req: 1, #token: 1730, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 20:13:03] Decode batch, #running-req: 1, #token: 1770, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.32, #queue-req: 0, 
[2025-12-17 20:13:03] Decode batch, #running-req: 1, #token: 1810, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.22, #queue-req: 0, 
[2025-12-17 20:13:03] INFO:     127.0.0.1:41752 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:05] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:05] INFO:     127.0.0.1:41756 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:05] Prefill batch, #new-seq: 1, #new-token: 63, #cached-token: 760, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:05] INFO:     127.0.0.1:41760 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:07] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:07] Decode batch, #running-req: 1, #token: 72, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.09, #queue-req: 0, 
[2025-12-17 20:13:07] INFO:     127.0.0.1:41764 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:07] Prefill batch, #new-seq: 1, #new-token: 1310, #cached-token: 18, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:07] INFO:     127.0.0.1:41768 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:09] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:09] INFO:     127.0.0.1:41772 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:09] Prefill batch, #new-seq: 1, #new-token: 507, #cached-token: 287, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:09] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.35, #queue-req: 0, 
[2025-12-17 20:13:09] INFO:     127.0.0.1:41776 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:11] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:11] INFO:     127.0.0.1:41782 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:11] Prefill batch, #new-seq: 1, #new-token: 1136, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:11] INFO:     127.0.0.1:41786 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:13] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:13] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.25, #queue-req: 0, 
[2025-12-17 20:13:13] INFO:     127.0.0.1:41790 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:13] Prefill batch, #new-seq: 1, #new-token: 1349, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:13] INFO:     127.0.0.1:41794 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:15] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:15] INFO:     127.0.0.1:41798 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:15] Prefill batch, #new-seq: 1, #new-token: 1225, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:15] INFO:     127.0.0.1:41802 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:16] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:16] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.90, #queue-req: 0, 
[2025-12-17 20:13:16] INFO:     127.0.0.1:41806 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:16] Prefill batch, #new-seq: 1, #new-token: 975, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:17] Decode batch, #running-req: 1, #token: 1025, token usage: 0.00, cuda graph: True, gen throughput (token/s): 192.14, #queue-req: 0, 
[2025-12-17 20:13:17] Decode batch, #running-req: 1, #token: 1065, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:13:17] Decode batch, #running-req: 1, #token: 1105, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:13:17] Decode batch, #running-req: 1, #token: 1145, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:13:17] Decode batch, #running-req: 1, #token: 1185, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.88, #queue-req: 0, 
[2025-12-17 20:13:17] Decode batch, #running-req: 1, #token: 1225, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:13:18] Decode batch, #running-req: 1, #token: 1265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:13:18] Decode batch, #running-req: 1, #token: 1305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:13:18] Decode batch, #running-req: 1, #token: 1345, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:13:18] Decode batch, #running-req: 1, #token: 1385, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.97, #queue-req: 0, 
[2025-12-17 20:13:18] Decode batch, #running-req: 1, #token: 1425, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:13:19] Decode batch, #running-req: 1, #token: 1465, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.29, #queue-req: 0, 
[2025-12-17 20:13:19] Decode batch, #running-req: 1, #token: 1505, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.01, #queue-req: 0, 
[2025-12-17 20:13:19] Decode batch, #running-req: 1, #token: 1545, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.02, #queue-req: 0, 
[2025-12-17 20:13:19] Decode batch, #running-req: 1, #token: 1585, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:13:19] Decode batch, #running-req: 1, #token: 1625, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:13:19] Decode batch, #running-req: 1, #token: 1665, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 20:13:20] Decode batch, #running-req: 1, #token: 1705, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:13:20] Decode batch, #running-req: 1, #token: 1745, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 20:13:20] Decode batch, #running-req: 1, #token: 1785, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 20:13:20] Decode batch, #running-req: 1, #token: 1825, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:13:20] Decode batch, #running-req: 1, #token: 1865, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:13:21] Decode batch, #running-req: 1, #token: 1905, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 20:13:21] Decode batch, #running-req: 1, #token: 1945, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:13:21] Decode batch, #running-req: 1, #token: 1985, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:13:21] INFO:     127.0.0.1:41810 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:23] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:23] INFO:     127.0.0.1:41814 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:23] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 804, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:23] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.60, #queue-req: 0, 
[2025-12-17 20:13:23] INFO:     127.0.0.1:41818 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:25] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:25] INFO:     127.0.0.1:41822 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:25] Prefill batch, #new-seq: 1, #new-token: 581, #cached-token: 221, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:25] INFO:     127.0.0.1:41826 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:26] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:27] INFO:     127.0.0.1:41830 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:27] Prefill batch, #new-seq: 1, #new-token: 612, #cached-token: 222, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:27] Decode batch, #running-req: 1, #token: 837, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.64, #queue-req: 0, 
[2025-12-17 20:13:27] INFO:     127.0.0.1:41834 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:28] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:28] INFO:     127.0.0.1:41838 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:28] Prefill batch, #new-seq: 1, #new-token: 1245, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:29] Decode batch, #running-req: 1, #token: 1275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.26, #queue-req: 0, 
[2025-12-17 20:13:29] INFO:     127.0.0.1:41842 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:31] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:31] INFO:     127.0.0.1:41846 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:31] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 807, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:31] INFO:     127.0.0.1:41850 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:32] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:33] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.20, #queue-req: 0, 
[2025-12-17 20:13:33] INFO:     127.0.0.1:41854 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:33] Prefill batch, #new-seq: 1, #new-token: 822, #cached-token: 403, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:33] INFO:     127.0.0.1:41858 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:34] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:34] INFO:     127.0.0.1:41862 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:34] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 806, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:34] Decode batch, #running-req: 1, #token: 829, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.32, #queue-req: 0, 
[2025-12-17 20:13:34] INFO:     127.0.0.1:41866 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:36] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:36] INFO:     127.0.0.1:41872 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:36] Prefill batch, #new-seq: 1, #new-token: 1232, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:36] INFO:     127.0.0.1:41876 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:38] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:38] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.06, #queue-req: 0, 
[2025-12-17 20:13:38] INFO:     127.0.0.1:41884 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:38] Prefill batch, #new-seq: 1, #new-token: 1254, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:39] INFO:     127.0.0.1:41888 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:40] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:40] INFO:     127.0.0.1:41892 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:40] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 804, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:40] INFO:     127.0.0.1:41896 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:40] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.26, #queue-req: 0, 
[2025-12-17 20:13:42] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:42] INFO:     127.0.0.1:41904 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:42] Prefill batch, #new-seq: 1, #new-token: 1214, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:42] INFO:     127.0.0.1:41908 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:44] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:44] INFO:     127.0.0.1:41912 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:44] Prefill batch, #new-seq: 1, #new-token: 7, #cached-token: 807, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:44] Decode batch, #running-req: 1, #token: 821, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.68, #queue-req: 0, 
[2025-12-17 20:13:44] INFO:     127.0.0.1:41916 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:46] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:46] INFO:     127.0.0.1:41920 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:46] Prefill batch, #new-seq: 1, #new-token: 21, #cached-token: 804, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:46] INFO:     127.0.0.1:41924 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:48] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:48] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.05, #queue-req: 0, 
[2025-12-17 20:13:48] INFO:     127.0.0.1:41928 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:48] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 807, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:48] INFO:     127.0.0.1:41932 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:50] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:50] INFO:     127.0.0.1:41936 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:50] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 786, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:50] Decode batch, #running-req: 1, #token: 808, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.66, #queue-req: 0, 
[2025-12-17 20:13:50] INFO:     127.0.0.1:41940 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:52] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:52] INFO:     127.0.0.1:41944 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:52] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 805, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:52] INFO:     127.0.0.1:41948 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:54] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:54] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.67, #queue-req: 0, 
[2025-12-17 20:13:54] INFO:     127.0.0.1:41952 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:54] Prefill batch, #new-seq: 1, #new-token: 1116, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:54] INFO:     127.0.0.1:41956 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:56] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:56] INFO:     127.0.0.1:41960 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:56] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 1185, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:56] Decode batch, #running-req: 1, #token: 1250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.39, #queue-req: 0, 
[2025-12-17 20:13:56] INFO:     127.0.0.1:41964 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:58] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:58] INFO:     127.0.0.1:41968 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:13:58] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:13:58] INFO:     127.0.0.1:41972 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:00] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:00] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.86, #queue-req: 0, 
[2025-12-17 20:14:00] INFO:     127.0.0.1:41976 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:00] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 807, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:00] INFO:     127.0.0.1:41980 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:01] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:02] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.72, #queue-req: 0, 
[2025-12-17 20:14:02] Decode batch, #running-req: 1, #token: 127, token usage: 0.00, cuda graph: True, gen throughput (token/s): 227.48, #queue-req: 0, 
[2025-12-17 20:14:02] Decode batch, #running-req: 1, #token: 167, token usage: 0.00, cuda graph: True, gen throughput (token/s): 225.88, #queue-req: 0, 
[2025-12-17 20:14:02] Decode batch, #running-req: 1, #token: 207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 225.74, #queue-req: 0, 
[2025-12-17 20:14:02] Decode batch, #running-req: 1, #token: 247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 225.82, #queue-req: 0, 
[2025-12-17 20:14:02] Decode batch, #running-req: 1, #token: 287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 224.03, #queue-req: 0, 
[2025-12-17 20:14:03] Decode batch, #running-req: 1, #token: 327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 223.20, #queue-req: 0, 
[2025-12-17 20:14:03] Decode batch, #running-req: 1, #token: 367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.62, #queue-req: 0, 
[2025-12-17 20:14:03] Decode batch, #running-req: 1, #token: 407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.76, #queue-req: 0, 
[2025-12-17 20:14:03] Decode batch, #running-req: 1, #token: 447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.77, #queue-req: 0, 
[2025-12-17 20:14:03] Decode batch, #running-req: 1, #token: 487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.77, #queue-req: 0, 
[2025-12-17 20:14:04] Decode batch, #running-req: 1, #token: 527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.52, #queue-req: 0, 
[2025-12-17 20:14:04] Decode batch, #running-req: 1, #token: 567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.41, #queue-req: 0, 
[2025-12-17 20:14:04] Decode batch, #running-req: 1, #token: 607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.40, #queue-req: 0, 
[2025-12-17 20:14:04] Decode batch, #running-req: 1, #token: 647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.30, #queue-req: 0, 
[2025-12-17 20:14:04] Decode batch, #running-req: 1, #token: 687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.32, #queue-req: 0, 
[2025-12-17 20:14:04] Decode batch, #running-req: 1, #token: 727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.33, #queue-req: 0, 
[2025-12-17 20:14:05] Decode batch, #running-req: 1, #token: 767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.23, #queue-req: 0, 
[2025-12-17 20:14:05] Decode batch, #running-req: 1, #token: 807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.31, #queue-req: 0, 
[2025-12-17 20:14:05] Decode batch, #running-req: 1, #token: 847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.34, #queue-req: 0, 
[2025-12-17 20:14:05] Decode batch, #running-req: 1, #token: 887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.24, #queue-req: 0, 
[2025-12-17 20:14:05] Decode batch, #running-req: 1, #token: 927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.23, #queue-req: 0, 
[2025-12-17 20:14:06] Decode batch, #running-req: 1, #token: 967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.42, #queue-req: 0, 
[2025-12-17 20:14:06] Decode batch, #running-req: 1, #token: 1007, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.30, #queue-req: 0, 
[2025-12-17 20:14:06] Decode batch, #running-req: 1, #token: 1047, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.12, #queue-req: 0, 
[2025-12-17 20:14:06] INFO:     127.0.0.1:41984 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:06] Prefill batch, #new-seq: 1, #new-token: 830, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:06] Decode batch, #running-req: 1, #token: 857, token usage: 0.00, cuda graph: True, gen throughput (token/s): 191.97, #queue-req: 0, 
[2025-12-17 20:14:06] INFO:     127.0.0.1:41990 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:08] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:08] INFO:     127.0.0.1:41994 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:08] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:08] Decode batch, #running-req: 1, #token: 822, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.47, #queue-req: 0, 
[2025-12-17 20:14:08] INFO:     127.0.0.1:41998 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:10] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:10] INFO:     127.0.0.1:42004 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:10] Prefill batch, #new-seq: 1, #new-token: 712, #cached-token: 87, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:10] Decode batch, #running-req: 1, #token: 818, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.11, #queue-req: 0, 
[2025-12-17 20:14:10] Decode batch, #running-req: 1, #token: 858, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.61, #queue-req: 0, 
[2025-12-17 20:14:11] Decode batch, #running-req: 1, #token: 898, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.47, #queue-req: 0, 
[2025-12-17 20:14:11] Decode batch, #running-req: 1, #token: 938, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.46, #queue-req: 0, 
[2025-12-17 20:14:11] Decode batch, #running-req: 1, #token: 978, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.59, #queue-req: 0, 
[2025-12-17 20:14:11] Decode batch, #running-req: 1, #token: 1018, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.58, #queue-req: 0, 
[2025-12-17 20:14:11] Decode batch, #running-req: 1, #token: 1058, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:14:11] Decode batch, #running-req: 1, #token: 1098, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.98, #queue-req: 0, 
[2025-12-17 20:14:12] Decode batch, #running-req: 1, #token: 1138, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:14:12] Decode batch, #running-req: 1, #token: 1178, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.92, #queue-req: 0, 
[2025-12-17 20:14:12] Decode batch, #running-req: 1, #token: 1218, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.01, #queue-req: 0, 
[2025-12-17 20:14:12] Decode batch, #running-req: 1, #token: 1258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:14:12] Decode batch, #running-req: 1, #token: 1298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:14:13] Decode batch, #running-req: 1, #token: 1338, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:14:13] Decode batch, #running-req: 1, #token: 1378, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:14:13] Decode batch, #running-req: 1, #token: 1418, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:14:13] Decode batch, #running-req: 1, #token: 1458, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.02, #queue-req: 0, 
[2025-12-17 20:14:13] Decode batch, #running-req: 1, #token: 1498, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.96, #queue-req: 0, 
[2025-12-17 20:14:13] Decode batch, #running-req: 1, #token: 1538, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:14:14] Decode batch, #running-req: 1, #token: 1578, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:14:14] Decode batch, #running-req: 1, #token: 1618, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:14:14] Decode batch, #running-req: 1, #token: 1658, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 20:14:14] Decode batch, #running-req: 1, #token: 1698, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 20:14:14] Decode batch, #running-req: 1, #token: 1738, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:14:15] Decode batch, #running-req: 1, #token: 1778, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:14:15] INFO:     127.0.0.1:42008 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:16] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:16] INFO:     127.0.0.1:42018 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:16] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 1229, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:16] Decode batch, #running-req: 1, #token: 1253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.90, #queue-req: 0, 
[2025-12-17 20:14:17] INFO:     127.0.0.1:42022 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:18] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:19] INFO:     127.0.0.1:42026 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:19] Prefill batch, #new-seq: 1, #new-token: 1078, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:19] INFO:     127.0.0.1:42030 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:20] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:20] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.25, #queue-req: 0, 
[2025-12-17 20:14:20] INFO:     127.0.0.1:42034 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:20] Prefill batch, #new-seq: 1, #new-token: 1269, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:21] INFO:     127.0.0.1:42038 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:22] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:22] INFO:     127.0.0.1:42042 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:22] Prefill batch, #new-seq: 1, #new-token: 984, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:22] Decode batch, #running-req: 1, #token: 1001, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.14, #queue-req: 0, 
[2025-12-17 20:14:22] INFO:     127.0.0.1:42046 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:24] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:24] INFO:     127.0.0.1:42054 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:25] Prefill batch, #new-seq: 1, #new-token: 1461, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:25] INFO:     127.0.0.1:42058 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:26] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:26] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.07, #queue-req: 0, 
[2025-12-17 20:14:26] INFO:     127.0.0.1:42064 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:26] Prefill batch, #new-seq: 1, #new-token: 782, #cached-token: 87, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:27] Decode batch, #running-req: 1, #token: 902, token usage: 0.00, cuda graph: True, gen throughput (token/s): 193.02, #queue-req: 0, 
[2025-12-17 20:14:27] Decode batch, #running-req: 1, #token: 942, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.71, #queue-req: 0, 
[2025-12-17 20:14:27] Decode batch, #running-req: 1, #token: 982, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.70, #queue-req: 0, 
[2025-12-17 20:14:27] Decode batch, #running-req: 1, #token: 1022, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.67, #queue-req: 0, 
[2025-12-17 20:14:27] Decode batch, #running-req: 1, #token: 1062, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.01, #queue-req: 0, 
[2025-12-17 20:14:27] Decode batch, #running-req: 1, #token: 1102, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.05, #queue-req: 0, 
[2025-12-17 20:14:28] Decode batch, #running-req: 1, #token: 1142, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.05, #queue-req: 0, 
[2025-12-17 20:14:28] Decode batch, #running-req: 1, #token: 1182, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:14:28] Decode batch, #running-req: 1, #token: 1222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:14:28] Decode batch, #running-req: 1, #token: 1262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.94, #queue-req: 0, 
[2025-12-17 20:14:28] Decode batch, #running-req: 1, #token: 1302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:14:29] Decode batch, #running-req: 1, #token: 1342, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.96, #queue-req: 0, 
[2025-12-17 20:14:29] Decode batch, #running-req: 1, #token: 1382, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:14:29] Decode batch, #running-req: 1, #token: 1422, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:14:29] Decode batch, #running-req: 1, #token: 1462, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:14:29] Decode batch, #running-req: 1, #token: 1502, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.02, #queue-req: 0, 
[2025-12-17 20:14:29] Decode batch, #running-req: 1, #token: 1542, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:14:30] Decode batch, #running-req: 1, #token: 1582, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:14:30] Decode batch, #running-req: 1, #token: 1622, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:14:30] Decode batch, #running-req: 1, #token: 1662, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 20:14:30] Decode batch, #running-req: 1, #token: 1702, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 20:14:30] Decode batch, #running-req: 1, #token: 1742, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:14:31] Decode batch, #running-req: 1, #token: 1782, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.64, #queue-req: 0, 
[2025-12-17 20:14:31] Decode batch, #running-req: 1, #token: 1822, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 20:14:31] Decode batch, #running-req: 1, #token: 1862, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 20:14:31] INFO:     127.0.0.1:42068 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:33] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:33] INFO:     127.0.0.1:42072 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:33] Prefill batch, #new-seq: 1, #new-token: 1426, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:33] INFO:     127.0.0.1:42076 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:35] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:35] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.19, #queue-req: 0, 
[2025-12-17 20:14:35] INFO:     127.0.0.1:42082 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:35] Prefill batch, #new-seq: 1, #new-token: 1147, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:35] INFO:     127.0.0.1:42086 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:37] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:37] INFO:     127.0.0.1:42090 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:37] Prefill batch, #new-seq: 1, #new-token: 8, #cached-token: 807, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:37] Decode batch, #running-req: 1, #token: 826, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.09, #queue-req: 0, 
[2025-12-17 20:14:37] INFO:     127.0.0.1:42094 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:39] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:39] INFO:     127.0.0.1:42098 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:39] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 807, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:39] INFO:     127.0.0.1:42102 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:41] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:41] INFO:     127.0.0.1:42106 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:41] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.76, #queue-req: 0, 
[2025-12-17 20:14:41] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 1211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:41] INFO:     127.0.0.1:42110 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:43] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:43] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.64, #queue-req: 0, 
[2025-12-17 20:14:43] INFO:     127.0.0.1:42114 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:43] Prefill batch, #new-seq: 1, #new-token: 619, #cached-token: 223, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:43] INFO:     127.0.0.1:42118 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:45] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:45] INFO:     127.0.0.1:42122 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:45] Prefill batch, #new-seq: 1, #new-token: 552, #cached-token: 345, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:45] Decode batch, #running-req: 1, #token: 899, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.51, #queue-req: 0, 
[2025-12-17 20:14:45] INFO:     127.0.0.1:42126 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:47] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:47] INFO:     127.0.0.1:42130 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:47] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:47] INFO:     127.0.0.1:42134 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:48] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:48] Decode batch, #running-req: 1, #token: 70, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.86, #queue-req: 0, 
[2025-12-17 20:14:49] INFO:     127.0.0.1:42138 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:49] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:49] INFO:     127.0.0.1:42142 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:50] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:50] INFO:     127.0.0.1:42146 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:50] Prefill batch, #new-seq: 1, #new-token: 767, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:50] Decode batch, #running-req: 1, #token: 781, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.55, #queue-req: 0, 
[2025-12-17 20:14:51] INFO:     127.0.0.1:42150 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:52] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:52] INFO:     127.0.0.1:42154 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:52] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 825, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:52] Decode batch, #running-req: 1, #token: 844, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.75, #queue-req: 0, 
[2025-12-17 20:14:52] INFO:     127.0.0.1:42158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:54] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:54] INFO:     127.0.0.1:42162 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:54] Prefill batch, #new-seq: 1, #new-token: 1267, #cached-token: 16, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:54] INFO:     127.0.0.1:42166 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:56] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:56] INFO:     127.0.0.1:42170 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:56] Prefill batch, #new-seq: 1, #new-token: 1028, #cached-token: 278, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:56] Decode batch, #running-req: 1, #token: 1308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.03, #queue-req: 0, 
[2025-12-17 20:14:56] INFO:     127.0.0.1:42174 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:58] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:58] INFO:     127.0.0.1:42178 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:14:58] Prefill batch, #new-seq: 1, #new-token: 782, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:14:58] Decode batch, #running-req: 1, #token: 904, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.52, #queue-req: 0, 
[2025-12-17 20:14:58] INFO:     127.0.0.1:42182 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:00] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:00] INFO:     127.0.0.1:42186 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:00] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 1213, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:00] Decode batch, #running-req: 1, #token: 1245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.53, #queue-req: 0, 
[2025-12-17 20:15:00] INFO:     127.0.0.1:42190 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:02] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:02] INFO:     127.0.0.1:42196 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:02] Prefill batch, #new-seq: 1, #new-token: 1368, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:02] Decode batch, #running-req: 1, #token: 1402, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.40, #queue-req: 0, 
[2025-12-17 20:15:02] Decode batch, #running-req: 1, #token: 1442, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 20:15:03] Decode batch, #running-req: 1, #token: 1482, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.25, #queue-req: 0, 
[2025-12-17 20:15:03] Decode batch, #running-req: 1, #token: 1522, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.12, #queue-req: 0, 
[2025-12-17 20:15:03] Decode batch, #running-req: 1, #token: 1562, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:15:03] Decode batch, #running-req: 1, #token: 1602, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:15:03] Decode batch, #running-req: 1, #token: 1642, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:15:03] Decode batch, #running-req: 1, #token: 1682, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:15:04] Decode batch, #running-req: 1, #token: 1722, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 20:15:04] Decode batch, #running-req: 1, #token: 1762, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:15:04] Decode batch, #running-req: 1, #token: 1802, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.43, #queue-req: 0, 
[2025-12-17 20:15:04] Decode batch, #running-req: 1, #token: 1842, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.64, #queue-req: 0, 
[2025-12-17 20:15:04] Decode batch, #running-req: 1, #token: 1882, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.38, #queue-req: 0, 
[2025-12-17 20:15:05] Decode batch, #running-req: 1, #token: 1922, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.63, #queue-req: 0, 
[2025-12-17 20:15:05] Decode batch, #running-req: 1, #token: 1962, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:15:05] Decode batch, #running-req: 1, #token: 2002, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:15:05] Decode batch, #running-req: 1, #token: 2042, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:15:05] Decode batch, #running-req: 1, #token: 2082, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.34, #queue-req: 0, 
[2025-12-17 20:15:05] Decode batch, #running-req: 1, #token: 2122, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.30, #queue-req: 0, 
[2025-12-17 20:15:06] Decode batch, #running-req: 1, #token: 2162, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.19, #queue-req: 0, 
[2025-12-17 20:15:06] Decode batch, #running-req: 1, #token: 2202, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.15, #queue-req: 0, 
[2025-12-17 20:15:06] Decode batch, #running-req: 1, #token: 2242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.14, #queue-req: 0, 
[2025-12-17 20:15:06] Decode batch, #running-req: 1, #token: 2282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.29, #queue-req: 0, 
[2025-12-17 20:15:06] Decode batch, #running-req: 1, #token: 2322, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.20, #queue-req: 0, 
[2025-12-17 20:15:07] Decode batch, #running-req: 1, #token: 2362, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.19, #queue-req: 0, 
[2025-12-17 20:15:07] INFO:     127.0.0.1:42200 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:08] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:08] INFO:     127.0.0.1:42208 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:08] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 786, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:09] Decode batch, #running-req: 1, #token: 806, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.49, #queue-req: 0, 
[2025-12-17 20:15:09] INFO:     127.0.0.1:42212 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:10] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:10] INFO:     127.0.0.1:42216 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:10] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:10] Decode batch, #running-req: 1, #token: 814, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.73, #queue-req: 0, 
[2025-12-17 20:15:10] INFO:     127.0.0.1:42220 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:12] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:12] INFO:     127.0.0.1:42224 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:12] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 1212, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:12] INFO:     127.0.0.1:42228 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:14] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:14] INFO:     127.0.0.1:42232 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:14] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.91, #queue-req: 0, 
[2025-12-17 20:15:14] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 807, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:14] INFO:     127.0.0.1:42236 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:16] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:16] INFO:     127.0.0.1:42240 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:16] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:16] Decode batch, #running-req: 1, #token: 803, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.42, #queue-req: 0, 
[2025-12-17 20:15:16] INFO:     127.0.0.1:42244 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:18] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:18] INFO:     127.0.0.1:42248 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:18] Prefill batch, #new-seq: 1, #new-token: 767, #cached-token: 85, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:18] Decode batch, #running-req: 1, #token: 855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.24, #queue-req: 0, 
[2025-12-17 20:15:18] INFO:     127.0.0.1:42252 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:20] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:20] INFO:     127.0.0.1:42258 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:20] Prefill batch, #new-seq: 1, #new-token: 1157, #cached-token: 167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:20] Decode batch, #running-req: 1, #token: 1326, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.04, #queue-req: 0, 
[2025-12-17 20:15:20] INFO:     127.0.0.1:42262 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:22] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:22] INFO:     127.0.0.1:42266 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:22] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 1212, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:22] INFO:     127.0.0.1:42270 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:24] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:24] Decode batch, #running-req: 1, #token: 72, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.03, #queue-req: 0, 
[2025-12-17 20:15:24] INFO:     127.0.0.1:42276 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:24] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 786, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:24] INFO:     127.0.0.1:42280 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:25] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:25] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.92, #queue-req: 0, 
[2025-12-17 20:15:25] INFO:     127.0.0.1:42284 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:26] Prefill batch, #new-seq: 1, #new-token: 1146, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:26] INFO:     127.0.0.1:42288 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:27] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:27] INFO:     127.0.0.1:42292 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:27] Prefill batch, #new-seq: 1, #new-token: 1049, #cached-token: 220, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:27] Decode batch, #running-req: 1, #token: 1274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.18, #queue-req: 0, 
[2025-12-17 20:15:28] INFO:     127.0.0.1:42296 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:29] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:29] INFO:     127.0.0.1:42300 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:29] Prefill batch, #new-seq: 1, #new-token: 1120, #cached-token: 224, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:29] Decode batch, #running-req: 1, #token: 1346, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.36, #queue-req: 0, 
[2025-12-17 20:15:29] INFO:     127.0.0.1:42304 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:31] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:31] INFO:     127.0.0.1:42308 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:31] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 781, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:31] INFO:     127.0.0.1:42312 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:33] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:33] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.98, #queue-req: 0, 
[2025-12-17 20:15:33] INFO:     127.0.0.1:42316 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:33] Prefill batch, #new-seq: 1, #new-token: 1249, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:33] INFO:     127.0.0.1:42320 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:35] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:35] INFO:     127.0.0.1:42324 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:35] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 788, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:35] Decode batch, #running-req: 1, #token: 815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.34, #queue-req: 0, 
[2025-12-17 20:15:35] Decode batch, #running-req: 1, #token: 855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 214.01, #queue-req: 0, 
[2025-12-17 20:15:35] Decode batch, #running-req: 1, #token: 895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.41, #queue-req: 0, 
[2025-12-17 20:15:36] Decode batch, #running-req: 1, #token: 935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.70, #queue-req: 0, 
[2025-12-17 20:15:36] Decode batch, #running-req: 1, #token: 975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.58, #queue-req: 0, 
[2025-12-17 20:15:36] Decode batch, #running-req: 1, #token: 1015, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.65, #queue-req: 0, 
[2025-12-17 20:15:36] Decode batch, #running-req: 1, #token: 1055, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.16, #queue-req: 0, 
[2025-12-17 20:15:36] Decode batch, #running-req: 1, #token: 1095, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 20:15:36] Decode batch, #running-req: 1, #token: 1135, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.88, #queue-req: 0, 
[2025-12-17 20:15:37] Decode batch, #running-req: 1, #token: 1175, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:15:37] Decode batch, #running-req: 1, #token: 1215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:15:37] Decode batch, #running-req: 1, #token: 1255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:15:37] Decode batch, #running-req: 1, #token: 1295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:15:37] Decode batch, #running-req: 1, #token: 1335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:15:38] Decode batch, #running-req: 1, #token: 1375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:15:38] Decode batch, #running-req: 1, #token: 1415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:15:38] Decode batch, #running-req: 1, #token: 1455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:15:38] Decode batch, #running-req: 1, #token: 1495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.92, #queue-req: 0, 
[2025-12-17 20:15:38] Decode batch, #running-req: 1, #token: 1535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:15:38] Decode batch, #running-req: 1, #token: 1575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:15:39] Decode batch, #running-req: 1, #token: 1615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:15:39] Decode batch, #running-req: 1, #token: 1655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.63, #queue-req: 0, 
[2025-12-17 20:15:39] Decode batch, #running-req: 1, #token: 1695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:15:39] Decode batch, #running-req: 1, #token: 1735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:15:39] Decode batch, #running-req: 1, #token: 1775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 20:15:40] INFO:     127.0.0.1:42328 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:41] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:41] INFO:     127.0.0.1:42332 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:41] Prefill batch, #new-seq: 1, #new-token: 1259, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:41] Decode batch, #running-req: 1, #token: 1434, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.62, #queue-req: 0, 
[2025-12-17 20:15:41] INFO:     127.0.0.1:42336 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:43] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:43] INFO:     127.0.0.1:42340 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:43] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 840, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:43] INFO:     127.0.0.1:42344 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:45] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:45] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.05, #queue-req: 0, 
[2025-12-17 20:15:45] INFO:     127.0.0.1:42348 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:45] Prefill batch, #new-seq: 1, #new-token: 1103, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:45] INFO:     127.0.0.1:42352 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:47] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:47] INFO:     127.0.0.1:42356 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:47] Prefill batch, #new-seq: 1, #new-token: 65, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:47] Decode batch, #running-req: 1, #token: 827, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.38, #queue-req: 0, 
[2025-12-17 20:15:47] Decode batch, #running-req: 1, #token: 867, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.42, #queue-req: 0, 
[2025-12-17 20:15:47] Decode batch, #running-req: 1, #token: 907, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.47, #queue-req: 0, 
[2025-12-17 20:15:47] Decode batch, #running-req: 1, #token: 947, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.56, #queue-req: 0, 
[2025-12-17 20:15:48] Decode batch, #running-req: 1, #token: 987, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.57, #queue-req: 0, 
[2025-12-17 20:15:48] Decode batch, #running-req: 1, #token: 1027, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.52, #queue-req: 0, 
[2025-12-17 20:15:48] Decode batch, #running-req: 1, #token: 1067, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 20:15:48] Decode batch, #running-req: 1, #token: 1107, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.08, #queue-req: 0, 
[2025-12-17 20:15:48] Decode batch, #running-req: 1, #token: 1147, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:15:49] Decode batch, #running-req: 1, #token: 1187, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.07, #queue-req: 0, 
[2025-12-17 20:15:49] Decode batch, #running-req: 1, #token: 1227, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.10, #queue-req: 0, 
[2025-12-17 20:15:49] Decode batch, #running-req: 1, #token: 1267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:15:49] Decode batch, #running-req: 1, #token: 1307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.06, #queue-req: 0, 
[2025-12-17 20:15:49] Decode batch, #running-req: 1, #token: 1347, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:15:49] Decode batch, #running-req: 1, #token: 1387, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:15:50] Decode batch, #running-req: 1, #token: 1427, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:15:50] Decode batch, #running-req: 1, #token: 1467, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:15:50] Decode batch, #running-req: 1, #token: 1507, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.22, #queue-req: 0, 
[2025-12-17 20:15:50] Decode batch, #running-req: 1, #token: 1547, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 20:15:50] Decode batch, #running-req: 1, #token: 1587, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:15:51] Decode batch, #running-req: 1, #token: 1627, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:15:51] Decode batch, #running-req: 1, #token: 1667, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:15:51] Decode batch, #running-req: 1, #token: 1707, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:15:51] Decode batch, #running-req: 1, #token: 1747, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:15:51] Decode batch, #running-req: 1, #token: 1787, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:15:51] INFO:     127.0.0.1:42360 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:53] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:53] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.26, #queue-req: 0, 
[2025-12-17 20:15:53] INFO:     127.0.0.1:42366 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:53] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 788, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:53] INFO:     127.0.0.1:42370 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:55] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:55] INFO:     127.0.0.1:42376 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:55] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:55] Decode batch, #running-req: 1, #token: 813, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.56, #queue-req: 0, 
[2025-12-17 20:15:56] INFO:     127.0.0.1:42380 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:58] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:58] INFO:     127.0.0.1:42386 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:58] Prefill batch, #new-seq: 1, #new-token: 1203, #cached-token: 16, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:15:58] Decode batch, #running-req: 1, #token: 1227, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.82, #queue-req: 0, 
[2025-12-17 20:15:58] INFO:     127.0.0.1:42390 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:15:59] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:00] INFO:     127.0.0.1:42394 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:00] Prefill batch, #new-seq: 1, #new-token: 1306, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:00] Decode batch, #running-req: 1, #token: 1322, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.61, #queue-req: 0, 
[2025-12-17 20:16:00] INFO:     127.0.0.1:42398 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:01] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:02] INFO:     127.0.0.1:42402 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:02] Prefill batch, #new-seq: 1, #new-token: 7, #cached-token: 1234, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:02] Decode batch, #running-req: 1, #token: 1244, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.54, #queue-req: 0, 
[2025-12-17 20:16:02] INFO:     127.0.0.1:42406 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:04] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:04] INFO:     127.0.0.1:42412 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:04] Prefill batch, #new-seq: 1, #new-token: 1327, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:04] INFO:     127.0.0.1:42416 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:05] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:06] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.10, #queue-req: 0, 
[2025-12-17 20:16:06] INFO:     127.0.0.1:42420 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:06] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 788, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:06] INFO:     127.0.0.1:42424 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:07] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:07] INFO:     127.0.0.1:42428 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:07] Prefill batch, #new-seq: 1, #new-token: 1236, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:07] Decode batch, #running-req: 1, #token: 1272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.26, #queue-req: 0, 
[2025-12-17 20:16:08] INFO:     127.0.0.1:42432 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:09] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:09] INFO:     127.0.0.1:42438 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:09] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:09] INFO:     127.0.0.1:42442 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:11] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:11] Decode batch, #running-req: 1, #token: 70, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.98, #queue-req: 0, 
[2025-12-17 20:16:11] INFO:     127.0.0.1:42448 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:11] Prefill batch, #new-seq: 1, #new-token: 7, #cached-token: 789, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:11] INFO:     127.0.0.1:42452 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:13] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:13] INFO:     127.0.0.1:42456 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:13] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 808, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:13] Decode batch, #running-req: 1, #token: 824, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.45, #queue-req: 0, 
[2025-12-17 20:16:13] INFO:     127.0.0.1:42460 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:15] Prefill batch, #new-seq: 1, #new-token: 65, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:15] INFO:     127.0.0.1:42464 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:15] Prefill batch, #new-seq: 1, #new-token: 30, #cached-token: 809, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:15] INFO:     127.0.0.1:42468 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:17] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:17] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.01, #queue-req: 0, 
[2025-12-17 20:16:17] INFO:     127.0.0.1:42474 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:17] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 810, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:17] INFO:     127.0.0.1:42478 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:19] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:19] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.46, #queue-req: 0, 
[2025-12-17 20:16:19] INFO:     127.0.0.1:42482 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:19] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 788, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:19] INFO:     127.0.0.1:42486 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:20] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:21] INFO:     127.0.0.1:42492 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:21] Prefill batch, #new-seq: 1, #new-token: 7, #cached-token: 791, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:21] INFO:     127.0.0.1:42496 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:21] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.43, #queue-req: 0, 
[2025-12-17 20:16:22] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:22] INFO:     127.0.0.1:42500 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:22] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 1212, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:23] INFO:     127.0.0.1:42504 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:24] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:24] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.99, #queue-req: 0, 
[2025-12-17 20:16:24] INFO:     127.0.0.1:42508 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:24] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 1212, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:24] INFO:     127.0.0.1:42512 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:26] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:26] INFO:     127.0.0.1:42516 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:26] Prefill batch, #new-seq: 1, #new-token: 1271, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:26] Decode batch, #running-req: 1, #token: 1294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.35, #queue-req: 0, 
[2025-12-17 20:16:26] INFO:     127.0.0.1:42520 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:28] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:28] INFO:     127.0.0.1:42524 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:28] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 826, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:28] INFO:     127.0.0.1:42528 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:30] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:30] INFO:     127.0.0.1:42532 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:30] Prefill batch, #new-seq: 1, #new-token: 1260, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:30] Decode batch, #running-req: 1, #token: 1273, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.82, #queue-req: 0, 
[2025-12-17 20:16:30] INFO:     127.0.0.1:42536 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:32] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:32] INFO:     127.0.0.1:42540 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:32] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 808, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:32] INFO:     127.0.0.1:42544 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:34] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:34] Decode batch, #running-req: 1, #token: 72, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.93, #queue-req: 0, 
[2025-12-17 20:16:34] INFO:     127.0.0.1:42548 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:34] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 827, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:34] Decode batch, #running-req: 1, #token: 866, token usage: 0.00, cuda graph: True, gen throughput (token/s): 176.22, #queue-req: 0, 
[2025-12-17 20:16:34] INFO:     127.0.0.1:42552 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:36] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:36] INFO:     127.0.0.1:42556 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:36] Prefill batch, #new-seq: 1, #new-token: 1171, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:36] INFO:     127.0.0.1:42560 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:37] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:37] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.93, #queue-req: 0, 
[2025-12-17 20:16:38] INFO:     127.0.0.1:42564 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:38] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 1212, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:38] INFO:     127.0.0.1:42568 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:39] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:39] Decode batch, #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.21, #queue-req: 0, 
[2025-12-17 20:16:39] INFO:     127.0.0.1:42574 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:39] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:39] INFO:     127.0.0.1:42578 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:41] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:41] INFO:     127.0.0.1:42582 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:41] Prefill batch, #new-seq: 1, #new-token: 1431, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:41] INFO:     127.0.0.1:42586 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:44] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:44] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.60, #queue-req: 0, 
[2025-12-17 20:16:44] INFO:     127.0.0.1:42590 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:44] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 1212, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:44] INFO:     127.0.0.1:42594 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:45] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:45] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.51, #queue-req: 0, 
[2025-12-17 20:16:46] INFO:     127.0.0.1:42598 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:46] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 786, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:46] INFO:     127.0.0.1:42602 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:47] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:47] Decode batch, #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.81, #queue-req: 0, 
[2025-12-17 20:16:47] INFO:     127.0.0.1:42606 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:47] Prefill batch, #new-seq: 1, #new-token: 1273, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:48] INFO:     127.0.0.1:42610 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:49] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:49] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.40, #queue-req: 0, 
[2025-12-17 20:16:49] INFO:     127.0.0.1:42614 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:49] Prefill batch, #new-seq: 1, #new-token: 1149, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:50] INFO:     127.0.0.1:42618 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:51] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:51] INFO:     127.0.0.1:42622 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:51] Prefill batch, #new-seq: 1, #new-token: 1171, #cached-token: 165, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:51] Decode batch, #running-req: 1, #token: 1340, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.16, #queue-req: 0, 
[2025-12-17 20:16:51] INFO:     127.0.0.1:42626 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:53] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:53] INFO:     127.0.0.1:42630 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:53] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 788, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:53] Decode batch, #running-req: 1, #token: 813, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.85, #queue-req: 0, 
[2025-12-17 20:16:53] INFO:     127.0.0.1:42634 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:55] Prefill batch, #new-seq: 1, #new-token: 61, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:55] INFO:     127.0.0.1:42640 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:55] Prefill batch, #new-seq: 1, #new-token: 26, #cached-token: 768, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:55] INFO:     127.0.0.1:42644 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:57] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:57] Decode batch, #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.33, #queue-req: 0, 
[2025-12-17 20:16:57] INFO:     127.0.0.1:42648 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:57] Prefill batch, #new-seq: 1, #new-token: 21, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:57] INFO:     127.0.0.1:42652 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:59] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:59] INFO:     127.0.0.1:42658 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:16:59] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 1211, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:16:59] Decode batch, #running-req: 1, #token: 1228, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.47, #queue-req: 0, 
[2025-12-17 20:16:59] INFO:     127.0.0.1:42662 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:01] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:01] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.92, #queue-req: 0, 
[2025-12-17 20:17:01] INFO:     127.0.0.1:42666 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:01] Prefill batch, #new-seq: 1, #new-token: 1232, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:01] Decode batch, #running-req: 1, #token: 1428, token usage: 0.00, cuda graph: True, gen throughput (token/s): 189.04, #queue-req: 0, 
[2025-12-17 20:17:01] INFO:     127.0.0.1:42670 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:03] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:03] INFO:     127.0.0.1:42674 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:03] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 840, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:03] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.78, #queue-req: 0, 
[2025-12-17 20:17:03] INFO:     127.0.0.1:42678 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:05] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:05] INFO:     127.0.0.1:42682 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:05] Prefill batch, #new-seq: 1, #new-token: 1191, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:05] INFO:     127.0.0.1:42686 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:07] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:07] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.14, #queue-req: 0, 
[2025-12-17 20:17:07] INFO:     127.0.0.1:42690 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:07] Prefill batch, #new-seq: 1, #new-token: 1189, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:07] INFO:     127.0.0.1:42694 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:09] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:09] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.75, #queue-req: 0, 
[2025-12-17 20:17:09] INFO:     127.0.0.1:42700 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:09] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 789, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:09] INFO:     127.0.0.1:42704 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:11] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:11] INFO:     127.0.0.1:42708 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:11] Prefill batch, #new-seq: 1, #new-token: 1029, #cached-token: 38, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:11] INFO:     127.0.0.1:42712 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:13] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:13] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.14, #queue-req: 0, 
[2025-12-17 20:17:13] INFO:     127.0.0.1:42716 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:13] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 789, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:13] INFO:     127.0.0.1:42720 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:15] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:15] INFO:     127.0.0.1:42724 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:15] Prefill batch, #new-seq: 1, #new-token: 941, #cached-token: 401, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:15] Decode batch, #running-req: 1, #token: 1356, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.07, #queue-req: 0, 
[2025-12-17 20:17:15] INFO:     127.0.0.1:42728 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:17] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:17] INFO:     127.0.0.1:42732 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:17] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:17] INFO:     127.0.0.1:42736 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:19] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:19] Decode batch, #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.90, #queue-req: 0, 
[2025-12-17 20:17:19] INFO:     127.0.0.1:42740 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:19] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 768, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:19] Decode batch, #running-req: 1, #token: 822, token usage: 0.00, cuda graph: True, gen throughput (token/s): 177.86, #queue-req: 0, 
[2025-12-17 20:17:19] INFO:     127.0.0.1:42744 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:21] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:21] INFO:     127.0.0.1:42750 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:21] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 789, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:21] INFO:     127.0.0.1:42754 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:23] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:23] INFO:     127.0.0.1:42758 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:23] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 1212, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:23] Decode batch, #running-req: 1, #token: 1235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.12, #queue-req: 0, 
[2025-12-17 20:17:23] INFO:     127.0.0.1:42762 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:25] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:25] Decode batch, #running-req: 1, #token: 101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.54, #queue-req: 0, 
[2025-12-17 20:17:25] INFO:     127.0.0.1:42766 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:25] Prefill batch, #new-seq: 1, #new-token: 976, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:25] INFO:     127.0.0.1:42770 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:27] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:27] INFO:     127.0.0.1:42774 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:27] Prefill batch, #new-seq: 1, #new-token: 1149, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:27] INFO:     127.0.0.1:42778 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:28] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:28] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.81, #queue-req: 0, 
[2025-12-17 20:17:28] INFO:     127.0.0.1:42782 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:29] Prefill batch, #new-seq: 1, #new-token: 21, #cached-token: 768, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:29] INFO:     127.0.0.1:42786 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:31] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:31] INFO:     127.0.0.1:42790 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:31] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:31] Decode batch, #running-req: 1, #token: 805, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.63, #queue-req: 0, 
[2025-12-17 20:17:31] INFO:     127.0.0.1:42794 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:33] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:33] Decode batch, #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.95, #queue-req: 0, 
[2025-12-17 20:17:33] INFO:     127.0.0.1:42800 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:33] Prefill batch, #new-seq: 1, #new-token: 1039, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:33] INFO:     127.0.0.1:42804 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:34] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:35] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.66, #queue-req: 0, 
[2025-12-17 20:17:35] INFO:     127.0.0.1:42808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:35] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 839, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:35] INFO:     127.0.0.1:42812 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:36] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:36] INFO:     127.0.0.1:42818 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:36] Prefill batch, #new-seq: 1, #new-token: 1275, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:37] INFO:     127.0.0.1:42822 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:38] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:38] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.90, #queue-req: 0, 
[2025-12-17 20:17:38] INFO:     127.0.0.1:42826 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:38] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 1212, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:38] INFO:     127.0.0.1:42830 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:40] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:40] Decode batch, #running-req: 1, #token: 70, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.21, #queue-req: 0, 
[2025-12-17 20:17:40] INFO:     127.0.0.1:42834 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:40] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 1288, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:40] INFO:     127.0.0.1:42838 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:42] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:42] INFO:     127.0.0.1:42844 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:42] Prefill batch, #new-seq: 1, #new-token: 1397, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:42] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.55, #queue-req: 0, 
[2025-12-17 20:17:42] INFO:     127.0.0.1:42848 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:44] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:44] INFO:     127.0.0.1:42852 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:44] Prefill batch, #new-seq: 1, #new-token: 1351, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:44] INFO:     127.0.0.1:42856 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:46] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:46] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.90, #queue-req: 0, 
[2025-12-17 20:17:46] INFO:     127.0.0.1:42860 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:46] Prefill batch, #new-seq: 1, #new-token: 1108, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:46] INFO:     127.0.0.1:42864 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:48] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:48] INFO:     127.0.0.1:42868 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:48] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 788, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:48] Decode batch, #running-req: 1, #token: 808, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.41, #queue-req: 0, 
[2025-12-17 20:17:48] INFO:     127.0.0.1:42874 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:50] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:50] INFO:     127.0.0.1:42878 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:50] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 788, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:50] INFO:     127.0.0.1:42882 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:52] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:52] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.10, #queue-req: 0, 
[2025-12-17 20:17:52] INFO:     127.0.0.1:42886 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:52] Prefill batch, #new-seq: 1, #new-token: 783, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:52] INFO:     127.0.0.1:42890 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:54] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:54] INFO:     127.0.0.1:42894 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:54] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 1214, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:54] INFO:     127.0.0.1:42898 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:54] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.32, #queue-req: 0, 
[2025-12-17 20:17:55] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:56] INFO:     127.0.0.1:42906 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:56] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 1213, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:56] INFO:     127.0.0.1:42910 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:57] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:57] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.90, #queue-req: 0, 
[2025-12-17 20:17:57] INFO:     127.0.0.1:42914 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:57] Prefill batch, #new-seq: 1, #new-token: 1248, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:58] INFO:     127.0.0.1:42918 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:59] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:17:59] INFO:     127.0.0.1:42924 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:17:59] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.57, #queue-req: 0, 
[2025-12-17 20:17:59] Prefill batch, #new-seq: 1, #new-token: 1204, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:00] Decode batch, #running-req: 1, #token: 1274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 187.27, #queue-req: 0, 
[2025-12-17 20:18:00] Decode batch, #running-req: 1, #token: 1314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:18:00] Decode batch, #running-req: 1, #token: 1354, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 20:18:00] Decode batch, #running-req: 1, #token: 1394, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.34, #queue-req: 0, 
[2025-12-17 20:18:00] Decode batch, #running-req: 1, #token: 1434, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.63, #queue-req: 0, 
[2025-12-17 20:18:00] Decode batch, #running-req: 1, #token: 1474, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 20:18:01] Decode batch, #running-req: 1, #token: 1514, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:18:01] Decode batch, #running-req: 1, #token: 1554, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 20:18:01] Decode batch, #running-req: 1, #token: 1594, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.08, #queue-req: 0, 
[2025-12-17 20:18:01] Decode batch, #running-req: 1, #token: 1634, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.31, #queue-req: 0, 
[2025-12-17 20:18:01] Decode batch, #running-req: 1, #token: 1674, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.35, #queue-req: 0, 
[2025-12-17 20:18:02] Decode batch, #running-req: 1, #token: 1714, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.46, #queue-req: 0, 
[2025-12-17 20:18:02] Decode batch, #running-req: 1, #token: 1754, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.33, #queue-req: 0, 
[2025-12-17 20:18:02] Decode batch, #running-req: 1, #token: 1794, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.28, #queue-req: 0, 
[2025-12-17 20:18:02] Decode batch, #running-req: 1, #token: 1834, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.23, #queue-req: 0, 
[2025-12-17 20:18:02] Decode batch, #running-req: 1, #token: 1874, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.34, #queue-req: 0, 
[2025-12-17 20:18:02] Decode batch, #running-req: 1, #token: 1914, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.21, #queue-req: 0, 
[2025-12-17 20:18:03] Decode batch, #running-req: 1, #token: 1954, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 20:18:03] Decode batch, #running-req: 1, #token: 1994, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:18:03] Decode batch, #running-req: 1, #token: 2034, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.45, #queue-req: 0, 
[2025-12-17 20:18:03] Decode batch, #running-req: 1, #token: 2074, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.21, #queue-req: 0, 
[2025-12-17 20:18:03] Decode batch, #running-req: 1, #token: 2114, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.90, #queue-req: 0, 
[2025-12-17 20:18:04] Decode batch, #running-req: 1, #token: 2154, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.00, #queue-req: 0, 
[2025-12-17 20:18:04] Decode batch, #running-req: 1, #token: 2194, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.78, #queue-req: 0, 
[2025-12-17 20:18:04] INFO:     127.0.0.1:42928 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:04] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.91, #queue-req: 0, 
[2025-12-17 20:18:06] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:06] INFO:     127.0.0.1:42936 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:06] Prefill batch, #new-seq: 1, #new-token: 1155, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:06] INFO:     127.0.0.1:42940 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:06] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.80, #queue-req: 0, 
[2025-12-17 20:18:08] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:08] INFO:     127.0.0.1:42944 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:08] Prefill batch, #new-seq: 1, #new-token: 1243, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:08] Decode batch, #running-req: 1, #token: 1272, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.68, #queue-req: 0, 
[2025-12-17 20:18:08] INFO:     127.0.0.1:42948 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:10] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:10] INFO:     127.0.0.1:42952 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:10] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 878, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:10] Decode batch, #running-req: 1, #token: 910, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.72, #queue-req: 0, 
[2025-12-17 20:18:10] INFO:     127.0.0.1:42956 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:11] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:12] INFO:     127.0.0.1:42960 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:12] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 825, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:12] Decode batch, #running-req: 1, #token: 860, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.83, #queue-req: 0, 
[2025-12-17 20:18:12] INFO:     127.0.0.1:42964 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:14] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:14] INFO:     127.0.0.1:42968 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:14] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 1212, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:14] INFO:     127.0.0.1:42972 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:16] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:16] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.01, #queue-req: 0, 
[2025-12-17 20:18:16] INFO:     127.0.0.1:42976 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:16] Prefill batch, #new-seq: 1, #new-token: 573, #cached-token: 222, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:16] INFO:     127.0.0.1:42980 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:18] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:18] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.61, #queue-req: 0, 
[2025-12-17 20:18:18] INFO:     127.0.0.1:42984 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:18] Prefill batch, #new-seq: 1, #new-token: 1141, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:18] INFO:     127.0.0.1:42988 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:19] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:19] INFO:     127.0.0.1:42992 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:19] Prefill batch, #new-seq: 1, #new-token: 1643, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:20] Decode batch, #running-req: 1, #token: 1686, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.25, #queue-req: 0, 
[2025-12-17 20:18:20] INFO:     127.0.0.1:42996 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:21] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:21] INFO:     127.0.0.1:43000 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:21] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:21] INFO:     127.0.0.1:43006 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:23] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:23] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.95, #queue-req: 0, 
[2025-12-17 20:18:23] INFO:     127.0.0.1:43010 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:23] Prefill batch, #new-seq: 1, #new-token: 1218, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:23] INFO:     127.0.0.1:43014 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:25] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:25] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.64, #queue-req: 0, 
[2025-12-17 20:18:25] INFO:     127.0.0.1:43020 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:25] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 789, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:25] INFO:     127.0.0.1:43024 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:27] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:27] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.74, #queue-req: 0, 
[2025-12-17 20:18:27] Decode batch, #running-req: 1, #token: 122, token usage: 0.00, cuda graph: True, gen throughput (token/s): 228.65, #queue-req: 0, 
[2025-12-17 20:18:27] Decode batch, #running-req: 1, #token: 162, token usage: 0.00, cuda graph: True, gen throughput (token/s): 227.23, #queue-req: 0, 
[2025-12-17 20:18:28] Decode batch, #running-req: 1, #token: 202, token usage: 0.00, cuda graph: True, gen throughput (token/s): 226.96, #queue-req: 0, 
[2025-12-17 20:18:28] Decode batch, #running-req: 1, #token: 242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 226.94, #queue-req: 0, 
[2025-12-17 20:18:28] Decode batch, #running-req: 1, #token: 282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 225.55, #queue-req: 0, 
[2025-12-17 20:18:28] Decode batch, #running-req: 1, #token: 322, token usage: 0.00, cuda graph: True, gen throughput (token/s): 224.42, #queue-req: 0, 
[2025-12-17 20:18:28] Decode batch, #running-req: 1, #token: 362, token usage: 0.00, cuda graph: True, gen throughput (token/s): 223.56, #queue-req: 0, 
[2025-12-17 20:18:28] Decode batch, #running-req: 1, #token: 402, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.87, #queue-req: 0, 
[2025-12-17 20:18:29] Decode batch, #running-req: 1, #token: 442, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.67, #queue-req: 0, 
[2025-12-17 20:18:29] Decode batch, #running-req: 1, #token: 482, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.82, #queue-req: 0, 
[2025-12-17 20:18:29] Decode batch, #running-req: 1, #token: 522, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.71, #queue-req: 0, 
[2025-12-17 20:18:29] Decode batch, #running-req: 1, #token: 562, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.59, #queue-req: 0, 
[2025-12-17 20:18:29] Decode batch, #running-req: 1, #token: 602, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.49, #queue-req: 0, 
[2025-12-17 20:18:30] Decode batch, #running-req: 1, #token: 642, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.45, #queue-req: 0, 
[2025-12-17 20:18:30] Decode batch, #running-req: 1, #token: 682, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.69, #queue-req: 0, 
[2025-12-17 20:18:30] Decode batch, #running-req: 1, #token: 722, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.39, #queue-req: 0, 
[2025-12-17 20:18:30] Decode batch, #running-req: 1, #token: 762, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.45, #queue-req: 0, 
[2025-12-17 20:18:30] Decode batch, #running-req: 1, #token: 802, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.41, #queue-req: 0, 
[2025-12-17 20:18:30] Decode batch, #running-req: 1, #token: 842, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.31, #queue-req: 0, 
[2025-12-17 20:18:31] Decode batch, #running-req: 1, #token: 882, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.25, #queue-req: 0, 
[2025-12-17 20:18:31] Decode batch, #running-req: 1, #token: 922, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.48, #queue-req: 0, 
[2025-12-17 20:18:31] Decode batch, #running-req: 1, #token: 962, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.56, #queue-req: 0, 
[2025-12-17 20:18:31] Decode batch, #running-req: 1, #token: 1002, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.46, #queue-req: 0, 
[2025-12-17 20:18:31] Decode batch, #running-req: 1, #token: 1042, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.14, #queue-req: 0, 
[2025-12-17 20:18:31] INFO:     127.0.0.1:43028 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:32] Prefill batch, #new-seq: 1, #new-token: 595, #cached-token: 224, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:32] Decode batch, #running-req: 1, #token: 828, token usage: 0.00, cuda graph: True, gen throughput (token/s): 189.79, #queue-req: 0, 
[2025-12-17 20:18:32] INFO:     127.0.0.1:43034 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:33] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:33] INFO:     127.0.0.1:43038 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:33] Prefill batch, #new-seq: 1, #new-token: 1170, #cached-token: 132, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:34] Decode batch, #running-req: 1, #token: 1318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.40, #queue-req: 0, 
[2025-12-17 20:18:34] INFO:     127.0.0.1:43042 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:35] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:35] INFO:     127.0.0.1:43046 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:35] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 767, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:35] Decode batch, #running-req: 1, #token: 798, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.67, #queue-req: 0, 
[2025-12-17 20:18:36] Decode batch, #running-req: 1, #token: 838, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.19, #queue-req: 0, 
[2025-12-17 20:18:36] Decode batch, #running-req: 1, #token: 878, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.37, #queue-req: 0, 
[2025-12-17 20:18:36] Decode batch, #running-req: 1, #token: 918, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.50, #queue-req: 0, 
[2025-12-17 20:18:36] Decode batch, #running-req: 1, #token: 958, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.68, #queue-req: 0, 
[2025-12-17 20:18:36] Decode batch, #running-req: 1, #token: 998, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.53, #queue-req: 0, 
[2025-12-17 20:18:37] Decode batch, #running-req: 1, #token: 1038, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.25, #queue-req: 0, 
[2025-12-17 20:18:37] Decode batch, #running-req: 1, #token: 1078, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.10, #queue-req: 0, 
[2025-12-17 20:18:37] Decode batch, #running-req: 1, #token: 1118, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.04, #queue-req: 0, 
[2025-12-17 20:18:37] Decode batch, #running-req: 1, #token: 1158, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.99, #queue-req: 0, 
[2025-12-17 20:18:37] Decode batch, #running-req: 1, #token: 1198, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.92, #queue-req: 0, 
[2025-12-17 20:18:37] Decode batch, #running-req: 1, #token: 1238, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:18:38] Decode batch, #running-req: 1, #token: 1278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.99, #queue-req: 0, 
[2025-12-17 20:18:38] Decode batch, #running-req: 1, #token: 1318, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:18:38] Decode batch, #running-req: 1, #token: 1358, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:18:38] Decode batch, #running-req: 1, #token: 1398, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:18:38] Decode batch, #running-req: 1, #token: 1438, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.97, #queue-req: 0, 
[2025-12-17 20:18:39] Decode batch, #running-req: 1, #token: 1478, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.92, #queue-req: 0, 
[2025-12-17 20:18:39] Decode batch, #running-req: 1, #token: 1518, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:18:39] Decode batch, #running-req: 1, #token: 1558, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:18:39] Decode batch, #running-req: 1, #token: 1598, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:18:39] Decode batch, #running-req: 1, #token: 1638, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:18:39] Decode batch, #running-req: 1, #token: 1678, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:18:40] Decode batch, #running-req: 1, #token: 1718, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:18:40] Decode batch, #running-req: 1, #token: 1758, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:18:40] INFO:     127.0.0.1:43050 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:42] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:42] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.98, #queue-req: 0, 
[2025-12-17 20:18:42] INFO:     127.0.0.1:43056 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:42] Prefill batch, #new-seq: 1, #new-token: 1379, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:42] INFO:     127.0.0.1:43060 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:44] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:44] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.91, #queue-req: 0, 
[2025-12-17 20:18:44] INFO:     127.0.0.1:43064 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:44] Prefill batch, #new-seq: 1, #new-token: 1024, #cached-token: 317, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:44] INFO:     127.0.0.1:43068 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:45] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:46] INFO:     127.0.0.1:43072 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:46] Prefill batch, #new-seq: 1, #new-token: 1149, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:46] Decode batch, #running-req: 1, #token: 1188, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.39, #queue-req: 0, 
[2025-12-17 20:18:46] INFO:     127.0.0.1:43076 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:47] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:47] INFO:     127.0.0.1:43080 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:47] Prefill batch, #new-seq: 1, #new-token: 1352, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:47] INFO:     127.0.0.1:43084 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:49] Prefill batch, #new-seq: 1, #new-token: 62, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:49] INFO:     127.0.0.1:43088 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:49] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.74, #queue-req: 0, 
[2025-12-17 20:18:49] Prefill batch, #new-seq: 1, #new-token: 1258, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:49] INFO:     127.0.0.1:43092 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:51] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:51] INFO:     127.0.0.1:43096 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:51] Prefill batch, #new-seq: 1, #new-token: 1259, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:51] Decode batch, #running-req: 1, #token: 1300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.18, #queue-req: 0, 
[2025-12-17 20:18:51] INFO:     127.0.0.1:43100 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:53] Prefill batch, #new-seq: 1, #new-token: 65, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:53] INFO:     127.0.0.1:43106 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:53] Prefill batch, #new-seq: 1, #new-token: 1390, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:54] INFO:     127.0.0.1:43110 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:56] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:56] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.34, #queue-req: 0, 
[2025-12-17 20:18:56] INFO:     127.0.0.1:43114 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:56] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:56] Decode batch, #running-req: 1, #token: 839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 186.58, #queue-req: 0, 
[2025-12-17 20:18:56] INFO:     127.0.0.1:43118 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:58] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:58] INFO:     127.0.0.1:43122 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:58] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 789, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:58] INFO:     127.0.0.1:43126 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:59] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:18:59] INFO:     127.0.0.1:43130 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:18:59] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.03, #queue-req: 0, 
[2025-12-17 20:18:59] Prefill batch, #new-seq: 1, #new-token: 25, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:00] Decode batch, #running-req: 1, #token: 853, token usage: 0.00, cuda graph: True, gen throughput (token/s): 195.79, #queue-req: 0, 
[2025-12-17 20:19:00] INFO:     127.0.0.1:43134 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:01] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:02] Decode batch, #running-req: 1, #token: 102, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.66, #queue-req: 0, 
[2025-12-17 20:19:02] Decode batch, #running-req: 1, #token: 142, token usage: 0.00, cuda graph: True, gen throughput (token/s): 226.35, #queue-req: 0, 
[2025-12-17 20:19:02] Decode batch, #running-req: 1, #token: 182, token usage: 0.00, cuda graph: True, gen throughput (token/s): 226.06, #queue-req: 0, 
[2025-12-17 20:19:02] Decode batch, #running-req: 1, #token: 222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 225.96, #queue-req: 0, 
[2025-12-17 20:19:02] Decode batch, #running-req: 1, #token: 262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 225.80, #queue-req: 0, 
[2025-12-17 20:19:02] Decode batch, #running-req: 1, #token: 302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 223.47, #queue-req: 0, 
[2025-12-17 20:19:03] Decode batch, #running-req: 1, #token: 342, token usage: 0.00, cuda graph: True, gen throughput (token/s): 223.26, #queue-req: 0, 
[2025-12-17 20:19:03] Decode batch, #running-req: 1, #token: 382, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.32, #queue-req: 0, 
[2025-12-17 20:19:03] Decode batch, #running-req: 1, #token: 422, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.74, #queue-req: 0, 
[2025-12-17 20:19:03] Decode batch, #running-req: 1, #token: 462, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.81, #queue-req: 0, 
[2025-12-17 20:19:03] Decode batch, #running-req: 1, #token: 502, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.79, #queue-req: 0, 
[2025-12-17 20:19:04] Decode batch, #running-req: 1, #token: 542, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.61, #queue-req: 0, 
[2025-12-17 20:19:04] Decode batch, #running-req: 1, #token: 582, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.61, #queue-req: 0, 
[2025-12-17 20:19:04] Decode batch, #running-req: 1, #token: 622, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.65, #queue-req: 0, 
[2025-12-17 20:19:04] Decode batch, #running-req: 1, #token: 662, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.47, #queue-req: 0, 
[2025-12-17 20:19:04] Decode batch, #running-req: 1, #token: 702, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.56, #queue-req: 0, 
[2025-12-17 20:19:04] Decode batch, #running-req: 1, #token: 742, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.61, #queue-req: 0, 
[2025-12-17 20:19:05] Decode batch, #running-req: 1, #token: 782, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.54, #queue-req: 0, 
[2025-12-17 20:19:05] Decode batch, #running-req: 1, #token: 822, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.50, #queue-req: 0, 
[2025-12-17 20:19:05] Decode batch, #running-req: 1, #token: 862, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.54, #queue-req: 0, 
[2025-12-17 20:19:05] Decode batch, #running-req: 1, #token: 902, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.49, #queue-req: 0, 
[2025-12-17 20:19:05] Decode batch, #running-req: 1, #token: 942, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.67, #queue-req: 0, 
[2025-12-17 20:19:06] Decode batch, #running-req: 1, #token: 982, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.69, #queue-req: 0, 
[2025-12-17 20:19:06] Decode batch, #running-req: 1, #token: 1022, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.52, #queue-req: 0, 
[2025-12-17 20:19:06] Decode batch, #running-req: 1, #token: 1062, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.04, #queue-req: 0, 
[2025-12-17 20:19:06] INFO:     127.0.0.1:43138 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:06] Prefill batch, #new-seq: 1, #new-token: 587, #cached-token: 85, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:06] INFO:     127.0.0.1:43142 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:08] Prefill batch, #new-seq: 1, #new-token: 62, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:08] Decode batch, #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.67, #queue-req: 0, 
[2025-12-17 20:19:08] INFO:     127.0.0.1:43146 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:08] Prefill batch, #new-seq: 1, #new-token: 1011, #cached-token: 109, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:08] INFO:     127.0.0.1:43150 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:10] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:10] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.45, #queue-req: 0, 
[2025-12-17 20:19:10] INFO:     127.0.0.1:43154 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:10] Prefill batch, #new-seq: 1, #new-token: 1002, #cached-token: 328, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:10] INFO:     127.0.0.1:43158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:12] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:12] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.32, #queue-req: 0, 
[2025-12-17 20:19:12] INFO:     127.0.0.1:43162 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:12] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 839, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:12] INFO:     127.0.0.1:43166 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:14] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:14] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.00, #queue-req: 0, 
[2025-12-17 20:19:14] INFO:     127.0.0.1:43172 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:14] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 1213, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:14] INFO:     127.0.0.1:43176 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:16] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:16] INFO:     127.0.0.1:43182 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:16] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 808, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:16] Decode batch, #running-req: 1, #token: 825, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.17, #queue-req: 0, 
[2025-12-17 20:19:16] INFO:     127.0.0.1:43186 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:18] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:18] INFO:     127.0.0.1:43190 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:18] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:18] Decode batch, #running-req: 1, #token: 802, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.15, #queue-req: 0, 
[2025-12-17 20:19:18] INFO:     127.0.0.1:43194 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:20] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:20] INFO:     127.0.0.1:43198 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:20] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 768, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:20] Decode batch, #running-req: 1, #token: 799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.76, #queue-req: 0, 
[2025-12-17 20:19:20] INFO:     127.0.0.1:43202 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:22] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:22] INFO:     127.0.0.1:43208 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:22] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 1214, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:22] INFO:     127.0.0.1:43212 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:24] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:24] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.09, #queue-req: 0, 
[2025-12-17 20:19:24] INFO:     127.0.0.1:43216 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:24] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 767, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:24] INFO:     127.0.0.1:43220 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:26] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:26] INFO:     127.0.0.1:43224 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:26] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 1313, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:26] Decode batch, #running-req: 1, #token: 1331, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.35, #queue-req: 0, 
[2025-12-17 20:19:26] INFO:     127.0.0.1:43228 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:26] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.37, #queue-req: 0, 
[2025-12-17 20:19:28] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:28] INFO:     127.0.0.1:43236 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:28] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 788, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:28] INFO:     127.0.0.1:43240 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:30] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:30] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.85, #queue-req: 0, 
[2025-12-17 20:19:30] INFO:     127.0.0.1:43244 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:30] Prefill batch, #new-seq: 1, #new-token: 498, #cached-token: 285, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:30] INFO:     127.0.0.1:43248 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:32] Prefill batch, #new-seq: 1, #new-token: 63, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:32] INFO:     127.0.0.1:43252 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:32] Prefill batch, #new-seq: 1, #new-token: 30, #cached-token: 808, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:32] Decode batch, #running-req: 1, #token: 842, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.44, #queue-req: 0, 
[2025-12-17 20:19:32] INFO:     127.0.0.1:43256 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:34] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:34] INFO:     127.0.0.1:43260 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:34] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:34] Decode batch, #running-req: 1, #token: 820, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.78, #queue-req: 0, 
[2025-12-17 20:19:34] Decode batch, #running-req: 1, #token: 860, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.55, #queue-req: 0, 
[2025-12-17 20:19:34] Decode batch, #running-req: 1, #token: 900, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.01, #queue-req: 0, 
[2025-12-17 20:19:34] Decode batch, #running-req: 1, #token: 940, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.38, #queue-req: 0, 
[2025-12-17 20:19:34] Decode batch, #running-req: 1, #token: 980, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.25, #queue-req: 0, 
[2025-12-17 20:19:35] Decode batch, #running-req: 1, #token: 1020, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.09, #queue-req: 0, 
[2025-12-17 20:19:35] Decode batch, #running-req: 1, #token: 1060, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:19:35] Decode batch, #running-req: 1, #token: 1100, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:19:35] Decode batch, #running-req: 1, #token: 1140, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 20:19:35] Decode batch, #running-req: 1, #token: 1180, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.46, #queue-req: 0, 
[2025-12-17 20:19:36] Decode batch, #running-req: 1, #token: 1220, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.55, #queue-req: 0, 
[2025-12-17 20:19:36] Decode batch, #running-req: 1, #token: 1260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:19:36] Decode batch, #running-req: 1, #token: 1300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.45, #queue-req: 0, 
[2025-12-17 20:19:36] Decode batch, #running-req: 1, #token: 1340, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.55, #queue-req: 0, 
[2025-12-17 20:19:36] Decode batch, #running-req: 1, #token: 1380, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 20:19:36] Decode batch, #running-req: 1, #token: 1420, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 20:19:37] Decode batch, #running-req: 1, #token: 1460, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:19:37] Decode batch, #running-req: 1, #token: 1500, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 20:19:37] Decode batch, #running-req: 1, #token: 1540, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.92, #queue-req: 0, 
[2025-12-17 20:19:37] Decode batch, #running-req: 1, #token: 1580, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:19:37] Decode batch, #running-req: 1, #token: 1620, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 20:19:38] Decode batch, #running-req: 1, #token: 1660, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.40, #queue-req: 0, 
[2025-12-17 20:19:38] Decode batch, #running-req: 1, #token: 1700, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.35, #queue-req: 0, 
[2025-12-17 20:19:38] Decode batch, #running-req: 1, #token: 1740, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 20:19:38] Decode batch, #running-req: 1, #token: 1780, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.29, #queue-req: 0, 
[2025-12-17 20:19:38] INFO:     127.0.0.1:43264 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:40] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:40] INFO:     127.0.0.1:43270 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:40] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 786, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:40] Decode batch, #running-req: 1, #token: 807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.15, #queue-req: 0, 
[2025-12-17 20:19:40] INFO:     127.0.0.1:43274 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:42] Prefill batch, #new-seq: 1, #new-token: 61, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:42] INFO:     127.0.0.1:43280 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:42] Prefill batch, #new-seq: 1, #new-token: 29, #cached-token: 768, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:42] Decode batch, #running-req: 1, #token: 804, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.59, #queue-req: 0, 
[2025-12-17 20:19:42] INFO:     127.0.0.1:43284 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:44] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:44] INFO:     127.0.0.1:43288 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:44] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 789, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:44] INFO:     127.0.0.1:43292 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:44] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.41, #queue-req: 0, 
[2025-12-17 20:19:46] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:46] INFO:     127.0.0.1:43298 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:46] Prefill batch, #new-seq: 1, #new-token: 1199, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:46] INFO:     127.0.0.1:43302 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:48] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:48] Decode batch, #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.91, #queue-req: 0, 
[2025-12-17 20:19:48] INFO:     127.0.0.1:43306 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:48] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 789, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:48] INFO:     127.0.0.1:43310 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:50] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:50] Decode batch, #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.09, #queue-req: 0, 
[2025-12-17 20:19:50] INFO:     127.0.0.1:43314 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:50] Prefill batch, #new-seq: 1, #new-token: 833, #cached-token: 318, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:50] INFO:     127.0.0.1:43318 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:52] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:52] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.70, #queue-req: 0, 
[2025-12-17 20:19:52] INFO:     127.0.0.1:43322 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:52] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 789, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:52] INFO:     127.0.0.1:43326 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:54] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:54] INFO:     127.0.0.1:43330 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:54] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 788, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:54] Decode batch, #running-req: 1, #token: 810, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.37, #queue-req: 0, 
[2025-12-17 20:19:54] INFO:     127.0.0.1:43334 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:56] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:56] INFO:     127.0.0.1:43338 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:56] Prefill batch, #new-seq: 1, #new-token: 956, #cached-token: 124, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:56] Decode batch, #running-req: 1, #token: 1084, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.59, #queue-req: 0, 
[2025-12-17 20:19:56] INFO:     127.0.0.1:43342 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:58] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:58] INFO:     127.0.0.1:43346 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:19:58] Prefill batch, #new-seq: 1, #new-token: 23, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:19:58] Decode batch, #running-req: 1, #token: 820, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.63, #queue-req: 0, 
[2025-12-17 20:19:58] Decode batch, #running-req: 1, #token: 860, token usage: 0.00, cuda graph: True, gen throughput (token/s): 208.93, #queue-req: 0, 
[2025-12-17 20:19:58] Decode batch, #running-req: 1, #token: 900, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.46, #queue-req: 0, 
[2025-12-17 20:19:58] Decode batch, #running-req: 1, #token: 940, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.52, #queue-req: 0, 
[2025-12-17 20:19:59] Decode batch, #running-req: 1, #token: 980, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.52, #queue-req: 0, 
[2025-12-17 20:19:59] Decode batch, #running-req: 1, #token: 1020, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.59, #queue-req: 0, 
[2025-12-17 20:19:59] Decode batch, #running-req: 1, #token: 1060, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.15, #queue-req: 0, 
[2025-12-17 20:19:59] Decode batch, #running-req: 1, #token: 1100, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.92, #queue-req: 0, 
[2025-12-17 20:19:59] Decode batch, #running-req: 1, #token: 1140, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:19:59] Decode batch, #running-req: 1, #token: 1180, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:20:00] Decode batch, #running-req: 1, #token: 1220, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:20:00] Decode batch, #running-req: 1, #token: 1260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:20:00] Decode batch, #running-req: 1, #token: 1300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:20:00] Decode batch, #running-req: 1, #token: 1340, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 20:20:00] Decode batch, #running-req: 1, #token: 1380, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:20:01] Decode batch, #running-req: 1, #token: 1420, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.97, #queue-req: 0, 
[2025-12-17 20:20:01] Decode batch, #running-req: 1, #token: 1460, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:20:01] Decode batch, #running-req: 1, #token: 1500, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.13, #queue-req: 0, 
[2025-12-17 20:20:01] Decode batch, #running-req: 1, #token: 1540, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:20:01] Decode batch, #running-req: 1, #token: 1580, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:20:01] Decode batch, #running-req: 1, #token: 1620, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:20:02] Decode batch, #running-req: 1, #token: 1660, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.55, #queue-req: 0, 
[2025-12-17 20:20:02] Decode batch, #running-req: 1, #token: 1700, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:20:02] Decode batch, #running-req: 1, #token: 1740, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:20:02] Decode batch, #running-req: 1, #token: 1780, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:20:02] INFO:     127.0.0.1:43350 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:04] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:04] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.84, #queue-req: 0, 
[2025-12-17 20:20:04] INFO:     127.0.0.1:43354 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:04] Prefill batch, #new-seq: 1, #new-token: 564, #cached-token: 222, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:04] INFO:     127.0.0.1:43358 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:06] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:06] INFO:     127.0.0.1:43362 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:06] Prefill batch, #new-seq: 1, #new-token: 1122, #cached-token: 135, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:06] Decode batch, #running-req: 1, #token: 1261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.44, #queue-req: 0, 
[2025-12-17 20:20:06] INFO:     127.0.0.1:43366 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:08] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:08] INFO:     127.0.0.1:43370 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:08] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:08] Decode batch, #running-req: 1, #token: 813, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.83, #queue-req: 0, 
[2025-12-17 20:20:08] INFO:     127.0.0.1:43374 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:10] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:10] INFO:     127.0.0.1:43380 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:10] Prefill batch, #new-seq: 1, #new-token: 1111, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:10] Decode batch, #running-req: 1, #token: 1268, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.34, #queue-req: 0, 
[2025-12-17 20:20:10] INFO:     127.0.0.1:43384 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:12] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:12] INFO:     127.0.0.1:43388 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:12] Prefill batch, #new-seq: 1, #new-token: 1188, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:12] Decode batch, #running-req: 1, #token: 1245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.51, #queue-req: 0, 
[2025-12-17 20:20:12] INFO:     127.0.0.1:43392 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:14] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:14] INFO:     127.0.0.1:43396 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:14] Prefill batch, #new-seq: 1, #new-token: 1109, #cached-token: 156, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:14] Decode batch, #running-req: 1, #token: 1280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.55, #queue-req: 0, 
[2025-12-17 20:20:14] INFO:     127.0.0.1:43400 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:16] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:16] INFO:     127.0.0.1:43404 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:16] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 786, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:16] Decode batch, #running-req: 1, #token: 809, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.51, #queue-req: 0, 
[2025-12-17 20:20:16] Decode batch, #running-req: 1, #token: 849, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.64, #queue-req: 0, 
[2025-12-17 20:20:16] Decode batch, #running-req: 1, #token: 889, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.41, #queue-req: 0, 
[2025-12-17 20:20:16] Decode batch, #running-req: 1, #token: 929, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.50, #queue-req: 0, 
[2025-12-17 20:20:17] Decode batch, #running-req: 1, #token: 969, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.59, #queue-req: 0, 
[2025-12-17 20:20:17] Decode batch, #running-req: 1, #token: 1009, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.38, #queue-req: 0, 
[2025-12-17 20:20:17] Decode batch, #running-req: 1, #token: 1049, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.29, #queue-req: 0, 
[2025-12-17 20:20:17] Decode batch, #running-req: 1, #token: 1089, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:20:17] Decode batch, #running-req: 1, #token: 1129, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.90, #queue-req: 0, 
[2025-12-17 20:20:17] Decode batch, #running-req: 1, #token: 1169, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.90, #queue-req: 0, 
[2025-12-17 20:20:18] Decode batch, #running-req: 1, #token: 1209, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.92, #queue-req: 0, 
[2025-12-17 20:20:18] Decode batch, #running-req: 1, #token: 1249, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:20:18] Decode batch, #running-req: 1, #token: 1289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.94, #queue-req: 0, 
[2025-12-17 20:20:18] Decode batch, #running-req: 1, #token: 1329, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:20:18] Decode batch, #running-req: 1, #token: 1369, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:20:19] Decode batch, #running-req: 1, #token: 1409, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:20:19] Decode batch, #running-req: 1, #token: 1449, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.08, #queue-req: 0, 
[2025-12-17 20:20:19] Decode batch, #running-req: 1, #token: 1489, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:20:19] Decode batch, #running-req: 1, #token: 1529, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.98, #queue-req: 0, 
[2025-12-17 20:20:19] Decode batch, #running-req: 1, #token: 1569, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:20:19] Decode batch, #running-req: 1, #token: 1609, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:20:20] Decode batch, #running-req: 1, #token: 1649, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:20:20] Decode batch, #running-req: 1, #token: 1689, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:20:20] Decode batch, #running-req: 1, #token: 1729, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:20:20] Decode batch, #running-req: 1, #token: 1769, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:20:20] INFO:     127.0.0.1:43408 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:22] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:22] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.80, #queue-req: 0, 
[2025-12-17 20:20:22] INFO:     127.0.0.1:43414 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:22] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 1214, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:22] INFO:     127.0.0.1:43418 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:24] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:24] INFO:     127.0.0.1:43422 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:24] Prefill batch, #new-seq: 1, #new-token: 1024, #cached-token: 99, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:24] INFO:     127.0.0.1:43426 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:26] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:26] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.63, #queue-req: 0, 
[2025-12-17 20:20:26] INFO:     127.0.0.1:43430 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:26] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 1313, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:26] INFO:     127.0.0.1:43434 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:28] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:28] Decode batch, #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.46, #queue-req: 0, 
[2025-12-17 20:20:28] INFO:     127.0.0.1:43438 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:28] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 789, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:28] INFO:     127.0.0.1:43442 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:30] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:30] INFO:     127.0.0.1:43446 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:30] Prefill batch, #new-seq: 1, #new-token: 1191, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:30] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.30, #queue-req: 0, 
[2025-12-17 20:20:30] INFO:     127.0.0.1:43450 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:31] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:32] INFO:     127.0.0.1:43454 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:32] Prefill batch, #new-seq: 1, #new-token: 1017, #cached-token: 280, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:32] INFO:     127.0.0.1:43458 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:33] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:33] INFO:     127.0.0.1:43462 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:33] Prefill batch, #new-seq: 1, #new-token: 29, #cached-token: 1190, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:33] Decode batch, #running-req: 1, #token: 1227, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.90, #queue-req: 0, 
[2025-12-17 20:20:33] INFO:     127.0.0.1:43466 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:35] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:36] INFO:     127.0.0.1:43470 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:36] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 765, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:36] INFO:     127.0.0.1:43474 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:37] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:37] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.04, #queue-req: 0, 
[2025-12-17 20:20:37] INFO:     127.0.0.1:43478 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:37] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 766, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:38] INFO:     127.0.0.1:43482 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:39] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:39] INFO:     127.0.0.1:43486 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:39] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 766, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:39] Decode batch, #running-req: 1, #token: 805, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.29, #queue-req: 0, 
[2025-12-17 20:20:39] INFO:     127.0.0.1:43490 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:41] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:41] INFO:     127.0.0.1:43496 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:41] Prefill batch, #new-seq: 1, #new-token: 1091, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:41] INFO:     127.0.0.1:43500 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:43] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:43] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.77, #queue-req: 0, 
[2025-12-17 20:20:43] INFO:     127.0.0.1:43504 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:43] Prefill batch, #new-seq: 1, #new-token: 1253, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:43] INFO:     127.0.0.1:43508 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:45] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:45] INFO:     127.0.0.1:43512 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:45] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 766, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:45] Decode batch, #running-req: 1, #token: 826, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.03, #queue-req: 0, 
[2025-12-17 20:20:45] INFO:     127.0.0.1:43516 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:47] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:47] INFO:     127.0.0.1:43522 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:47] Prefill batch, #new-seq: 1, #new-token: 989, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:47] Decode batch, #running-req: 1, #token: 1038, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.80, #queue-req: 0, 
[2025-12-17 20:20:47] INFO:     127.0.0.1:43526 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:49] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:49] INFO:     127.0.0.1:43530 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:49] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 766, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:49] INFO:     127.0.0.1:43534 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:51] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:52] Decode batch, #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.61, #queue-req: 0, 
[2025-12-17 20:20:52] INFO:     127.0.0.1:43538 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:52] Prefill batch, #new-seq: 1, #new-token: 1156, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:52] INFO:     127.0.0.1:43542 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:53] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:53] INFO:     127.0.0.1:43546 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:53] Prefill batch, #new-seq: 1, #new-token: 1302, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:53] INFO:     127.0.0.1:43550 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:55] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:55] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.72, #queue-req: 0, 
[2025-12-17 20:20:55] INFO:     127.0.0.1:43554 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:55] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 786, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:55] INFO:     127.0.0.1:43558 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:57] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:57] INFO:     127.0.0.1:43562 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:57] Prefill batch, #new-seq: 1, #new-token: 1167, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:57] Decode batch, #running-req: 1, #token: 1208, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.36, #queue-req: 0, 
[2025-12-17 20:20:57] INFO:     127.0.0.1:43566 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:59] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:59] INFO:     127.0.0.1:43570 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:20:59] Prefill batch, #new-seq: 1, #new-token: 1533, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:20:59] INFO:     127.0.0.1:43574 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:01] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:01] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.99, #queue-req: 0, 
[2025-12-17 20:21:01] INFO:     127.0.0.1:43578 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:01] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 765, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:01] INFO:     127.0.0.1:43582 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:03] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:03] INFO:     127.0.0.1:43586 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:03] Prefill batch, #new-seq: 1, #new-token: 1027, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:03] Decode batch, #running-req: 1, #token: 1048, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.81, #queue-req: 0, 
[2025-12-17 20:21:03] INFO:     127.0.0.1:43590 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:05] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:06] INFO:     127.0.0.1:43596 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:06] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 765, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:06] INFO:     127.0.0.1:43600 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:07] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:07] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.16, #queue-req: 0, 
[2025-12-17 20:21:07] INFO:     127.0.0.1:43604 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:07] Prefill batch, #new-seq: 1, #new-token: 1331, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:07] INFO:     127.0.0.1:43608 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:09] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:09] INFO:     127.0.0.1:43612 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:09] Prefill batch, #new-seq: 1, #new-token: 30, #cached-token: 766, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:09] INFO:     127.0.0.1:43616 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:11] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:11] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.81, #queue-req: 0, 
[2025-12-17 20:21:11] INFO:     127.0.0.1:43620 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:11] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 1190, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:11] INFO:     127.0.0.1:43624 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:13] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:13] INFO:     127.0.0.1:43630 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:13] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 1191, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:13] Decode batch, #running-req: 1, #token: 1234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.52, #queue-req: 0, 
[2025-12-17 20:21:13] INFO:     127.0.0.1:43634 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:15] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:15] INFO:     127.0.0.1:43640 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:15] Prefill batch, #new-seq: 1, #new-token: 1184, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:15] INFO:     127.0.0.1:43644 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:17] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:17] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.00, #queue-req: 0, 
[2025-12-17 20:21:17] INFO:     127.0.0.1:43648 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:17] Prefill batch, #new-seq: 1, #new-token: 1019, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:17] INFO:     127.0.0.1:43652 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:19] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:19] Decode batch, #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.55, #queue-req: 0, 
[2025-12-17 20:21:19] INFO:     127.0.0.1:43660 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:19] Prefill batch, #new-seq: 1, #new-token: 1352, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:19] INFO:     127.0.0.1:43664 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:20] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:21] INFO:     127.0.0.1:43668 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:21] Prefill batch, #new-seq: 1, #new-token: 496, #cached-token: 287, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:21] Decode batch, #running-req: 1, #token: 792, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.55, #queue-req: 0, 
[2025-12-17 20:21:21] INFO:     127.0.0.1:43672 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:22] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:22] INFO:     127.0.0.1:43676 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:22] Prefill batch, #new-seq: 1, #new-token: 1223, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:22] INFO:     127.0.0.1:43680 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:24] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:24] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.82, #queue-req: 0, 
[2025-12-17 20:21:24] INFO:     127.0.0.1:43684 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:24] Prefill batch, #new-seq: 1, #new-token: 1203, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:24] INFO:     127.0.0.1:43688 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:26] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:26] INFO:     127.0.0.1:43694 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:26] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 1192, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:26] Decode batch, #running-req: 1, #token: 1234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.39, #queue-req: 0, 
[2025-12-17 20:21:26] INFO:     127.0.0.1:43698 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:28] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:28] INFO:     127.0.0.1:43702 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:28] Prefill batch, #new-seq: 1, #new-token: 1470, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:28] INFO:     127.0.0.1:43706 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:30] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:30] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.83, #queue-req: 0, 
[2025-12-17 20:21:30] INFO:     127.0.0.1:43710 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:30] Prefill batch, #new-seq: 1, #new-token: 1199, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:30] INFO:     127.0.0.1:43714 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:32] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:32] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.51, #queue-req: 0, 
[2025-12-17 20:21:32] INFO:     127.0.0.1:43722 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:32] Prefill batch, #new-seq: 1, #new-token: 1383, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:32] INFO:     127.0.0.1:43726 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:34] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:34] INFO:     127.0.0.1:43730 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:34] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 786, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:34] Decode batch, #running-req: 1, #token: 827, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.34, #queue-req: 0, 
[2025-12-17 20:21:34] INFO:     127.0.0.1:43734 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:36] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:36] INFO:     127.0.0.1:43738 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:36] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 767, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:36] Decode batch, #running-req: 1, #token: 820, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.01, #queue-req: 0, 
[2025-12-17 20:21:36] INFO:     127.0.0.1:43742 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:37] Prefill batch, #new-seq: 1, #new-token: 60, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:38] INFO:     127.0.0.1:43746 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:38] Prefill batch, #new-seq: 1, #new-token: 1243, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:38] INFO:     127.0.0.1:43750 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:39] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:39] Decode batch, #running-req: 1, #token: 100, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.91, #queue-req: 0, 
[2025-12-17 20:21:39] INFO:     127.0.0.1:43754 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:39] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 1162, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:40] INFO:     127.0.0.1:43758 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:41] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:41] INFO:     127.0.0.1:43762 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:41] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 766, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:41] Decode batch, #running-req: 1, #token: 815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.18, #queue-req: 0, 
[2025-12-17 20:21:41] INFO:     127.0.0.1:43766 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:43] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:43] INFO:     127.0.0.1:43770 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:43] Prefill batch, #new-seq: 1, #new-token: 795, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:43] INFO:     127.0.0.1:43774 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:45] Prefill batch, #new-seq: 1, #new-token: 61, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:45] Decode batch, #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.92, #queue-req: 0, 
[2025-12-17 20:21:45] INFO:     127.0.0.1:43778 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:45] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 767, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:45] INFO:     127.0.0.1:43782 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:47] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:47] INFO:     127.0.0.1:43786 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:47] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 1190, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:47] Decode batch, #running-req: 1, #token: 1233, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.22, #queue-req: 0, 
[2025-12-17 20:21:47] INFO:     127.0.0.1:43790 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:49] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:49] INFO:     127.0.0.1:43794 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:49] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 1191, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:49] INFO:     127.0.0.1:43798 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:51] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:51] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.94, #queue-req: 0, 
[2025-12-17 20:21:51] INFO:     127.0.0.1:43804 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:51] Prefill batch, #new-seq: 1, #new-token: 934, #cached-token: 131, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:51] INFO:     127.0.0.1:43808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:53] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:53] INFO:     127.0.0.1:43812 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:53] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 766, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:53] Decode batch, #running-req: 1, #token: 807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.27, #queue-req: 0, 
[2025-12-17 20:21:53] INFO:     127.0.0.1:43816 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:55] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:55] INFO:     127.0.0.1:43820 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:55] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:55] INFO:     127.0.0.1:43824 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:57] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:57] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.13, #queue-req: 0, 
[2025-12-17 20:21:57] INFO:     127.0.0.1:43828 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:57] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 1286, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:57] INFO:     127.0.0.1:43832 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:58] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:59] INFO:     127.0.0.1:43836 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:21:59] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 1267, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:21:59] Decode batch, #running-req: 1, #token: 1311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.34, #queue-req: 0, 
[2025-12-17 20:21:59] INFO:     127.0.0.1:43840 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:00] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:00] INFO:     127.0.0.1:43844 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:00] Prefill batch, #new-seq: 1, #new-token: 1436, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:01] INFO:     127.0.0.1:43848 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:02] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:02] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.80, #queue-req: 0, 
[2025-12-17 20:22:02] INFO:     127.0.0.1:45014 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:02] Prefill batch, #new-seq: 1, #new-token: 1393, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:02] INFO:     127.0.0.1:45018 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:04] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:05] INFO:     127.0.0.1:45022 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:05] Prefill batch, #new-seq: 1, #new-token: 1231, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:05] Decode batch, #running-req: 1, #token: 1271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.58, #queue-req: 0, 
[2025-12-17 20:22:05] INFO:     127.0.0.1:45026 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:06] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:06] INFO:     127.0.0.1:45030 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:06] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 767, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:06] INFO:     127.0.0.1:45034 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:08] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:08] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.11, #queue-req: 0, 
[2025-12-17 20:22:08] INFO:     127.0.0.1:45038 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:08] Prefill batch, #new-seq: 1, #new-token: 953, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:08] INFO:     127.0.0.1:45042 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:10] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:10] Decode batch, #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.77, #queue-req: 0, 
[2025-12-17 20:22:10] INFO:     127.0.0.1:45046 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:10] Prefill batch, #new-seq: 1, #new-token: 1446, #cached-token: 40, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:10] INFO:     127.0.0.1:45050 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:12] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:12] INFO:     127.0.0.1:45054 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:12] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 766, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:12] Decode batch, #running-req: 1, #token: 825, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.28, #queue-req: 0, 
[2025-12-17 20:22:12] INFO:     127.0.0.1:45058 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:14] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:14] INFO:     127.0.0.1:45064 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:14] Prefill batch, #new-seq: 1, #new-token: 1016, #cached-token: 143, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:14] INFO:     127.0.0.1:45068 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:16] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:16] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.38, #queue-req: 0, 
[2025-12-17 20:22:16] INFO:     127.0.0.1:45072 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:16] Prefill batch, #new-seq: 1, #new-token: 572, #cached-token: 224, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:16] INFO:     127.0.0.1:45076 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:18] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:18] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.05, #queue-req: 0, 
[2025-12-17 20:22:18] INFO:     127.0.0.1:45080 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:18] Prefill batch, #new-seq: 1, #new-token: 29, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:18] INFO:     127.0.0.1:45084 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:20] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:20] INFO:     127.0.0.1:45088 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:20] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 787, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:20] INFO:     127.0.0.1:45092 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:22] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:22] Decode batch, #running-req: 1, #token: 70, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.89, #queue-req: 0, 
[2025-12-17 20:22:22] INFO:     127.0.0.1:45096 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:22] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 765, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:22] INFO:     127.0.0.1:45100 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:24] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:24] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.47, #queue-req: 0, 
[2025-12-17 20:22:24] INFO:     127.0.0.1:45104 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:24] Prefill batch, #new-seq: 1, #new-token: 29, #cached-token: 1292, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:24] INFO:     127.0.0.1:45108 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:26] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:26] INFO:     127.0.0.1:45112 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:26] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 788, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:26] Decode batch, #running-req: 1, #token: 831, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.36, #queue-req: 0, 
[2025-12-17 20:22:26] INFO:     127.0.0.1:45116 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:32] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:32] INFO:     127.0.0.1:45120 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:32] Prefill batch, #new-seq: 1, #new-token: 755, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:32] Decode batch, #running-req: 1, #token: 776, token usage: 0.00, cuda graph: True, gen throughput (token/s): 6.10, #queue-req: 0, 
[2025-12-17 20:22:32] INFO:     127.0.0.1:45124 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:34] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:34] INFO:     127.0.0.1:45128 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:34] Prefill batch, #new-seq: 1, #new-token: 1110, #cached-token: 16, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:34] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.56, #queue-req: 0, 
[2025-12-17 20:22:34] INFO:     127.0.0.1:45132 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:36] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:36] INFO:     127.0.0.1:45136 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:36] Prefill batch, #new-seq: 1, #new-token: 1525, #cached-token: 19, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:36] INFO:     127.0.0.1:45140 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:38] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:38] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.94, #queue-req: 0, 
[2025-12-17 20:22:38] INFO:     127.0.0.1:45146 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:38] Prefill batch, #new-seq: 1, #new-token: 1309, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:38] INFO:     127.0.0.1:45150 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:40] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:40] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 15.88, #queue-req: 0, 
[2025-12-17 20:22:40] INFO:     127.0.0.1:45154 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:40] Prefill batch, #new-seq: 1, #new-token: 1234, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:41] INFO:     127.0.0.1:45158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:43] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:43] Decode batch, #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.98, #queue-req: 0, 
[2025-12-17 20:22:43] INFO:     127.0.0.1:45162 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:43] Prefill batch, #new-seq: 1, #new-token: 1221, #cached-token: 18, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:43] INFO:     127.0.0.1:45166 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:45] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:45] INFO:     127.0.0.1:45172 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:45] Prefill batch, #new-seq: 1, #new-token: 774, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:45] Decode batch, #running-req: 1, #token: 791, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.88, #queue-req: 0, 
[2025-12-17 20:22:45] INFO:     127.0.0.1:45176 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:47] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:47] INFO:     127.0.0.1:45180 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:47] Prefill batch, #new-seq: 1, #new-token: 582, #cached-token: 213, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:47] INFO:     127.0.0.1:45184 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:49] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:49] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.96, #queue-req: 0, 
[2025-12-17 20:22:49] INFO:     127.0.0.1:45192 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:49] Prefill batch, #new-seq: 1, #new-token: 1332, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:49] INFO:     127.0.0.1:45196 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:50] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:51] INFO:     127.0.0.1:45200 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:51] Prefill batch, #new-seq: 1, #new-token: 1378, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:51] Decode batch, #running-req: 1, #token: 1396, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.28, #queue-req: 0, 
[2025-12-17 20:22:51] INFO:     127.0.0.1:45204 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:52] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:52] INFO:     127.0.0.1:45208 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:52] Prefill batch, #new-seq: 1, #new-token: 1138, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:53] Decode batch, #running-req: 1, #token: 1168, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.09, #queue-req: 0, 
[2025-12-17 20:22:53] INFO:     127.0.0.1:45212 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:54] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:54] INFO:     127.0.0.1:45216 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:54] Prefill batch, #new-seq: 1, #new-token: 1365, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:54] Decode batch, #running-req: 1, #token: 1402, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.64, #queue-req: 0, 
[2025-12-17 20:22:54] INFO:     127.0.0.1:45220 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:56] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:56] INFO:     127.0.0.1:45224 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:22:56] Prefill batch, #new-seq: 1, #new-token: 565, #cached-token: 215, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:22:56] Decode batch, #running-req: 1, #token: 801, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.66, #queue-req: 0, 
[2025-12-17 20:22:57] Decode batch, #running-req: 1, #token: 841, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.63, #queue-req: 0, 
[2025-12-17 20:22:57] Decode batch, #running-req: 1, #token: 881, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.49, #queue-req: 0, 
[2025-12-17 20:22:57] Decode batch, #running-req: 1, #token: 921, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.52, #queue-req: 0, 
[2025-12-17 20:22:57] Decode batch, #running-req: 1, #token: 961, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.85, #queue-req: 0, 
[2025-12-17 20:22:57] Decode batch, #running-req: 1, #token: 1001, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.57, #queue-req: 0, 
[2025-12-17 20:22:57] Decode batch, #running-req: 1, #token: 1041, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.42, #queue-req: 0, 
[2025-12-17 20:22:58] Decode batch, #running-req: 1, #token: 1081, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.01, #queue-req: 0, 
[2025-12-17 20:22:58] Decode batch, #running-req: 1, #token: 1121, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.11, #queue-req: 0, 
[2025-12-17 20:22:58] Decode batch, #running-req: 1, #token: 1161, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.99, #queue-req: 0, 
[2025-12-17 20:22:58] Decode batch, #running-req: 1, #token: 1201, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.02, #queue-req: 0, 
[2025-12-17 20:22:58] Decode batch, #running-req: 1, #token: 1241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:22:59] Decode batch, #running-req: 1, #token: 1281, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:22:59] Decode batch, #running-req: 1, #token: 1321, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:22:59] Decode batch, #running-req: 1, #token: 1361, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.88, #queue-req: 0, 
[2025-12-17 20:22:59] Decode batch, #running-req: 1, #token: 1401, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.90, #queue-req: 0, 
[2025-12-17 20:22:59] Decode batch, #running-req: 1, #token: 1441, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.10, #queue-req: 0, 
[2025-12-17 20:22:59] Decode batch, #running-req: 1, #token: 1481, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.11, #queue-req: 0, 
[2025-12-17 20:23:00] Decode batch, #running-req: 1, #token: 1521, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:23:00] Decode batch, #running-req: 1, #token: 1561, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.88, #queue-req: 0, 
[2025-12-17 20:23:00] Decode batch, #running-req: 1, #token: 1601, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 20:23:00] Decode batch, #running-req: 1, #token: 1641, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:23:00] Decode batch, #running-req: 1, #token: 1681, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:23:01] Decode batch, #running-req: 1, #token: 1721, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:23:01] Decode batch, #running-req: 1, #token: 1761, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:23:01] INFO:     127.0.0.1:45228 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:03] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:03] INFO:     127.0.0.1:46360 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:03] Prefill batch, #new-seq: 1, #new-token: 550, #cached-token: 213, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:03] Decode batch, #running-req: 1, #token: 767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.49, #queue-req: 0, 
[2025-12-17 20:23:03] INFO:     127.0.0.1:46364 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:04] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:05] INFO:     127.0.0.1:46372 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:05] Prefill batch, #new-seq: 1, #new-token: 1074, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:05] Decode batch, #running-req: 1, #token: 1104, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.66, #queue-req: 0, 
[2025-12-17 20:23:05] INFO:     127.0.0.1:46376 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:06] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:06] INFO:     127.0.0.1:46380 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:06] Prefill batch, #new-seq: 1, #new-token: 474, #cached-token: 297, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:07] INFO:     127.0.0.1:46384 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:08] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:09] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.24, #queue-req: 0, 
[2025-12-17 20:23:09] INFO:     127.0.0.1:46390 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:09] Prefill batch, #new-seq: 1, #new-token: 1250, #cached-token: 19, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:09] INFO:     127.0.0.1:46394 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:10] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:10] INFO:     127.0.0.1:46398 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:10] Prefill batch, #new-seq: 1, #new-token: 1248, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:10] INFO:     127.0.0.1:46402 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:12] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:12] Decode batch, #running-req: 1, #token: 72, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.87, #queue-req: 0, 
[2025-12-17 20:23:12] INFO:     127.0.0.1:46406 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:12] Prefill batch, #new-seq: 1, #new-token: 1228, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:12] INFO:     127.0.0.1:46410 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:15] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:15] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.42, #queue-req: 0, 
[2025-12-17 20:23:15] INFO:     127.0.0.1:46414 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:15] Prefill batch, #new-seq: 1, #new-token: 1196, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:15] INFO:     127.0.0.1:46418 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:16] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:17] INFO:     127.0.0.1:46424 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:17] Prefill batch, #new-seq: 1, #new-token: 1139, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:17] Decode batch, #running-req: 1, #token: 1158, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.27, #queue-req: 0, 
[2025-12-17 20:23:17] INFO:     127.0.0.1:46428 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:18] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:18] INFO:     127.0.0.1:46434 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:18] Prefill batch, #new-seq: 1, #new-token: 666, #cached-token: 131, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:19] INFO:     127.0.0.1:46438 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:20] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:20] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.04, #queue-req: 0, 
[2025-12-17 20:23:20] INFO:     127.0.0.1:46442 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:20] Prefill batch, #new-seq: 1, #new-token: 1268, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:20] INFO:     127.0.0.1:46446 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:23] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:23] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.84, #queue-req: 0, 
[2025-12-17 20:23:23] INFO:     127.0.0.1:46450 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:23] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 769, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:23] INFO:     127.0.0.1:46454 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:24] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:25] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.80, #queue-req: 0, 
[2025-12-17 20:23:25] INFO:     127.0.0.1:46458 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:25] Prefill batch, #new-seq: 1, #new-token: 23, #cached-token: 769, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:25] INFO:     127.0.0.1:46462 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:27] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:27] INFO:     127.0.0.1:46468 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:27] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.40, #queue-req: 0, 
[2025-12-17 20:23:27] Prefill batch, #new-seq: 1, #new-token: 1319, #cached-token: 17, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:27] INFO:     127.0.0.1:46472 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:28] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:29] INFO:     127.0.0.1:46476 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:29] Prefill batch, #new-seq: 1, #new-token: 1118, #cached-token: 146, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:29] INFO:     127.0.0.1:46480 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:30] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:30] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.91, #queue-req: 0, 
[2025-12-17 20:23:30] INFO:     127.0.0.1:46484 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:30] Prefill batch, #new-seq: 1, #new-token: 1280, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:31] INFO:     127.0.0.1:46488 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:32] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:33] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.33, #queue-req: 0, 
[2025-12-17 20:23:33] INFO:     127.0.0.1:46494 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:33] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 725, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:33] INFO:     127.0.0.1:46498 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:35] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:35] Decode batch, #running-req: 1, #token: 99, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.19, #queue-req: 0, 
[2025-12-17 20:23:35] INFO:     127.0.0.1:46504 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:35] Prefill batch, #new-seq: 1, #new-token: 763, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:35] INFO:     127.0.0.1:46508 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:37] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:37] INFO:     127.0.0.1:46512 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:37] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 784, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:37] Decode batch, #running-req: 1, #token: 800, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.34, #queue-req: 0, 
[2025-12-17 20:23:37] INFO:     127.0.0.1:46516 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:39] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:39] INFO:     127.0.0.1:46520 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:39] Prefill batch, #new-seq: 1, #new-token: 1206, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:39] INFO:     127.0.0.1:46524 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:39] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.45, #queue-req: 0, 
[2025-12-17 20:23:41] Prefill batch, #new-seq: 1, #new-token: 60, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:41] INFO:     127.0.0.1:46528 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:41] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 725, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:41] INFO:     127.0.0.1:46532 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:43] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:43] INFO:     127.0.0.1:46536 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:43] Prefill batch, #new-seq: 1, #new-token: 1289, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:43] Decode batch, #running-req: 1, #token: 1308, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.84, #queue-req: 0, 
[2025-12-17 20:23:43] INFO:     127.0.0.1:46540 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:45] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:45] INFO:     127.0.0.1:46544 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:45] Prefill batch, #new-seq: 1, #new-token: 1429, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:45] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.18, #queue-req: 0, 
[2025-12-17 20:23:45] INFO:     127.0.0.1:46548 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:47] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:47] INFO:     127.0.0.1:46552 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:47] Prefill batch, #new-seq: 1, #new-token: 1212, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:48] INFO:     127.0.0.1:46556 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:49] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:49] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.59, #queue-req: 0, 
[2025-12-17 20:23:49] INFO:     127.0.0.1:46560 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:49] Prefill batch, #new-seq: 1, #new-token: 1179, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:50] Decode batch, #running-req: 1, #token: 1243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 187.84, #queue-req: 0, 
[2025-12-17 20:23:50] INFO:     127.0.0.1:46564 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:51] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:51] INFO:     127.0.0.1:46568 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:51] Prefill batch, #new-seq: 1, #new-token: 1126, #cached-token: 193, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:52] INFO:     127.0.0.1:46572 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:53] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:53] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.07, #queue-req: 0, 
[2025-12-17 20:23:53] INFO:     127.0.0.1:46576 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:53] Prefill batch, #new-seq: 1, #new-token: 1004, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:53] INFO:     127.0.0.1:46580 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:55] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:55] INFO:     127.0.0.1:46584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:55] Prefill batch, #new-seq: 1, #new-token: 1051, #cached-token: 20, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:55] INFO:     127.0.0.1:46588 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:57] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:57] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.82, #queue-req: 0, 
[2025-12-17 20:23:57] INFO:     127.0.0.1:46596 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:57] Prefill batch, #new-seq: 1, #new-token: 688, #cached-token: 133, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:57] INFO:     127.0.0.1:46600 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:59] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:59] INFO:     127.0.0.1:46604 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:23:59] Prefill batch, #new-seq: 1, #new-token: 1096, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:23:59] Decode batch, #running-req: 1, #token: 1120, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.70, #queue-req: 0, 
[2025-12-17 20:23:59] INFO:     127.0.0.1:46608 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:01] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:01] INFO:     127.0.0.1:46612 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:01] Prefill batch, #new-seq: 1, #new-token: 8, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:01] Decode batch, #running-req: 1, #token: 781, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.22, #queue-req: 0, 
[2025-12-17 20:24:02] Decode batch, #running-req: 1, #token: 821, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.14, #queue-req: 0, 
[2025-12-17 20:24:02] Decode batch, #running-req: 1, #token: 861, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.21, #queue-req: 0, 
[2025-12-17 20:24:02] Decode batch, #running-req: 1, #token: 901, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.10, #queue-req: 0, 
[2025-12-17 20:24:02] Decode batch, #running-req: 1, #token: 941, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.20, #queue-req: 0, 
[2025-12-17 20:24:02] Decode batch, #running-req: 1, #token: 981, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.34, #queue-req: 0, 
[2025-12-17 20:24:02] Decode batch, #running-req: 1, #token: 1021, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.15, #queue-req: 0, 
[2025-12-17 20:24:03] Decode batch, #running-req: 1, #token: 1061, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:24:03] Decode batch, #running-req: 1, #token: 1101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:24:03] Decode batch, #running-req: 1, #token: 1141, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 20:24:03] Decode batch, #running-req: 1, #token: 1181, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 20:24:03] Decode batch, #running-req: 1, #token: 1221, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:24:04] Decode batch, #running-req: 1, #token: 1261, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:24:04] Decode batch, #running-req: 1, #token: 1301, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 20:24:04] Decode batch, #running-req: 1, #token: 1341, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:24:04] Decode batch, #running-req: 1, #token: 1381, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 20:24:04] Decode batch, #running-req: 1, #token: 1421, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.49, #queue-req: 0, 
[2025-12-17 20:24:04] Decode batch, #running-req: 1, #token: 1461, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.64, #queue-req: 0, 
[2025-12-17 20:24:05] Decode batch, #running-req: 1, #token: 1501, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:24:05] Decode batch, #running-req: 1, #token: 1541, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:24:05] Decode batch, #running-req: 1, #token: 1581, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 20:24:05] Decode batch, #running-req: 1, #token: 1621, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.30, #queue-req: 0, 
[2025-12-17 20:24:05] Decode batch, #running-req: 1, #token: 1661, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.36, #queue-req: 0, 
[2025-12-17 20:24:06] Decode batch, #running-req: 1, #token: 1701, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.27, #queue-req: 0, 
[2025-12-17 20:24:06] Decode batch, #running-req: 1, #token: 1741, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.16, #queue-req: 0, 
[2025-12-17 20:24:06] INFO:     127.0.0.1:46616 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:08] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:08] INFO:     127.0.0.1:46622 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:08] Prefill batch, #new-seq: 1, #new-token: 653, #cached-token: 57, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:08] Decode batch, #running-req: 1, #token: 717, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.69, #queue-req: 0, 
[2025-12-17 20:24:08] INFO:     127.0.0.1:46626 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:09] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:09] INFO:     127.0.0.1:46630 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:09] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 1268, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:10] INFO:     127.0.0.1:46634 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:10] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.11, #queue-req: 0, 
[2025-12-17 20:24:11] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:11] INFO:     127.0.0.1:46638 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:11] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 769, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:11] INFO:     127.0.0.1:46642 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:13] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:13] Decode batch, #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.91, #queue-req: 0, 
[2025-12-17 20:24:13] INFO:     127.0.0.1:46648 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:13] Prefill batch, #new-seq: 1, #new-token: 1206, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:13] Decode batch, #running-req: 1, #token: 1255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 173.97, #queue-req: 0, 
[2025-12-17 20:24:14] Decode batch, #running-req: 1, #token: 1295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 20:24:14] Decode batch, #running-req: 1, #token: 1335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:24:14] Decode batch, #running-req: 1, #token: 1375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:24:14] Decode batch, #running-req: 1, #token: 1415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:24:14] Decode batch, #running-req: 1, #token: 1455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:24:15] Decode batch, #running-req: 1, #token: 1495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:24:15] Decode batch, #running-req: 1, #token: 1535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:24:15] Decode batch, #running-req: 1, #token: 1575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.42, #queue-req: 0, 
[2025-12-17 20:24:15] Decode batch, #running-req: 1, #token: 1615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 20:24:15] Decode batch, #running-req: 1, #token: 1655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 20:24:15] Decode batch, #running-req: 1, #token: 1695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.37, #queue-req: 0, 
[2025-12-17 20:24:16] Decode batch, #running-req: 1, #token: 1735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.32, #queue-req: 0, 
[2025-12-17 20:24:16] Decode batch, #running-req: 1, #token: 1775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.49, #queue-req: 0, 
[2025-12-17 20:24:16] Decode batch, #running-req: 1, #token: 1815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.30, #queue-req: 0, 
[2025-12-17 20:24:16] Decode batch, #running-req: 1, #token: 1855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.42, #queue-req: 0, 
[2025-12-17 20:24:16] Decode batch, #running-req: 1, #token: 1895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.29, #queue-req: 0, 
[2025-12-17 20:24:17] Decode batch, #running-req: 1, #token: 1935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 20:24:17] Decode batch, #running-req: 1, #token: 1975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:24:17] Decode batch, #running-req: 1, #token: 2015, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:24:17] Decode batch, #running-req: 1, #token: 2055, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.49, #queue-req: 0, 
[2025-12-17 20:24:17] Decode batch, #running-req: 1, #token: 2095, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.11, #queue-req: 0, 
[2025-12-17 20:24:17] Decode batch, #running-req: 1, #token: 2135, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.00, #queue-req: 0, 
[2025-12-17 20:24:18] Decode batch, #running-req: 1, #token: 2175, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.03, #queue-req: 0, 
[2025-12-17 20:24:18] Decode batch, #running-req: 1, #token: 2215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.00, #queue-req: 0, 
[2025-12-17 20:24:18] INFO:     127.0.0.1:46652 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:20] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:20] INFO:     127.0.0.1:46656 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:20] Prefill batch, #new-seq: 1, #new-token: 1134, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:20] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.68, #queue-req: 0, 
[2025-12-17 20:24:20] INFO:     127.0.0.1:46660 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:22] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:22] INFO:     127.0.0.1:46668 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:22] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 783, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:22] INFO:     127.0.0.1:46672 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:23] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:23] INFO:     127.0.0.1:46676 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:23] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.03, #queue-req: 0, 
[2025-12-17 20:24:23] Prefill batch, #new-seq: 1, #new-token: 1347, #cached-token: 39, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:24] Decode batch, #running-req: 1, #token: 1427, token usage: 0.00, cuda graph: True, gen throughput (token/s): 182.44, #queue-req: 0, 
[2025-12-17 20:24:24] Decode batch, #running-req: 1, #token: 1467, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:24:24] Decode batch, #running-req: 1, #token: 1507, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 20:24:24] Decode batch, #running-req: 1, #token: 1547, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 20:24:24] Decode batch, #running-req: 1, #token: 1587, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.40, #queue-req: 0, 
[2025-12-17 20:24:25] Decode batch, #running-req: 1, #token: 1627, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 20:24:25] Decode batch, #running-req: 1, #token: 1667, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.45, #queue-req: 0, 
[2025-12-17 20:24:25] Decode batch, #running-req: 1, #token: 1707, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 20:24:25] Decode batch, #running-req: 1, #token: 1747, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.37, #queue-req: 0, 
[2025-12-17 20:24:25] Decode batch, #running-req: 1, #token: 1787, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 20:24:25] Decode batch, #running-req: 1, #token: 1827, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.34, #queue-req: 0, 
[2025-12-17 20:24:26] Decode batch, #running-req: 1, #token: 1867, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 20:24:26] Decode batch, #running-req: 1, #token: 1907, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:24:26] Decode batch, #running-req: 1, #token: 1947, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.45, #queue-req: 0, 
[2025-12-17 20:24:26] Decode batch, #running-req: 1, #token: 1987, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:24:26] Decode batch, #running-req: 1, #token: 2027, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 20:24:27] Decode batch, #running-req: 1, #token: 2067, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.26, #queue-req: 0, 
[2025-12-17 20:24:27] Decode batch, #running-req: 1, #token: 2107, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.06, #queue-req: 0, 
[2025-12-17 20:24:27] Decode batch, #running-req: 1, #token: 2147, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.10, #queue-req: 0, 
[2025-12-17 20:24:27] Decode batch, #running-req: 1, #token: 2187, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.85, #queue-req: 0, 
[2025-12-17 20:24:27] Decode batch, #running-req: 1, #token: 2227, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.07, #queue-req: 0, 
[2025-12-17 20:24:27] Decode batch, #running-req: 1, #token: 2267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.93, #queue-req: 0, 
[2025-12-17 20:24:28] Decode batch, #running-req: 1, #token: 2307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.79, #queue-req: 0, 
[2025-12-17 20:24:28] Decode batch, #running-req: 1, #token: 2347, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.82, #queue-req: 0, 
[2025-12-17 20:24:28] INFO:     127.0.0.1:46680 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:28] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.01, #queue-req: 0, 
[2025-12-17 20:24:30] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:30] INFO:     127.0.0.1:46684 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:30] Prefill batch, #new-seq: 1, #new-token: 1341, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:30] INFO:     127.0.0.1:46688 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:32] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:32] INFO:     127.0.0.1:46692 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:32] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 757, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:32] Decode batch, #running-req: 1, #token: 805, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.81, #queue-req: 0, 
[2025-12-17 20:24:32] INFO:     127.0.0.1:46696 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:34] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:34] INFO:     127.0.0.1:46700 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:34] Prefill batch, #new-seq: 1, #new-token: 1432, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:34] Decode batch, #running-req: 1, #token: 1459, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.59, #queue-req: 0, 
[2025-12-17 20:24:34] INFO:     127.0.0.1:46704 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:36] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:36] INFO:     127.0.0.1:46710 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:36] Prefill batch, #new-seq: 1, #new-token: 1338, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:36] INFO:     127.0.0.1:46714 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:38] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:38] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.38, #queue-req: 0, 
[2025-12-17 20:24:38] INFO:     127.0.0.1:46718 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:38] Prefill batch, #new-seq: 1, #new-token: 1099, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:38] INFO:     127.0.0.1:46722 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:40] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:40] INFO:     127.0.0.1:46726 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:40] Prefill batch, #new-seq: 1, #new-token: 1075, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:40] INFO:     127.0.0.1:46730 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:42] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:42] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.88, #queue-req: 0, 
[2025-12-17 20:24:42] INFO:     127.0.0.1:46734 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:42] Prefill batch, #new-seq: 1, #new-token: 1126, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:42] INFO:     127.0.0.1:46738 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:43] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:44] INFO:     127.0.0.1:46742 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:44] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.54, #queue-req: 0, 
[2025-12-17 20:24:44] Prefill batch, #new-seq: 1, #new-token: 1253, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:44] INFO:     127.0.0.1:46746 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:45] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:45] INFO:     127.0.0.1:46750 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:45] Prefill batch, #new-seq: 1, #new-token: 1354, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:46] INFO:     127.0.0.1:46754 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:47] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:47] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.80, #queue-req: 0, 
[2025-12-17 20:24:47] INFO:     127.0.0.1:46758 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:47] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 784, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:47] INFO:     127.0.0.1:46762 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:49] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:49] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.62, #queue-req: 0, 
[2025-12-17 20:24:49] INFO:     127.0.0.1:46768 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:49] Prefill batch, #new-seq: 1, #new-token: 1474, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:49] INFO:     127.0.0.1:46772 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:51] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:51] INFO:     127.0.0.1:46776 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:51] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 751, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:51] Decode batch, #running-req: 1, #token: 769, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.04, #queue-req: 0, 
[2025-12-17 20:24:51] INFO:     127.0.0.1:46780 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:53] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:53] INFO:     127.0.0.1:46784 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:53] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 1247, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:53] INFO:     127.0.0.1:46788 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:55] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:55] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.92, #queue-req: 0, 
[2025-12-17 20:24:55] INFO:     127.0.0.1:46792 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:55] Prefill batch, #new-seq: 1, #new-token: 1596, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:55] INFO:     127.0.0.1:46796 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:57] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:57] INFO:     127.0.0.1:46800 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:57] Prefill batch, #new-seq: 1, #new-token: 1167, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:57] INFO:     127.0.0.1:46804 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:57] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.61, #queue-req: 0, 
[2025-12-17 20:24:59] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:59] INFO:     127.0.0.1:46808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:24:59] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:24:59] INFO:     127.0.0.1:46812 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:01] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:01] INFO:     127.0.0.1:46824 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:01] Prefill batch, #new-seq: 1, #new-token: 1112, #cached-token: 144, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:01] Decode batch, #running-req: 1, #token: 1258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.78, #queue-req: 0, 
[2025-12-17 20:25:01] INFO:     127.0.0.1:46828 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:03] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:03] INFO:     127.0.0.1:46832 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:03] Prefill batch, #new-seq: 1, #new-token: 1331, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:03] INFO:     127.0.0.1:46836 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:05] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:05] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.01, #queue-req: 0, 
[2025-12-17 20:25:05] INFO:     127.0.0.1:46840 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:05] Prefill batch, #new-seq: 1, #new-token: 1289, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:05] INFO:     127.0.0.1:46844 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:06] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:06] INFO:     127.0.0.1:46848 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:06] Prefill batch, #new-seq: 1, #new-token: 966, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:07] Decode batch, #running-req: 1, #token: 1013, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.47, #queue-req: 0, 
[2025-12-17 20:25:07] INFO:     127.0.0.1:46852 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:08] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:08] INFO:     127.0.0.1:46856 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:08] Prefill batch, #new-seq: 1, #new-token: 1120, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:08] INFO:     127.0.0.1:46860 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:10] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:10] INFO:     127.0.0.1:46868 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:10] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.95, #queue-req: 0, 
[2025-12-17 20:25:10] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 751, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:10] INFO:     127.0.0.1:46872 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:12] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:12] INFO:     127.0.0.1:46878 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:12] Prefill batch, #new-seq: 1, #new-token: 1251, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:12] INFO:     127.0.0.1:46882 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:14] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:14] Decode batch, #running-req: 1, #token: 72, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.72, #queue-req: 0, 
[2025-12-17 20:25:14] INFO:     127.0.0.1:46886 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:14] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:14] INFO:     127.0.0.1:46890 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:16] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:16] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.83, #queue-req: 0, 
[2025-12-17 20:25:16] INFO:     127.0.0.1:46894 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:16] Prefill batch, #new-seq: 1, #new-token: 1185, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:16] Decode batch, #running-req: 1, #token: 1242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 189.31, #queue-req: 0, 
[2025-12-17 20:25:16] INFO:     127.0.0.1:46898 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:18] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:18] INFO:     127.0.0.1:46902 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:18] Prefill batch, #new-seq: 1, #new-token: 1112, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:18] INFO:     127.0.0.1:46906 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:20] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:20] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.03, #queue-req: 0, 
[2025-12-17 20:25:20] INFO:     127.0.0.1:46912 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:20] Prefill batch, #new-seq: 1, #new-token: 1246, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:20] INFO:     127.0.0.1:46916 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:22] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:22] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.51, #queue-req: 0, 
[2025-12-17 20:25:22] INFO:     127.0.0.1:46920 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:22] Prefill batch, #new-seq: 1, #new-token: 1261, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:22] INFO:     127.0.0.1:46924 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:23] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:23] INFO:     127.0.0.1:46928 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:24] Prefill batch, #new-seq: 1, #new-token: 1370, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:24] Decode batch, #running-req: 1, #token: 1413, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.44, #queue-req: 0, 
[2025-12-17 20:25:24] INFO:     127.0.0.1:46932 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:25] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:25] INFO:     127.0.0.1:46936 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:25] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:25] Decode batch, #running-req: 1, #token: 777, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.94, #queue-req: 0, 
[2025-12-17 20:25:26] INFO:     127.0.0.1:46940 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:27] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:27] INFO:     127.0.0.1:46944 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:27] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:27] INFO:     127.0.0.1:46948 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:30] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:30] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.47, #queue-req: 0, 
[2025-12-17 20:25:30] INFO:     127.0.0.1:46952 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:30] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 751, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:30] INFO:     127.0.0.1:46956 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:32] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:32] INFO:     127.0.0.1:46962 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:32] Prefill batch, #new-seq: 1, #new-token: 1229, #cached-token: 39, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:32] Decode batch, #running-req: 1, #token: 1277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.05, #queue-req: 0, 
[2025-12-17 20:25:32] INFO:     127.0.0.1:46966 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:33] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:34] INFO:     127.0.0.1:46972 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:34] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:34] Decode batch, #running-req: 1, #token: 788, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.56, #queue-req: 0, 
[2025-12-17 20:25:34] INFO:     127.0.0.1:46976 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:35] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:35] INFO:     127.0.0.1:46980 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:35] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 784, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:36] INFO:     127.0.0.1:46984 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:38] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:38] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.04, #queue-req: 0, 
[2025-12-17 20:25:38] INFO:     127.0.0.1:46988 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:38] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:38] INFO:     127.0.0.1:46992 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:40] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:40] INFO:     127.0.0.1:46996 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:40] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 753, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:40] Decode batch, #running-req: 1, #token: 777, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.10, #queue-req: 0, 
[2025-12-17 20:25:40] INFO:     127.0.0.1:47000 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:42] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:42] INFO:     127.0.0.1:47004 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:42] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 783, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:42] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.01, #queue-req: 0, 
[2025-12-17 20:25:42] INFO:     127.0.0.1:47008 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:44] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:44] INFO:     127.0.0.1:47012 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:44] Prefill batch, #new-seq: 1, #new-token: 756, #cached-token: 57, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:44] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.76, #queue-req: 0, 
[2025-12-17 20:25:44] INFO:     127.0.0.1:47016 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:46] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:46] INFO:     127.0.0.1:47020 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:46] Prefill batch, #new-seq: 1, #new-token: 1135, #cached-token: 123, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:46] INFO:     127.0.0.1:47024 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:48] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:48] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.90, #queue-req: 0, 
[2025-12-17 20:25:48] INFO:     127.0.0.1:47028 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:48] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:48] INFO:     127.0.0.1:47032 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:49] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:49] INFO:     127.0.0.1:47038 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:49] Prefill batch, #new-seq: 1, #new-token: 24, #cached-token: 751, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:50] Decode batch, #running-req: 1, #token: 791, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.18, #queue-req: 0, 
[2025-12-17 20:25:50] INFO:     127.0.0.1:47042 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:51] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:51] INFO:     127.0.0.1:47046 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:51] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 754, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:51] Decode batch, #running-req: 1, #token: 787, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.63, #queue-req: 0, 
[2025-12-17 20:25:52] INFO:     127.0.0.1:47050 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:54] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:54] INFO:     127.0.0.1:47054 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:54] Prefill batch, #new-seq: 1, #new-token: 705, #cached-token: 57, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:54] Decode batch, #running-req: 1, #token: 786, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.52, #queue-req: 0, 
[2025-12-17 20:25:54] INFO:     127.0.0.1:47058 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:56] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:56] INFO:     127.0.0.1:47062 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:25:56] Prefill batch, #new-seq: 1, #new-token: 1365, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:25:56] Decode batch, #running-req: 1, #token: 1394, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.59, #queue-req: 0, 
[2025-12-17 20:25:56] Decode batch, #running-req: 1, #token: 1434, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 20:25:56] Decode batch, #running-req: 1, #token: 1474, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.96, #queue-req: 0, 
[2025-12-17 20:25:56] Decode batch, #running-req: 1, #token: 1514, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 20:25:57] Decode batch, #running-req: 1, #token: 1554, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:25:57] Decode batch, #running-req: 1, #token: 1594, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:25:57] Decode batch, #running-req: 1, #token: 1634, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:25:57] Decode batch, #running-req: 1, #token: 1674, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:25:57] Decode batch, #running-req: 1, #token: 1714, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 20:25:57] Decode batch, #running-req: 1, #token: 1754, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:25:58] Decode batch, #running-req: 1, #token: 1794, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:25:58] Decode batch, #running-req: 1, #token: 1834, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 20:25:58] Decode batch, #running-req: 1, #token: 1874, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:25:58] Decode batch, #running-req: 1, #token: 1914, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 20:25:58] Decode batch, #running-req: 1, #token: 1954, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:25:59] Decode batch, #running-req: 1, #token: 1994, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:25:59] Decode batch, #running-req: 1, #token: 2034, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.62, #queue-req: 0, 
[2025-12-17 20:25:59] Decode batch, #running-req: 1, #token: 2074, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.38, #queue-req: 0, 
[2025-12-17 20:25:59] Decode batch, #running-req: 1, #token: 2114, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.20, #queue-req: 0, 
[2025-12-17 20:25:59] Decode batch, #running-req: 1, #token: 2154, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.21, #queue-req: 0, 
[2025-12-17 20:25:59] Decode batch, #running-req: 1, #token: 2194, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.03, #queue-req: 0, 
[2025-12-17 20:26:00] Decode batch, #running-req: 1, #token: 2234, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.14, #queue-req: 0, 
[2025-12-17 20:26:00] Decode batch, #running-req: 1, #token: 2274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.01, #queue-req: 0, 
[2025-12-17 20:26:00] Decode batch, #running-req: 1, #token: 2314, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.23, #queue-req: 0, 
[2025-12-17 20:26:00] Decode batch, #running-req: 1, #token: 2354, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.09, #queue-req: 0, 
[2025-12-17 20:26:00] INFO:     127.0.0.1:47066 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:02] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:02] INFO:     127.0.0.1:47072 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:02] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:02] Decode batch, #running-req: 1, #token: 773, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.70, #queue-req: 0, 
[2025-12-17 20:26:02] INFO:     127.0.0.1:47076 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:04] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:04] INFO:     127.0.0.1:47080 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:04] Prefill batch, #new-seq: 1, #new-token: 1098, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:04] INFO:     127.0.0.1:47084 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:06] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:06] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.89, #queue-req: 0, 
[2025-12-17 20:26:06] INFO:     127.0.0.1:47088 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:06] Prefill batch, #new-seq: 1, #new-token: 21, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:06] INFO:     127.0.0.1:47092 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:08] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:08] INFO:     127.0.0.1:47096 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:08] Prefill batch, #new-seq: 1, #new-token: 1192, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:08] Decode batch, #running-req: 1, #token: 1227, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.02, #queue-req: 0, 
[2025-12-17 20:26:08] INFO:     127.0.0.1:47100 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:10] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:10] INFO:     127.0.0.1:47104 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:10] Prefill batch, #new-seq: 1, #new-token: 1237, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:10] INFO:     127.0.0.1:47108 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:11] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:11] Decode batch, #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.93, #queue-req: 0, 
[2025-12-17 20:26:11] INFO:     127.0.0.1:47112 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:11] Prefill batch, #new-seq: 1, #new-token: 1486, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:12] INFO:     127.0.0.1:47116 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:14] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:14] INFO:     127.0.0.1:47120 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:14] Prefill batch, #new-seq: 1, #new-token: 1212, #cached-token: 16, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:14] INFO:     127.0.0.1:47124 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:16] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:16] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.58, #queue-req: 0, 
[2025-12-17 20:26:16] INFO:     127.0.0.1:47132 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:16] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 754, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:16] INFO:     127.0.0.1:47136 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:18] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:18] INFO:     127.0.0.1:47140 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:18] Prefill batch, #new-seq: 1, #new-token: 1044, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:18] Decode batch, #running-req: 1, #token: 1059, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.54, #queue-req: 0, 
[2025-12-17 20:26:18] INFO:     127.0.0.1:47144 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:20] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:20] INFO:     127.0.0.1:47148 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:20] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:20] INFO:     127.0.0.1:47152 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:22] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:22] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.80, #queue-req: 0, 
[2025-12-17 20:26:22] INFO:     127.0.0.1:47158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:22] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:22] INFO:     127.0.0.1:47162 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:24] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:24] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.65, #queue-req: 0, 
[2025-12-17 20:26:24] INFO:     127.0.0.1:47166 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:24] Prefill batch, #new-seq: 1, #new-token: 1353, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:24] INFO:     127.0.0.1:47170 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:25] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:26] INFO:     127.0.0.1:47174 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:26] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:26] Decode batch, #running-req: 1, #token: 777, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.89, #queue-req: 0, 
[2025-12-17 20:26:26] INFO:     127.0.0.1:47178 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:27] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:27] INFO:     127.0.0.1:47182 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:27] Prefill batch, #new-seq: 1, #new-token: 1170, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:27] Decode batch, #running-req: 1, #token: 1226, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.12, #queue-req: 0, 
[2025-12-17 20:26:27] INFO:     127.0.0.1:47186 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:29] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:30] INFO:     127.0.0.1:47190 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:30] Prefill batch, #new-seq: 1, #new-token: 1255, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:30] INFO:     127.0.0.1:47194 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:31] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:31] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.11, #queue-req: 0, 
[2025-12-17 20:26:31] INFO:     127.0.0.1:47198 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:31] Prefill batch, #new-seq: 1, #new-token: 1222, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:32] INFO:     127.0.0.1:47202 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:34] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:34] INFO:     127.0.0.1:47208 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:34] Prefill batch, #new-seq: 1, #new-token: 1269, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:34] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.66, #queue-req: 0, 
[2025-12-17 20:26:34] INFO:     127.0.0.1:47212 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:35] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:35] INFO:     127.0.0.1:47216 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:35] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:36] INFO:     127.0.0.1:47220 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:37] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:37] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.92, #queue-req: 0, 
[2025-12-17 20:26:37] INFO:     127.0.0.1:47224 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:37] Prefill batch, #new-seq: 1, #new-token: 1251, #cached-token: 111, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:38] INFO:     127.0.0.1:47228 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:39] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:39] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.04, #queue-req: 0, 
[2025-12-17 20:26:39] INFO:     127.0.0.1:47232 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:39] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:40] Decode batch, #running-req: 1, #token: 799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 194.08, #queue-req: 0, 
[2025-12-17 20:26:40] Decode batch, #running-req: 1, #token: 839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.44, #queue-req: 0, 
[2025-12-17 20:26:40] Decode batch, #running-req: 1, #token: 879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.43, #queue-req: 0, 
[2025-12-17 20:26:40] Decode batch, #running-req: 1, #token: 919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.37, #queue-req: 0, 
[2025-12-17 20:26:40] Decode batch, #running-req: 1, #token: 959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.55, #queue-req: 0, 
[2025-12-17 20:26:40] Decode batch, #running-req: 1, #token: 999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.50, #queue-req: 0, 
[2025-12-17 20:26:41] Decode batch, #running-req: 1, #token: 1039, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.37, #queue-req: 0, 
[2025-12-17 20:26:41] Decode batch, #running-req: 1, #token: 1079, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:26:41] Decode batch, #running-req: 1, #token: 1119, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.62, #queue-req: 0, 
[2025-12-17 20:26:41] Decode batch, #running-req: 1, #token: 1159, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:26:41] Decode batch, #running-req: 1, #token: 1199, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.88, #queue-req: 0, 
[2025-12-17 20:26:42] Decode batch, #running-req: 1, #token: 1239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:26:42] Decode batch, #running-req: 1, #token: 1279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:26:42] Decode batch, #running-req: 1, #token: 1319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:26:42] Decode batch, #running-req: 1, #token: 1359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:26:42] Decode batch, #running-req: 1, #token: 1399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:26:42] Decode batch, #running-req: 1, #token: 1439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 20:26:43] Decode batch, #running-req: 1, #token: 1479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.05, #queue-req: 0, 
[2025-12-17 20:26:43] Decode batch, #running-req: 1, #token: 1519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.10, #queue-req: 0, 
[2025-12-17 20:26:43] Decode batch, #running-req: 1, #token: 1559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:26:43] Decode batch, #running-req: 1, #token: 1599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:26:43] Decode batch, #running-req: 1, #token: 1639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:26:44] Decode batch, #running-req: 1, #token: 1679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:26:44] Decode batch, #running-req: 1, #token: 1719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:26:44] Decode batch, #running-req: 1, #token: 1759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.55, #queue-req: 0, 
[2025-12-17 20:26:44] INFO:     127.0.0.1:47236 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:46] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:46] INFO:     127.0.0.1:47240 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:46] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:46] Decode batch, #running-req: 1, #token: 781, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.79, #queue-req: 0, 
[2025-12-17 20:26:46] INFO:     127.0.0.1:47244 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:48] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:48] INFO:     127.0.0.1:47248 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:48] Prefill batch, #new-seq: 1, #new-token: 1297, #cached-token: 17, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:48] INFO:     127.0.0.1:47252 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:50] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:50] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.71, #queue-req: 0, 
[2025-12-17 20:26:50] INFO:     127.0.0.1:47260 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:50] Prefill batch, #new-seq: 1, #new-token: 1166, #cached-token: 169, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:50] INFO:     127.0.0.1:47264 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:52] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:52] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.73, #queue-req: 0, 
[2025-12-17 20:26:52] INFO:     127.0.0.1:47268 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:52] Prefill batch, #new-seq: 1, #new-token: 1260, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:52] INFO:     127.0.0.1:47272 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:54] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:54] INFO:     127.0.0.1:47276 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:54] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 1247, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:54] INFO:     127.0.0.1:47280 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:56] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:56] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.90, #queue-req: 0, 
[2025-12-17 20:26:56] INFO:     127.0.0.1:47284 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:56] Prefill batch, #new-seq: 1, #new-token: 1369, #cached-token: 18, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:56] INFO:     127.0.0.1:47288 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:57] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:57] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.88, #queue-req: 0, 
[2025-12-17 20:26:58] INFO:     127.0.0.1:47292 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:58] Prefill batch, #new-seq: 1, #new-token: 1314, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:58] INFO:     127.0.0.1:47296 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:59] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:26:59] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.65, #queue-req: 0, 
[2025-12-17 20:26:59] INFO:     127.0.0.1:47302 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:26:59] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:00] INFO:     127.0.0.1:47306 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:00] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 193.67, #queue-req: 0, 
[2025-12-17 20:27:01] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:01] INFO:     127.0.0.1:47310 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:01] Prefill batch, #new-seq: 1, #new-token: 1139, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:01] INFO:     127.0.0.1:47314 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:03] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:03] INFO:     127.0.0.1:47318 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:03] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 751, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:03] Decode batch, #running-req: 1, #token: 770, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.93, #queue-req: 0, 
[2025-12-17 20:27:03] INFO:     127.0.0.1:47322 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:05] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:05] INFO:     127.0.0.1:47326 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:05] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:05] Decode batch, #running-req: 1, #token: 770, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.97, #queue-req: 0, 
[2025-12-17 20:27:05] Decode batch, #running-req: 1, #token: 810, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.54, #queue-req: 0, 
[2025-12-17 20:27:06] Decode batch, #running-req: 1, #token: 850, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.53, #queue-req: 0, 
[2025-12-17 20:27:06] Decode batch, #running-req: 1, #token: 890, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.46, #queue-req: 0, 
[2025-12-17 20:27:06] Decode batch, #running-req: 1, #token: 930, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.59, #queue-req: 0, 
[2025-12-17 20:27:06] Decode batch, #running-req: 1, #token: 970, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.40, #queue-req: 0, 
[2025-12-17 20:27:06] Decode batch, #running-req: 1, #token: 1010, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.55, #queue-req: 0, 
[2025-12-17 20:27:06] Decode batch, #running-req: 1, #token: 1050, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.25, #queue-req: 0, 
[2025-12-17 20:27:07] Decode batch, #running-req: 1, #token: 1090, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:27:07] Decode batch, #running-req: 1, #token: 1130, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:27:07] Decode batch, #running-req: 1, #token: 1170, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:27:07] Decode batch, #running-req: 1, #token: 1210, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 20:27:07] Decode batch, #running-req: 1, #token: 1250, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:27:08] Decode batch, #running-req: 1, #token: 1290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:27:08] Decode batch, #running-req: 1, #token: 1330, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 20:27:08] Decode batch, #running-req: 1, #token: 1370, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 20:27:08] Decode batch, #running-req: 1, #token: 1410, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:27:08] Decode batch, #running-req: 1, #token: 1450, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:27:08] Decode batch, #running-req: 1, #token: 1490, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.06, #queue-req: 0, 
[2025-12-17 20:27:09] Decode batch, #running-req: 1, #token: 1530, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:27:09] Decode batch, #running-req: 1, #token: 1570, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:27:09] Decode batch, #running-req: 1, #token: 1610, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:27:09] Decode batch, #running-req: 1, #token: 1650, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:27:09] Decode batch, #running-req: 1, #token: 1690, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 20:27:10] Decode batch, #running-req: 1, #token: 1730, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 20:27:10] INFO:     127.0.0.1:47330 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:11] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:11] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.15, #queue-req: 0, 
[2025-12-17 20:27:11] INFO:     127.0.0.1:47338 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:11] Prefill batch, #new-seq: 1, #new-token: 1322, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:12] INFO:     127.0.0.1:47342 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:13] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:13] INFO:     127.0.0.1:47346 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:13] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:13] Decode batch, #running-req: 1, #token: 771, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.12, #queue-req: 0, 
[2025-12-17 20:27:13] INFO:     127.0.0.1:47350 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:15] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:15] INFO:     127.0.0.1:47354 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:15] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:15] INFO:     127.0.0.1:47358 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:17] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:17] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.05, #queue-req: 0, 
[2025-12-17 20:27:17] INFO:     127.0.0.1:47362 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:17] Prefill batch, #new-seq: 1, #new-token: 1310, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:17] INFO:     127.0.0.1:47366 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:19] Prefill batch, #new-seq: 1, #new-token: 60, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:19] Decode batch, #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.71, #queue-req: 0, 
[2025-12-17 20:27:19] INFO:     127.0.0.1:47372 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:19] Prefill batch, #new-seq: 1, #new-token: 25, #cached-token: 753, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:19] Decode batch, #running-req: 1, #token: 809, token usage: 0.00, cuda graph: True, gen throughput (token/s): 195.79, #queue-req: 0, 
[2025-12-17 20:27:19] INFO:     127.0.0.1:47376 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:21] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:21] INFO:     127.0.0.1:47380 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:21] Prefill batch, #new-seq: 1, #new-token: 1159, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:21] INFO:     127.0.0.1:47384 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:21] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.71, #queue-req: 0, 
[2025-12-17 20:27:23] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:23] INFO:     127.0.0.1:47390 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:23] Prefill batch, #new-seq: 1, #new-token: 1156, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:23] Decode batch, #running-req: 1, #token: 1209, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.05, #queue-req: 0, 
[2025-12-17 20:27:23] INFO:     127.0.0.1:47394 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:25] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:25] INFO:     127.0.0.1:47398 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:25] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:25] INFO:     127.0.0.1:47402 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:27] Prefill batch, #new-seq: 1, #new-token: 60, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:27] INFO:     127.0.0.1:47408 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:27] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.05, #queue-req: 0, 
[2025-12-17 20:27:27] Prefill batch, #new-seq: 1, #new-token: 27, #cached-token: 753, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:27] INFO:     127.0.0.1:47412 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:29] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:29] INFO:     127.0.0.1:47418 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:29] Prefill batch, #new-seq: 1, #new-token: 1150, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:29] Decode batch, #running-req: 1, #token: 1200, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.95, #queue-req: 0, 
[2025-12-17 20:27:29] INFO:     127.0.0.1:47422 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:31] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:31] INFO:     127.0.0.1:47426 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:31] Prefill batch, #new-seq: 1, #new-token: 21, #cached-token: 753, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:31] INFO:     127.0.0.1:47430 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:32] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:32] Decode batch, #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.66, #queue-req: 0, 
[2025-12-17 20:27:33] INFO:     127.0.0.1:47434 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:33] Prefill batch, #new-seq: 1, #new-token: 1113, #cached-token: 114, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:33] Decode batch, #running-req: 1, #token: 1247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 190.31, #queue-req: 0, 
[2025-12-17 20:27:33] INFO:     127.0.0.1:47438 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:34] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:35] INFO:     127.0.0.1:47442 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:35] Prefill batch, #new-seq: 1, #new-token: 905, #cached-token: 307, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:35] Decode batch, #running-req: 1, #token: 1225, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.68, #queue-req: 0, 
[2025-12-17 20:27:35] INFO:     127.0.0.1:47446 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:37] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:37] INFO:     127.0.0.1:47450 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:37] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:37] Decode batch, #running-req: 1, #token: 777, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.15, #queue-req: 0, 
[2025-12-17 20:27:37] INFO:     127.0.0.1:47454 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:39] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:39] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.13, #queue-req: 0, 
[2025-12-17 20:27:39] INFO:     127.0.0.1:47458 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:39] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 751, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:39] INFO:     127.0.0.1:47462 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:41] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:41] INFO:     127.0.0.1:47466 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:41] Prefill batch, #new-seq: 1, #new-token: 1263, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:41] Decode batch, #running-req: 1, #token: 1277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.78, #queue-req: 0, 
[2025-12-17 20:27:41] INFO:     127.0.0.1:47470 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:43] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:43] INFO:     127.0.0.1:47474 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:43] Prefill batch, #new-seq: 1, #new-token: 1152, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:43] Decode batch, #running-req: 1, #token: 1194, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.58, #queue-req: 0, 
[2025-12-17 20:27:43] INFO:     127.0.0.1:47478 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:45] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:45] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.28, #queue-req: 0, 
[2025-12-17 20:27:45] INFO:     127.0.0.1:47482 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:45] Prefill batch, #new-seq: 1, #new-token: 1143, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:45] INFO:     127.0.0.1:47486 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:47] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:47] INFO:     127.0.0.1:47490 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:47] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 1248, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:47] Decode batch, #running-req: 1, #token: 1277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.43, #queue-req: 0, 
[2025-12-17 20:27:47] INFO:     127.0.0.1:47494 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:49] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:49] INFO:     127.0.0.1:47498 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:49] Prefill batch, #new-seq: 1, #new-token: 1163, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:49] INFO:     127.0.0.1:47502 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:51] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:51] Decode batch, #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.00, #queue-req: 0, 
[2025-12-17 20:27:51] INFO:     127.0.0.1:47506 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:51] Prefill batch, #new-seq: 1, #new-token: 23, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:51] Decode batch, #running-req: 1, #token: 806, token usage: 0.00, cuda graph: True, gen throughput (token/s): 193.90, #queue-req: 0, 
[2025-12-17 20:27:51] Decode batch, #running-req: 1, #token: 846, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.55, #queue-req: 0, 
[2025-12-17 20:27:51] Decode batch, #running-req: 1, #token: 886, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.50, #queue-req: 0, 
[2025-12-17 20:27:51] Decode batch, #running-req: 1, #token: 926, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.52, #queue-req: 0, 
[2025-12-17 20:27:52] Decode batch, #running-req: 1, #token: 966, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.61, #queue-req: 0, 
[2025-12-17 20:27:52] Decode batch, #running-req: 1, #token: 1006, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.54, #queue-req: 0, 
[2025-12-17 20:27:52] Decode batch, #running-req: 1, #token: 1046, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.26, #queue-req: 0, 
[2025-12-17 20:27:52] Decode batch, #running-req: 1, #token: 1086, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.96, #queue-req: 0, 
[2025-12-17 20:27:52] Decode batch, #running-req: 1, #token: 1126, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:27:53] Decode batch, #running-req: 1, #token: 1166, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.07, #queue-req: 0, 
[2025-12-17 20:27:53] Decode batch, #running-req: 1, #token: 1206, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:27:53] Decode batch, #running-req: 1, #token: 1246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:27:53] Decode batch, #running-req: 1, #token: 1286, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.94, #queue-req: 0, 
[2025-12-17 20:27:53] Decode batch, #running-req: 1, #token: 1326, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:27:53] Decode batch, #running-req: 1, #token: 1366, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:27:54] Decode batch, #running-req: 1, #token: 1406, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:27:54] Decode batch, #running-req: 1, #token: 1446, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.09, #queue-req: 0, 
[2025-12-17 20:27:54] Decode batch, #running-req: 1, #token: 1486, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 20:27:54] Decode batch, #running-req: 1, #token: 1526, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:27:54] Decode batch, #running-req: 1, #token: 1566, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:27:55] Decode batch, #running-req: 1, #token: 1606, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 20:27:55] Decode batch, #running-req: 1, #token: 1646, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:27:55] Decode batch, #running-req: 1, #token: 1686, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:27:55] Decode batch, #running-req: 1, #token: 1726, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:27:55] Decode batch, #running-req: 1, #token: 1766, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:27:55] INFO:     127.0.0.1:47510 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:58] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:58] INFO:     127.0.0.1:47514 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:58] Prefill batch, #new-seq: 1, #new-token: 1090, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:58] INFO:     127.0.0.1:47518 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:59] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:27:59] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.60, #queue-req: 0, 
[2025-12-17 20:27:59] INFO:     127.0.0.1:47522 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:27:59] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 784, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:00] Decode batch, #running-req: 1, #token: 836, token usage: 0.00, cuda graph: True, gen throughput (token/s): 196.57, #queue-req: 0, 
[2025-12-17 20:28:00] INFO:     127.0.0.1:47526 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:01] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:01] INFO:     127.0.0.1:47532 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:01] Prefill batch, #new-seq: 1, #new-token: 1197, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:02] Decode batch, #running-req: 1, #token: 1241, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.51, #queue-req: 0, 
[2025-12-17 20:28:02] INFO:     127.0.0.1:47536 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:03] Prefill batch, #new-seq: 1, #new-token: 60, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:03] INFO:     127.0.0.1:47540 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:03] Prefill batch, #new-seq: 1, #new-token: 891, #cached-token: 438, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:03] INFO:     127.0.0.1:47544 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:05] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:05] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.00, #queue-req: 0, 
[2025-12-17 20:28:05] INFO:     127.0.0.1:47548 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:05] Prefill batch, #new-seq: 1, #new-token: 24, #cached-token: 753, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:05] INFO:     127.0.0.1:47552 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:07] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:07] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.20, #queue-req: 0, 
[2025-12-17 20:28:07] INFO:     127.0.0.1:47558 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:07] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 746, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:07] INFO:     127.0.0.1:47562 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:09] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:09] INFO:     127.0.0.1:47568 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:09] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 753, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:09] INFO:     127.0.0.1:47572 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:11] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:11] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.77, #queue-req: 0, 
[2025-12-17 20:28:11] INFO:     127.0.0.1:47576 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:11] Prefill batch, #new-seq: 1, #new-token: 1281, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:11] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 187.61, #queue-req: 0, 
[2025-12-17 20:28:11] INFO:     127.0.0.1:47580 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:13] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:13] INFO:     127.0.0.1:47584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:13] Prefill batch, #new-seq: 1, #new-token: 1332, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:13] Decode batch, #running-req: 1, #token: 1393, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.61, #queue-req: 0, 
[2025-12-17 20:28:13] INFO:     127.0.0.1:47588 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:15] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:15] INFO:     127.0.0.1:47592 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:15] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 783, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:15] INFO:     127.0.0.1:47596 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:17] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:17] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.99, #queue-req: 0, 
[2025-12-17 20:28:17] INFO:     127.0.0.1:47600 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:17] Prefill batch, #new-seq: 1, #new-token: 1036, #cached-token: 128, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:17] INFO:     127.0.0.1:47604 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:19] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:19] INFO:     127.0.0.1:47608 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:19] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 751, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:19] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.36, #queue-req: 0, 
[2025-12-17 20:28:19] INFO:     127.0.0.1:47612 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:21] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:21] INFO:     127.0.0.1:47616 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:21] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 1248, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:21] Decode batch, #running-req: 1, #token: 1287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.00, #queue-req: 0, 
[2025-12-17 20:28:21] INFO:     127.0.0.1:47620 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:23] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:23] INFO:     127.0.0.1:47624 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:23] Prefill batch, #new-seq: 1, #new-token: 1386, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:23] INFO:     127.0.0.1:47628 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:25] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:25] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.98, #queue-req: 0, 
[2025-12-17 20:28:25] INFO:     127.0.0.1:47632 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:25] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 784, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:25] INFO:     127.0.0.1:47636 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:27] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:27] INFO:     127.0.0.1:47640 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:27] Prefill batch, #new-seq: 1, #new-token: 1239, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:27] Decode batch, #running-req: 1, #token: 1275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.51, #queue-req: 0, 
[2025-12-17 20:28:27] INFO:     127.0.0.1:47644 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:29] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:29] INFO:     127.0.0.1:47648 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:29] Prefill batch, #new-seq: 1, #new-token: 1017, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:29] INFO:     127.0.0.1:47652 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:31] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:31] Decode batch, #running-req: 1, #token: 71, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.04, #queue-req: 0, 
[2025-12-17 20:28:31] INFO:     127.0.0.1:47656 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:31] Prefill batch, #new-seq: 1, #new-token: 998, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:31] INFO:     127.0.0.1:47660 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:32] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:32] INFO:     127.0.0.1:47664 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:32] Prefill batch, #new-seq: 1, #new-token: 1056, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:32] Decode batch, #running-req: 1, #token: 1095, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.41, #queue-req: 0, 
[2025-12-17 20:28:33] INFO:     127.0.0.1:47668 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:34] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:34] INFO:     127.0.0.1:47672 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:34] Prefill batch, #new-seq: 1, #new-token: 1135, #cached-token: 105, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:34] INFO:     127.0.0.1:47676 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:36] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:36] INFO:     127.0.0.1:47680 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:36] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.98, #queue-req: 0, 
[2025-12-17 20:28:36] Prefill batch, #new-seq: 1, #new-token: 1116, #cached-token: 142, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:36] INFO:     127.0.0.1:47684 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:38] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:38] INFO:     127.0.0.1:47688 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:38] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 751, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:38] Decode batch, #running-req: 1, #token: 785, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.09, #queue-req: 0, 
[2025-12-17 20:28:38] INFO:     127.0.0.1:47692 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:40] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:40] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.06, #queue-req: 0, 
[2025-12-17 20:28:40] INFO:     127.0.0.1:47696 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:40] Prefill batch, #new-seq: 1, #new-token: 1220, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:40] INFO:     127.0.0.1:47700 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:42] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:42] Decode batch, #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.47, #queue-req: 0, 
[2025-12-17 20:28:42] INFO:     127.0.0.1:47704 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:42] Prefill batch, #new-seq: 1, #new-token: 1142, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:42] INFO:     127.0.0.1:47708 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:44] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:44] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.93, #queue-req: 0, 
[2025-12-17 20:28:44] INFO:     127.0.0.1:47714 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:44] Prefill batch, #new-seq: 1, #new-token: 1115, #cached-token: 123, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:44] INFO:     127.0.0.1:47718 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:46] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:46] INFO:     127.0.0.1:47722 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:46] Prefill batch, #new-seq: 1, #new-token: 1276, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:46] Decode batch, #running-req: 1, #token: 1317, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.02, #queue-req: 0, 
[2025-12-17 20:28:46] INFO:     127.0.0.1:47726 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:48] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:48] INFO:     127.0.0.1:47732 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:48] Prefill batch, #new-seq: 1, #new-token: 1108, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:48] INFO:     127.0.0.1:47736 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:50] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:50] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.10, #queue-req: 0, 
[2025-12-17 20:28:50] INFO:     127.0.0.1:47742 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:50] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:50] INFO:     127.0.0.1:47746 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:52] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:52] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.57, #queue-req: 0, 
[2025-12-17 20:28:52] INFO:     127.0.0.1:47752 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:52] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 752, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:52] Decode batch, #running-req: 1, #token: 807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 194.10, #queue-req: 0, 
[2025-12-17 20:28:52] Decode batch, #running-req: 1, #token: 847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.16, #queue-req: 0, 
[2025-12-17 20:28:52] Decode batch, #running-req: 1, #token: 887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.28, #queue-req: 0, 
[2025-12-17 20:28:52] Decode batch, #running-req: 1, #token: 927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.31, #queue-req: 0, 
[2025-12-17 20:28:53] Decode batch, #running-req: 1, #token: 967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.45, #queue-req: 0, 
[2025-12-17 20:28:53] Decode batch, #running-req: 1, #token: 1007, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.35, #queue-req: 0, 
[2025-12-17 20:28:53] Decode batch, #running-req: 1, #token: 1047, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 20:28:53] Decode batch, #running-req: 1, #token: 1087, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:28:53] Decode batch, #running-req: 1, #token: 1127, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:28:54] Decode batch, #running-req: 1, #token: 1167, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 20:28:54] Decode batch, #running-req: 1, #token: 1207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:28:54] Decode batch, #running-req: 1, #token: 1247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:28:54] Decode batch, #running-req: 1, #token: 1287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:28:54] Decode batch, #running-req: 1, #token: 1327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 20:28:54] Decode batch, #running-req: 1, #token: 1367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:28:55] Decode batch, #running-req: 1, #token: 1407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 20:28:55] Decode batch, #running-req: 1, #token: 1447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:28:55] Decode batch, #running-req: 1, #token: 1487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:28:55] Decode batch, #running-req: 1, #token: 1527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 20:28:55] Decode batch, #running-req: 1, #token: 1567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.42, #queue-req: 0, 
[2025-12-17 20:28:56] Decode batch, #running-req: 1, #token: 1607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 20:28:56] Decode batch, #running-req: 1, #token: 1647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.28, #queue-req: 0, 
[2025-12-17 20:28:56] Decode batch, #running-req: 1, #token: 1687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.37, #queue-req: 0, 
[2025-12-17 20:28:56] Decode batch, #running-req: 1, #token: 1727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.29, #queue-req: 0, 
[2025-12-17 20:28:56] Decode batch, #running-req: 1, #token: 1767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.33, #queue-req: 0, 
[2025-12-17 20:28:56] INFO:     127.0.0.1:47756 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:58] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:58] INFO:     127.0.0.1:47760 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:28:58] Prefill batch, #new-seq: 1, #new-token: 1199, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:28:58] INFO:     127.0.0.1:47764 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:00] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:00] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.98, #queue-req: 0, 
[2025-12-17 20:29:00] INFO:     127.0.0.1:47768 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:00] Prefill batch, #new-seq: 1, #new-token: 951, #cached-token: 177, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:00] INFO:     127.0.0.1:47772 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:02] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:02] INFO:     127.0.0.1:47780 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:02] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 730, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:02] INFO:     127.0.0.1:47784 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:04] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:04] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.89, #queue-req: 0, 
[2025-12-17 20:29:04] INFO:     127.0.0.1:47788 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:04] Prefill batch, #new-seq: 1, #new-token: 1209, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:04] INFO:     127.0.0.1:47792 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:06] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:06] INFO:     127.0.0.1:47796 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:06] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 730, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:06] Decode batch, #running-req: 1, #token: 770, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.89, #queue-req: 0, 
[2025-12-17 20:29:06] INFO:     127.0.0.1:47800 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:08] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:08] INFO:     127.0.0.1:47804 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:08] Prefill batch, #new-seq: 1, #new-token: 1155, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:08] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.75, #queue-req: 0, 
[2025-12-17 20:29:08] INFO:     127.0.0.1:47808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:09] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:10] INFO:     127.0.0.1:47812 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:10] Prefill batch, #new-seq: 1, #new-token: 1158, #cached-token: 38, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:10] INFO:     127.0.0.1:47818 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:11] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:11] INFO:     127.0.0.1:47822 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:11] Prefill batch, #new-seq: 1, #new-token: 1183, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:11] Decode batch, #running-req: 1, #token: 1221, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.86, #queue-req: 0, 
[2025-12-17 20:29:11] INFO:     127.0.0.1:47826 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:13] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:14] INFO:     127.0.0.1:47830 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:14] Prefill batch, #new-seq: 1, #new-token: 1420, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:14] Decode batch, #running-req: 1, #token: 1464, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.51, #queue-req: 0, 
[2025-12-17 20:29:14] INFO:     127.0.0.1:47834 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:16] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:16] INFO:     127.0.0.1:48384 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:16] Prefill batch, #new-seq: 1, #new-token: 1073, #cached-token: 41, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:16] Decode batch, #running-req: 1, #token: 1122, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.59, #queue-req: 0, 
[2025-12-17 20:29:16] INFO:     127.0.0.1:48388 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:17] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:17] INFO:     127.0.0.1:48392 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:17] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 731, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:18] Decode batch, #running-req: 1, #token: 796, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.60, #queue-req: 0, 
[2025-12-17 20:29:18] INFO:     127.0.0.1:48396 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:19] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:19] INFO:     127.0.0.1:48402 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:19] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 762, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:19] INFO:     127.0.0.1:48406 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:21] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:21] INFO:     127.0.0.1:48410 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:21] Prefill batch, #new-seq: 1, #new-token: 841, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:21] Decode batch, #running-req: 1, #token: 877, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.51, #queue-req: 0, 
[2025-12-17 20:29:21] INFO:     127.0.0.1:48414 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:23] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:23] INFO:     127.0.0.1:48418 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:23] Prefill batch, #new-seq: 1, #new-token: 1290, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:23] Decode batch, #running-req: 1, #token: 1335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.53, #queue-req: 0, 
[2025-12-17 20:29:23] INFO:     127.0.0.1:48422 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:25] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:25] INFO:     127.0.0.1:48428 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:25] Prefill batch, #new-seq: 1, #new-token: 581, #cached-token: 215, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:25] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.80, #queue-req: 0, 
[2025-12-17 20:29:25] INFO:     127.0.0.1:48432 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:27] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:27] INFO:     127.0.0.1:48436 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:27] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 731, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:27] INFO:     127.0.0.1:48440 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:29] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:29] Decode batch, #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.82, #queue-req: 0, 
[2025-12-17 20:29:29] INFO:     127.0.0.1:48444 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:29] Prefill batch, #new-seq: 1, #new-token: 1139, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:29] INFO:     127.0.0.1:48448 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:31] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:31] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.53, #queue-req: 0, 
[2025-12-17 20:29:31] INFO:     127.0.0.1:48452 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:31] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 730, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:31] INFO:     127.0.0.1:48458 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:33] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:33] INFO:     127.0.0.1:48462 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:33] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 1226, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:33] Decode batch, #running-req: 1, #token: 1274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.38, #queue-req: 0, 
[2025-12-17 20:29:33] INFO:     127.0.0.1:48466 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:35] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:35] Decode batch, #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.83, #queue-req: 0, 
[2025-12-17 20:29:35] INFO:     127.0.0.1:48470 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:35] Prefill batch, #new-seq: 1, #new-token: 1024, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:35] INFO:     127.0.0.1:48474 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:37] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:37] INFO:     127.0.0.1:48478 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:37] Prefill batch, #new-seq: 1, #new-token: 1207, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:37] Decode batch, #running-req: 1, #token: 1224, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.21, #queue-req: 0, 
[2025-12-17 20:29:37] INFO:     127.0.0.1:48482 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:39] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:39] INFO:     127.0.0.1:48486 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:39] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 1226, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:39] INFO:     127.0.0.1:48490 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:41] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:41] INFO:     127.0.0.1:48494 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:41] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 1213, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:41] Decode batch, #running-req: 1, #token: 1263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.90, #queue-req: 0, 
[2025-12-17 20:29:41] INFO:     127.0.0.1:48498 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:43] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:43] Decode batch, #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.09, #queue-req: 0, 
[2025-12-17 20:29:43] INFO:     127.0.0.1:48502 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:43] Prefill batch, #new-seq: 1, #new-token: 1395, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:43] INFO:     127.0.0.1:48506 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:45] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:45] INFO:     127.0.0.1:48510 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:45] Prefill batch, #new-seq: 1, #new-token: 30, #cached-token: 1226, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:45] INFO:     127.0.0.1:48514 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:47] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:47] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.79, #queue-req: 0, 
[2025-12-17 20:29:47] INFO:     127.0.0.1:48518 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:47] Prefill batch, #new-seq: 1, #new-token: 1155, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:47] INFO:     127.0.0.1:48522 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:48] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:48] INFO:     127.0.0.1:48526 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:48] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 762, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:48] Decode batch, #running-req: 1, #token: 800, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.52, #queue-req: 0, 
[2025-12-17 20:29:48] INFO:     127.0.0.1:48530 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:50] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:50] INFO:     127.0.0.1:48534 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:50] Prefill batch, #new-seq: 1, #new-token: 1345, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:50] INFO:     127.0.0.1:48538 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:52] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:52] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.85, #queue-req: 0, 
[2025-12-17 20:29:52] INFO:     127.0.0.1:48542 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:52] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 731, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:52] INFO:     127.0.0.1:48546 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:54] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:54] INFO:     127.0.0.1:48550 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:54] Prefill batch, #new-seq: 1, #new-token: 1215, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:54] Decode batch, #running-req: 1, #token: 1254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.57, #queue-req: 0, 
[2025-12-17 20:29:54] INFO:     127.0.0.1:48554 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:56] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:56] INFO:     127.0.0.1:49716 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:56] Prefill batch, #new-seq: 1, #new-token: 1082, #cached-token: 120, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:56] INFO:     127.0.0.1:49720 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:58] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:58] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.90, #queue-req: 0, 
[2025-12-17 20:29:58] INFO:     127.0.0.1:49724 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:29:58] Prefill batch, #new-seq: 1, #new-token: 1172, #cached-token: 41, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:29:58] INFO:     127.0.0.1:49728 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:00] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:00] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.74, #queue-req: 0, 
[2025-12-17 20:30:00] INFO:     127.0.0.1:49734 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:00] Prefill batch, #new-seq: 1, #new-token: 1222, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:00] INFO:     127.0.0.1:49738 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:02] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:02] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.70, #queue-req: 0, 
[2025-12-17 20:30:02] INFO:     127.0.0.1:49742 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:02] Prefill batch, #new-seq: 1, #new-token: 1310, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:02] INFO:     127.0.0.1:49746 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:04] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:04] INFO:     127.0.0.1:49750 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:04] Prefill batch, #new-seq: 1, #new-token: 1275, #cached-token: 80, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:04] Decode batch, #running-req: 1, #token: 1360, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.89, #queue-req: 0, 
[2025-12-17 20:30:04] INFO:     127.0.0.1:49754 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:05] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:05] INFO:     127.0.0.1:49758 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:06] Prefill batch, #new-seq: 1, #new-token: 29, #cached-token: 731, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:06] INFO:     127.0.0.1:49762 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:07] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:07] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.71, #queue-req: 0, 
[2025-12-17 20:30:07] INFO:     127.0.0.1:49768 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:07] Prefill batch, #new-seq: 1, #new-token: 967, #cached-token: 122, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:08] INFO:     127.0.0.1:49772 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:10] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:10] INFO:     127.0.0.1:49776 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:10] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.73, #queue-req: 0, 
[2025-12-17 20:30:10] Prefill batch, #new-seq: 1, #new-token: 1027, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:10] INFO:     127.0.0.1:49780 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:12] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:12] INFO:     127.0.0.1:49784 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:12] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 730, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:12] Decode batch, #running-req: 1, #token: 775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.20, #queue-req: 0, 
[2025-12-17 20:30:12] INFO:     127.0.0.1:49788 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:14] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:14] INFO:     127.0.0.1:49792 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:14] Prefill batch, #new-seq: 1, #new-token: 1102, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:14] Decode batch, #running-req: 1, #token: 1158, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.66, #queue-req: 0, 
[2025-12-17 20:30:14] INFO:     127.0.0.1:49796 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:16] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:16] INFO:     127.0.0.1:49800 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:16] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 1227, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:16] INFO:     127.0.0.1:49804 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:18] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:18] Decode batch, #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.12, #queue-req: 0, 
[2025-12-17 20:30:18] INFO:     127.0.0.1:49808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:18] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 731, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:18] INFO:     127.0.0.1:49812 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:20] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:20] INFO:     127.0.0.1:49816 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:20] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 731, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:20] Decode batch, #running-req: 1, #token: 797, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.97, #queue-req: 0, 
[2025-12-17 20:30:20] INFO:     127.0.0.1:49820 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:22] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:22] INFO:     127.0.0.1:49824 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:22] Prefill batch, #new-seq: 1, #new-token: 1237, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:22] Decode batch, #running-req: 1, #token: 1287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.62, #queue-req: 0, 
[2025-12-17 20:30:22] INFO:     127.0.0.1:49830 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:24] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:24] INFO:     127.0.0.1:49834 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:24] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 1227, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:24] INFO:     127.0.0.1:49838 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:26] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:26] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.13, #queue-req: 0, 
[2025-12-17 20:30:26] INFO:     127.0.0.1:49842 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:26] Prefill batch, #new-seq: 1, #new-token: 941, #cached-token: 334, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:26] INFO:     127.0.0.1:49846 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:28] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:28] Decode batch, #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.64, #queue-req: 0, 
[2025-12-17 20:30:28] INFO:     127.0.0.1:49854 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:28] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 732, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:28] INFO:     127.0.0.1:49858 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:30] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:30] INFO:     127.0.0.1:49862 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:30] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 1227, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:30] Decode batch, #running-req: 1, #token: 1280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.84, #queue-req: 0, 
[2025-12-17 20:30:30] INFO:     127.0.0.1:49866 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:32] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:33] INFO:     127.0.0.1:49870 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:33] Prefill batch, #new-seq: 1, #new-token: 1012, #cached-token: 78, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:33] Decode batch, #running-req: 1, #token: 1092, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.01, #queue-req: 0, 
[2025-12-17 20:30:33] INFO:     127.0.0.1:49874 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:34] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:34] INFO:     127.0.0.1:49878 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:34] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 762, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:35] INFO:     127.0.0.1:49882 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:36] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:36] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.87, #queue-req: 0, 
[2025-12-17 20:30:36] INFO:     127.0.0.1:49888 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:36] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 763, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:36] INFO:     127.0.0.1:49892 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:38] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:38] INFO:     127.0.0.1:49896 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:38] Prefill batch, #new-seq: 1, #new-token: 1282, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:38] INFO:     127.0.0.1:49900 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:40] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:40] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.88, #queue-req: 0, 
[2025-12-17 20:30:40] INFO:     127.0.0.1:49904 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:40] Prefill batch, #new-seq: 1, #new-token: 1078, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:40] INFO:     127.0.0.1:49908 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:42] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:42] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.45, #queue-req: 0, 
[2025-12-17 20:30:42] INFO:     127.0.0.1:49912 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:42] Prefill batch, #new-seq: 1, #new-token: 1195, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:42] INFO:     127.0.0.1:49916 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:44] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:44] INFO:     127.0.0.1:49922 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:44] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.56, #queue-req: 0, 
[2025-12-17 20:30:44] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 730, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:44] INFO:     127.0.0.1:49926 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:46] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:46] INFO:     127.0.0.1:49930 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:46] Prefill batch, #new-seq: 1, #new-token: 927, #cached-token: 147, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:46] INFO:     127.0.0.1:49934 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:47] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:48] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.82, #queue-req: 0, 
[2025-12-17 20:30:48] INFO:     127.0.0.1:49938 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:48] Prefill batch, #new-seq: 1, #new-token: 856, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:48] INFO:     127.0.0.1:49942 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:49] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:50] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.33, #queue-req: 0, 
[2025-12-17 20:30:50] INFO:     127.0.0.1:49946 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:50] Prefill batch, #new-seq: 1, #new-token: 1234, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:50] INFO:     127.0.0.1:49950 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:51] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:51] INFO:     127.0.0.1:49954 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:51] Prefill batch, #new-seq: 1, #new-token: 1141, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:51] Decode batch, #running-req: 1, #token: 1181, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.25, #queue-req: 0, 
[2025-12-17 20:30:51] INFO:     127.0.0.1:49960 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:53] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:53] INFO:     127.0.0.1:49964 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:53] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 762, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:53] INFO:     127.0.0.1:49968 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:55] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:55] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.98, #queue-req: 0, 
[2025-12-17 20:30:55] INFO:     127.0.0.1:49974 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:55] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 1226, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:55] INFO:     127.0.0.1:49978 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:57] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:57] INFO:     127.0.0.1:49984 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:57] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 733, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:57] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.27, #queue-req: 0, 
[2025-12-17 20:30:57] INFO:     127.0.0.1:49988 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:59] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:59] INFO:     127.0.0.1:49992 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:30:59] Prefill batch, #new-seq: 1, #new-token: 1205, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:30:59] INFO:     127.0.0.1:49996 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:01] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:01] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.88, #queue-req: 0, 
[2025-12-17 20:31:01] INFO:     127.0.0.1:50002 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:01] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 731, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:01] INFO:     127.0.0.1:50006 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:03] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:03] INFO:     127.0.0.1:50010 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:03] Prefill batch, #new-seq: 1, #new-token: 1197, #cached-token: 138, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:03] Decode batch, #running-req: 1, #token: 1344, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.19, #queue-req: 0, 
[2025-12-17 20:31:03] INFO:     127.0.0.1:50014 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:05] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:05] INFO:     127.0.0.1:50018 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:05] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 731, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:05] INFO:     127.0.0.1:50022 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:11] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:11] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 4.59, #queue-req: 0, 
[2025-12-17 20:31:11] INFO:     127.0.0.1:50028 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:12] Prefill batch, #new-seq: 1, #new-token: 1420, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:12] INFO:     127.0.0.1:50032 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:14] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:14] INFO:     127.0.0.1:50036 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:14] Prefill batch, #new-seq: 1, #new-token: 998, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:14] INFO:     127.0.0.1:50040 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:14] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.45, #queue-req: 0, 
[2025-12-17 20:31:16] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:16] INFO:     127.0.0.1:50044 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:16] Prefill batch, #new-seq: 1, #new-token: 1224, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:16] INFO:     127.0.0.1:50048 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:17] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:17] Decode batch, #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.20, #queue-req: 0, 
[2025-12-17 20:31:18] INFO:     127.0.0.1:50054 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:18] Prefill batch, #new-seq: 1, #new-token: 1216, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:18] INFO:     127.0.0.1:50058 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:19] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:19] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.03, #queue-req: 0, 
[2025-12-17 20:31:19] INFO:     127.0.0.1:50062 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:19] Prefill batch, #new-seq: 1, #new-token: 982, #cached-token: 140, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:19] INFO:     127.0.0.1:50066 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:21] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:21] INFO:     127.0.0.1:50070 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:21] Prefill batch, #new-seq: 1, #new-token: 1190, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:21] Decode batch, #running-req: 1, #token: 1212, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.47, #queue-req: 0, 
[2025-12-17 20:31:21] INFO:     127.0.0.1:50074 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:23] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:23] INFO:     127.0.0.1:50078 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:23] Prefill batch, #new-seq: 1, #new-token: 880, #cached-token: 174, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:23] INFO:     127.0.0.1:50082 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:25] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:25] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.19, #queue-req: 0, 
[2025-12-17 20:31:25] INFO:     127.0.0.1:50086 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:25] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 1043, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:25] INFO:     127.0.0.1:50090 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:27] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:27] INFO:     127.0.0.1:50102 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:27] Prefill batch, #new-seq: 1, #new-token: 1090, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:27] Decode batch, #running-req: 1, #token: 1110, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.57, #queue-req: 0, 
[2025-12-17 20:31:27] INFO:     127.0.0.1:50106 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:29] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:29] INFO:     127.0.0.1:50114 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:29] Prefill batch, #new-seq: 1, #new-token: 1643, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:29] Decode batch, #running-req: 1, #token: 1680, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.20, #queue-req: 0, 
[2025-12-17 20:31:29] INFO:     127.0.0.1:50118 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:31] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:31] INFO:     127.0.0.1:50122 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:31] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 998, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:31] INFO:     127.0.0.1:50126 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:33] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:33] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.86, #queue-req: 0, 
[2025-12-17 20:31:33] INFO:     127.0.0.1:50130 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:33] Prefill batch, #new-seq: 1, #new-token: 8, #cached-token: 999, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:33] INFO:     127.0.0.1:50134 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:35] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:35] INFO:     127.0.0.1:50138 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:35] Prefill batch, #new-seq: 1, #new-token: 1072, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:35] Decode batch, #running-req: 1, #token: 1095, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.19, #queue-req: 0, 
[2025-12-17 20:31:35] INFO:     127.0.0.1:50142 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:36] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:37] INFO:     127.0.0.1:50146 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:37] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 999, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:37] Decode batch, #running-req: 1, #token: 1028, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.98, #queue-req: 0, 
[2025-12-17 20:31:37] INFO:     127.0.0.1:50150 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:38] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:38] INFO:     127.0.0.1:50154 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:38] Prefill batch, #new-seq: 1, #new-token: 1104, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:39] Decode batch, #running-req: 1, #token: 1133, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.32, #queue-req: 0, 
[2025-12-17 20:31:39] Decode batch, #running-req: 1, #token: 1173, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.90, #queue-req: 0, 
[2025-12-17 20:31:39] Decode batch, #running-req: 1, #token: 1213, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.92, #queue-req: 0, 
[2025-12-17 20:31:39] Decode batch, #running-req: 1, #token: 1253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:31:39] Decode batch, #running-req: 1, #token: 1293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 20:31:39] Decode batch, #running-req: 1, #token: 1333, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:31:40] Decode batch, #running-req: 1, #token: 1373, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:31:40] Decode batch, #running-req: 1, #token: 1413, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:31:40] Decode batch, #running-req: 1, #token: 1453, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.08, #queue-req: 0, 
[2025-12-17 20:31:40] Decode batch, #running-req: 1, #token: 1493, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.02, #queue-req: 0, 
[2025-12-17 20:31:40] Decode batch, #running-req: 1, #token: 1533, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.99, #queue-req: 0, 
[2025-12-17 20:31:41] Decode batch, #running-req: 1, #token: 1573, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:31:41] Decode batch, #running-req: 1, #token: 1613, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:31:41] Decode batch, #running-req: 1, #token: 1653, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 20:31:41] Decode batch, #running-req: 1, #token: 1693, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:31:41] Decode batch, #running-req: 1, #token: 1733, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 20:31:41] Decode batch, #running-req: 1, #token: 1773, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:31:42] Decode batch, #running-req: 1, #token: 1813, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:31:42] Decode batch, #running-req: 1, #token: 1853, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 20:31:42] Decode batch, #running-req: 1, #token: 1893, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.63, #queue-req: 0, 
[2025-12-17 20:31:42] Decode batch, #running-req: 1, #token: 1933, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.53, #queue-req: 0, 
[2025-12-17 20:31:42] Decode batch, #running-req: 1, #token: 1973, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 20:31:43] Decode batch, #running-req: 1, #token: 2013, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:31:43] Decode batch, #running-req: 1, #token: 2053, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:31:43] Decode batch, #running-req: 1, #token: 2093, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.30, #queue-req: 0, 
[2025-12-17 20:31:43] INFO:     127.0.0.1:50158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:45] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:45] Decode batch, #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.64, #queue-req: 0, 
[2025-12-17 20:31:45] INFO:     127.0.0.1:50162 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:45] Prefill batch, #new-seq: 1, #new-token: 1419, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:45] INFO:     127.0.0.1:50166 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:47] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:47] INFO:     127.0.0.1:50170 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:47] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 1110, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:47] Decode batch, #running-req: 1, #token: 1130, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.84, #queue-req: 0, 
[2025-12-17 20:31:47] INFO:     127.0.0.1:50174 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:49] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:49] INFO:     127.0.0.1:50180 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:49] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 1068, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:49] INFO:     127.0.0.1:50184 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:50] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:51] INFO:     127.0.0.1:50188 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:51] Prefill batch, #new-seq: 1, #new-token: 758, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:51] Decode batch, #running-req: 1, #token: 772, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.15, #queue-req: 0, 
[2025-12-17 20:31:51] INFO:     127.0.0.1:50192 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:52] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:52] INFO:     127.0.0.1:50196 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:52] Prefill batch, #new-seq: 1, #new-token: 1486, #cached-token: 18, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:52] Decode batch, #running-req: 1, #token: 1515, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.33, #queue-req: 0, 
[2025-12-17 20:31:52] INFO:     127.0.0.1:50200 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:54] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:54] INFO:     127.0.0.1:50204 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:54] Prefill batch, #new-seq: 1, #new-token: 789, #cached-token: 310, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:54] INFO:     127.0.0.1:50208 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:56] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:56] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.14, #queue-req: 0, 
[2025-12-17 20:31:56] INFO:     127.0.0.1:50212 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:56] Prefill batch, #new-seq: 1, #new-token: 925, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:56] INFO:     127.0.0.1:50216 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:58] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:58] Decode batch, #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.55, #queue-req: 0, 
[2025-12-17 20:31:58] INFO:     127.0.0.1:50220 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:31:58] Prefill batch, #new-seq: 1, #new-token: 1007, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:31:58] INFO:     127.0.0.1:50224 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:00] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:00] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.16, #queue-req: 0, 
[2025-12-17 20:32:00] INFO:     127.0.0.1:50228 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:00] Prefill batch, #new-seq: 1, #new-token: 969, #cached-token: 138, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:00] INFO:     127.0.0.1:50232 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:02] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:02] INFO:     127.0.0.1:50236 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:02] Prefill batch, #new-seq: 1, #new-token: 1396, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:02] Decode batch, #running-req: 1, #token: 1418, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.99, #queue-req: 0, 
[2025-12-17 20:32:02] INFO:     127.0.0.1:50240 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:04] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:04] INFO:     127.0.0.1:50244 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:04] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 999, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:04] INFO:     127.0.0.1:50248 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:06] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:06] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.30, #queue-req: 0, 
[2025-12-17 20:32:06] INFO:     127.0.0.1:50252 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:06] Prefill batch, #new-seq: 1, #new-token: 875, #cached-token: 172, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:06] INFO:     127.0.0.1:50256 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:07] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:07] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.42, #queue-req: 0, 
[2025-12-17 20:32:07] INFO:     127.0.0.1:50260 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:07] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 978, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:08] INFO:     127.0.0.1:50264 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:09] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:09] INFO:     127.0.0.1:50268 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:09] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 1069, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:09] Decode batch, #running-req: 1, #token: 1091, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.09, #queue-req: 0, 
[2025-12-17 20:32:09] INFO:     127.0.0.1:50272 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:11] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:11] INFO:     127.0.0.1:50276 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:11] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 1026, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:11] INFO:     127.0.0.1:50280 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:13] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:13] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.36, #queue-req: 0, 
[2025-12-17 20:32:13] INFO:     127.0.0.1:50284 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:13] Prefill batch, #new-seq: 1, #new-token: 1191, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:13] INFO:     127.0.0.1:50288 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:15] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:15] INFO:     127.0.0.1:50292 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:15] Prefill batch, #new-seq: 1, #new-token: 1277, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:15] INFO:     127.0.0.1:50296 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:17] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:17] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.09, #queue-req: 0, 
[2025-12-17 20:32:17] INFO:     127.0.0.1:50306 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:17] Prefill batch, #new-seq: 1, #new-token: 1232, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:17] INFO:     127.0.0.1:50310 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:19] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:19] Decode batch, #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.96, #queue-req: 0, 
[2025-12-17 20:32:19] INFO:     127.0.0.1:50314 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:19] Prefill batch, #new-seq: 1, #new-token: 865, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:19] INFO:     127.0.0.1:50318 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:21] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:21] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.03, #queue-req: 0, 
[2025-12-17 20:32:21] INFO:     127.0.0.1:50324 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:21] Prefill batch, #new-seq: 1, #new-token: 1230, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:21] INFO:     127.0.0.1:50328 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:23] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:23] INFO:     127.0.0.1:50334 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:23] Prefill batch, #new-seq: 1, #new-token: 1245, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:23] INFO:     127.0.0.1:50338 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:23] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.05, #queue-req: 0, 
[2025-12-17 20:32:24] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:24] INFO:     127.0.0.1:50342 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:24] Prefill batch, #new-seq: 1, #new-token: 1264, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:24] INFO:     127.0.0.1:50346 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:26] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:26] INFO:     127.0.0.1:50350 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:26] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.13, #queue-req: 0, 
[2025-12-17 20:32:26] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 999, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:26] INFO:     127.0.0.1:50354 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:28] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:28] INFO:     127.0.0.1:50360 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:28] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 1086, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:28] Decode batch, #running-req: 1, #token: 1108, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.09, #queue-req: 0, 
[2025-12-17 20:32:28] INFO:     127.0.0.1:50364 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:30] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:30] INFO:     127.0.0.1:50368 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:30] Prefill batch, #new-seq: 1, #new-token: 1295, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:30] Decode batch, #running-req: 1, #token: 1327, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.27, #queue-req: 0, 
[2025-12-17 20:32:30] Decode batch, #running-req: 1, #token: 1367, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:32:30] Decode batch, #running-req: 1, #token: 1407, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:32:31] Decode batch, #running-req: 1, #token: 1447, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:32:31] Decode batch, #running-req: 1, #token: 1487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.97, #queue-req: 0, 
[2025-12-17 20:32:31] Decode batch, #running-req: 1, #token: 1527, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:32:31] Decode batch, #running-req: 1, #token: 1567, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:32:31] Decode batch, #running-req: 1, #token: 1607, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:32:31] Decode batch, #running-req: 1, #token: 1647, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:32:32] Decode batch, #running-req: 1, #token: 1687, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:32:32] Decode batch, #running-req: 1, #token: 1727, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:32:32] Decode batch, #running-req: 1, #token: 1767, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:32:32] Decode batch, #running-req: 1, #token: 1807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 20:32:32] Decode batch, #running-req: 1, #token: 1847, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:32:33] Decode batch, #running-req: 1, #token: 1887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 20:32:33] Decode batch, #running-req: 1, #token: 1927, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.55, #queue-req: 0, 
[2025-12-17 20:32:33] Decode batch, #running-req: 1, #token: 1967, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:32:33] Decode batch, #running-req: 1, #token: 2007, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:32:33] Decode batch, #running-req: 1, #token: 2047, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:32:33] Decode batch, #running-req: 1, #token: 2087, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.30, #queue-req: 0, 
[2025-12-17 20:32:34] Decode batch, #running-req: 1, #token: 2127, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.28, #queue-req: 0, 
[2025-12-17 20:32:34] Decode batch, #running-req: 1, #token: 2167, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.29, #queue-req: 0, 
[2025-12-17 20:32:34] Decode batch, #running-req: 1, #token: 2207, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.08, #queue-req: 0, 
[2025-12-17 20:32:34] Decode batch, #running-req: 1, #token: 2247, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.19, #queue-req: 0, 
[2025-12-17 20:32:34] Decode batch, #running-req: 1, #token: 2287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.28, #queue-req: 0, 
[2025-12-17 20:32:34] INFO:     127.0.0.1:50372 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:36] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:36] INFO:     127.0.0.1:50376 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:36] Prefill batch, #new-seq: 1, #new-token: 1545, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:36] Decode batch, #running-req: 1, #token: 1563, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.90, #queue-req: 0, 
[2025-12-17 20:32:36] INFO:     127.0.0.1:50380 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:38] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:38] INFO:     127.0.0.1:50386 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:38] Prefill batch, #new-seq: 1, #new-token: 1294, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:38] INFO:     127.0.0.1:50390 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:40] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:40] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.42, #queue-req: 0, 
[2025-12-17 20:32:40] INFO:     127.0.0.1:50394 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:40] Prefill batch, #new-seq: 1, #new-token: 1357, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:40] INFO:     127.0.0.1:50398 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:42] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:42] INFO:     127.0.0.1:50404 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:42] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 952, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:42] INFO:     127.0.0.1:50408 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:44] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:44] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.99, #queue-req: 0, 
[2025-12-17 20:32:44] INFO:     127.0.0.1:50412 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:44] Prefill batch, #new-seq: 1, #new-token: 1335, #cached-token: 166, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:44] INFO:     127.0.0.1:50416 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:46] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:46] Decode batch, #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.30, #queue-req: 0, 
[2025-12-17 20:32:46] INFO:     127.0.0.1:50420 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:46] Prefill batch, #new-seq: 1, #new-token: 1298, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:46] INFO:     127.0.0.1:50424 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:47] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:47] INFO:     127.0.0.1:50430 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:47] Prefill batch, #new-seq: 1, #new-token: 1346, #cached-token: 142, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:48] INFO:     127.0.0.1:50434 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:49] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:49] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.23, #queue-req: 0, 
[2025-12-17 20:32:49] INFO:     127.0.0.1:50438 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:49] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 996, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:49] INFO:     127.0.0.1:50442 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:51] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:51] INFO:     127.0.0.1:50448 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:51] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 1069, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:51] Decode batch, #running-req: 1, #token: 1094, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.11, #queue-req: 0, 
[2025-12-17 20:32:51] Decode batch, #running-req: 1, #token: 1134, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:32:51] Decode batch, #running-req: 1, #token: 1174, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:32:52] Decode batch, #running-req: 1, #token: 1214, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 20:32:52] Decode batch, #running-req: 1, #token: 1254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:32:52] Decode batch, #running-req: 1, #token: 1294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 20:32:52] Decode batch, #running-req: 1, #token: 1334, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:32:52] Decode batch, #running-req: 1, #token: 1374, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:32:53] Decode batch, #running-req: 1, #token: 1414, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.45, #queue-req: 0, 
[2025-12-17 20:32:53] Decode batch, #running-req: 1, #token: 1454, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:32:53] Decode batch, #running-req: 1, #token: 1494, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:32:53] Decode batch, #running-req: 1, #token: 1534, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:32:53] Decode batch, #running-req: 1, #token: 1574, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 20:32:53] Decode batch, #running-req: 1, #token: 1614, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.33, #queue-req: 0, 
[2025-12-17 20:32:54] Decode batch, #running-req: 1, #token: 1654, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.45, #queue-req: 0, 
[2025-12-17 20:32:54] Decode batch, #running-req: 1, #token: 1694, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.46, #queue-req: 0, 
[2025-12-17 20:32:54] Decode batch, #running-req: 1, #token: 1734, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.37, #queue-req: 0, 
[2025-12-17 20:32:54] Decode batch, #running-req: 1, #token: 1774, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.35, #queue-req: 0, 
[2025-12-17 20:32:54] Decode batch, #running-req: 1, #token: 1814, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.46, #queue-req: 0, 
[2025-12-17 20:32:55] Decode batch, #running-req: 1, #token: 1854, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.33, #queue-req: 0, 
[2025-12-17 20:32:55] Decode batch, #running-req: 1, #token: 1894, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.39, #queue-req: 0, 
[2025-12-17 20:32:55] Decode batch, #running-req: 1, #token: 1934, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.28, #queue-req: 0, 
[2025-12-17 20:32:55] Decode batch, #running-req: 1, #token: 1974, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:32:55] Decode batch, #running-req: 1, #token: 2014, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 20:32:55] Decode batch, #running-req: 1, #token: 2054, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.30, #queue-req: 0, 
[2025-12-17 20:32:56] INFO:     127.0.0.1:50452 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:57] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:57] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.69, #queue-req: 0, 
[2025-12-17 20:32:57] INFO:     127.0.0.1:50458 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:32:57] Prefill batch, #new-seq: 1, #new-token: 787, #cached-token: 308, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:32:58] Decode batch, #running-req: 1, #token: 1132, token usage: 0.00, cuda graph: True, gen throughput (token/s): 191.98, #queue-req: 0, 
[2025-12-17 20:32:58] Decode batch, #running-req: 1, #token: 1172, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:32:58] Decode batch, #running-req: 1, #token: 1212, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:32:58] Decode batch, #running-req: 1, #token: 1252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.90, #queue-req: 0, 
[2025-12-17 20:32:58] Decode batch, #running-req: 1, #token: 1292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:32:58] Decode batch, #running-req: 1, #token: 1332, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:32:59] Decode batch, #running-req: 1, #token: 1372, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:32:59] Decode batch, #running-req: 1, #token: 1412, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:32:59] Decode batch, #running-req: 1, #token: 1452, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.02, #queue-req: 0, 
[2025-12-17 20:32:59] Decode batch, #running-req: 1, #token: 1492, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.88, #queue-req: 0, 
[2025-12-17 20:32:59] Decode batch, #running-req: 1, #token: 1532, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 20:32:59] Decode batch, #running-req: 1, #token: 1572, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:33:00] Decode batch, #running-req: 1, #token: 1612, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:33:00] Decode batch, #running-req: 1, #token: 1652, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:33:00] Decode batch, #running-req: 1, #token: 1692, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:33:00] Decode batch, #running-req: 1, #token: 1732, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:33:00] Decode batch, #running-req: 1, #token: 1772, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 20:33:01] Decode batch, #running-req: 1, #token: 1812, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:33:01] Decode batch, #running-req: 1, #token: 1852, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.49, #queue-req: 0, 
[2025-12-17 20:33:01] Decode batch, #running-req: 1, #token: 1892, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:33:01] Decode batch, #running-req: 1, #token: 1932, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:33:01] Decode batch, #running-req: 1, #token: 1972, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:33:01] Decode batch, #running-req: 1, #token: 2012, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 20:33:02] Decode batch, #running-req: 1, #token: 2052, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:33:02] Decode batch, #running-req: 1, #token: 2092, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.27, #queue-req: 0, 
[2025-12-17 20:33:02] INFO:     127.0.0.1:50462 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:04] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:04] INFO:     127.0.0.1:50466 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:04] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 979, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:04] INFO:     127.0.0.1:50470 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:06] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:06] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.78, #queue-req: 0, 
[2025-12-17 20:33:06] INFO:     127.0.0.1:50474 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:06] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 1092, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:06] INFO:     127.0.0.1:50478 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:08] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:08] Decode batch, #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.25, #queue-req: 0, 
[2025-12-17 20:33:08] INFO:     127.0.0.1:50482 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:08] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 1065, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:08] INFO:     127.0.0.1:50486 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:10] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:10] INFO:     127.0.0.1:50492 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:10] Prefill batch, #new-seq: 1, #new-token: 21, #cached-token: 980, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:10] INFO:     127.0.0.1:50496 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:11] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:11] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.24, #queue-req: 0, 
[2025-12-17 20:33:11] INFO:     127.0.0.1:50500 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:11] Prefill batch, #new-seq: 1, #new-token: 1604, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:12] INFO:     127.0.0.1:50504 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:13] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:13] INFO:     127.0.0.1:50510 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:13] Prefill batch, #new-seq: 1, #new-token: 1197, #cached-token: 145, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:13] Decode batch, #running-req: 1, #token: 1346, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.90, #queue-req: 0, 
[2025-12-17 20:33:13] INFO:     127.0.0.1:50514 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:15] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:15] INFO:     127.0.0.1:50518 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:15] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 1068, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:15] INFO:     127.0.0.1:50522 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:17] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:17] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.29, #queue-req: 0, 
[2025-12-17 20:33:17] INFO:     127.0.0.1:50526 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:17] Prefill batch, #new-seq: 1, #new-token: 7, #cached-token: 999, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:17] INFO:     127.0.0.1:50530 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:19] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:19] INFO:     127.0.0.1:50534 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:19] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 996, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:19] Decode batch, #running-req: 1, #token: 1022, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.25, #queue-req: 0, 
[2025-12-17 20:33:19] INFO:     127.0.0.1:50538 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:20] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:20] INFO:     127.0.0.1:50542 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:20] Prefill batch, #new-seq: 1, #new-token: 24, #cached-token: 997, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:21] INFO:     127.0.0.1:50546 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:22] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:22] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.19, #queue-req: 0, 
[2025-12-17 20:33:22] INFO:     127.0.0.1:50550 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:22] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 1025, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:22] INFO:     127.0.0.1:50554 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:24] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:24] INFO:     127.0.0.1:50558 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:24] Prefill batch, #new-seq: 1, #new-token: 1200, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:24] INFO:     127.0.0.1:50562 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:26] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:26] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.13, #queue-req: 0, 
[2025-12-17 20:33:26] INFO:     127.0.0.1:50568 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:26] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 979, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:26] Decode batch, #running-req: 1, #token: 1025, token usage: 0.00, cuda graph: True, gen throughput (token/s): 193.73, #queue-req: 0, 
[2025-12-17 20:33:26] Decode batch, #running-req: 1, #token: 1065, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.16, #queue-req: 0, 
[2025-12-17 20:33:26] Decode batch, #running-req: 1, #token: 1105, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 20:33:27] Decode batch, #running-req: 1, #token: 1145, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.92, #queue-req: 0, 
[2025-12-17 20:33:27] Decode batch, #running-req: 1, #token: 1185, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.01, #queue-req: 0, 
[2025-12-17 20:33:27] Decode batch, #running-req: 1, #token: 1225, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:33:27] Decode batch, #running-req: 1, #token: 1265, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:33:27] Decode batch, #running-req: 1, #token: 1305, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:33:28] Decode batch, #running-req: 1, #token: 1345, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:33:28] Decode batch, #running-req: 1, #token: 1385, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:33:28] Decode batch, #running-req: 1, #token: 1425, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.01, #queue-req: 0, 
[2025-12-17 20:33:28] Decode batch, #running-req: 1, #token: 1465, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.07, #queue-req: 0, 
[2025-12-17 20:33:28] Decode batch, #running-req: 1, #token: 1505, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:33:28] Decode batch, #running-req: 1, #token: 1545, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:33:29] Decode batch, #running-req: 1, #token: 1585, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:33:29] Decode batch, #running-req: 1, #token: 1625, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:33:29] Decode batch, #running-req: 1, #token: 1665, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:33:29] Decode batch, #running-req: 1, #token: 1705, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:33:29] Decode batch, #running-req: 1, #token: 1745, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 20:33:30] Decode batch, #running-req: 1, #token: 1785, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:33:30] Decode batch, #running-req: 1, #token: 1825, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:33:30] Decode batch, #running-req: 1, #token: 1865, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:33:30] Decode batch, #running-req: 1, #token: 1905, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:33:30] Decode batch, #running-req: 1, #token: 1945, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:33:30] Decode batch, #running-req: 1, #token: 1985, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:33:31] INFO:     127.0.0.1:50572 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:32] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:32] INFO:     127.0.0.1:50576 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:32] Prefill batch, #new-seq: 1, #new-token: 1345, #cached-token: 38, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:32] INFO:     127.0.0.1:50580 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:34] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:34] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.16, #queue-req: 0, 
[2025-12-17 20:33:34] INFO:     127.0.0.1:50584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:34] Prefill batch, #new-seq: 1, #new-token: 969, #cached-token: 327, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:34] INFO:     127.0.0.1:50588 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:36] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:36] INFO:     127.0.0.1:50594 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:36] Prefill batch, #new-seq: 1, #new-token: 1300, #cached-token: 179, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:36] Decode batch, #running-req: 1, #token: 1487, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.77, #queue-req: 0, 
[2025-12-17 20:33:36] INFO:     127.0.0.1:50598 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:38] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:38] INFO:     127.0.0.1:50604 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:38] Prefill batch, #new-seq: 1, #new-token: 1334, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:38] Decode batch, #running-req: 1, #token: 1350, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.34, #queue-req: 0, 
[2025-12-17 20:33:38] INFO:     127.0.0.1:50608 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:40] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:40] INFO:     127.0.0.1:50612 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:40] Prefill batch, #new-seq: 1, #new-token: 1005, #cached-token: 163, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:40] Decode batch, #running-req: 1, #token: 1175, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.23, #queue-req: 0, 
[2025-12-17 20:33:40] INFO:     127.0.0.1:50616 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:42] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:42] INFO:     127.0.0.1:50620 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:42] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 978, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:42] Decode batch, #running-req: 1, #token: 1017, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.36, #queue-req: 0, 
[2025-12-17 20:33:42] INFO:     127.0.0.1:50624 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:43] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:44] INFO:     127.0.0.1:50628 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:44] Prefill batch, #new-seq: 1, #new-token: 455, #cached-token: 308, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:44] Decode batch, #running-req: 1, #token: 784, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.06, #queue-req: 0, 
[2025-12-17 20:33:44] INFO:     127.0.0.1:50632 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:45] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:45] INFO:     127.0.0.1:50636 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:45] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 979, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:46] INFO:     127.0.0.1:50640 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:47] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:47] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.29, #queue-req: 0, 
[2025-12-17 20:33:47] INFO:     127.0.0.1:50644 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:47] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 1083, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:47] INFO:     127.0.0.1:50648 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:49] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:49] INFO:     127.0.0.1:50652 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:49] Prefill batch, #new-seq: 1, #new-token: 1446, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:49] Decode batch, #running-req: 1, #token: 1486, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.99, #queue-req: 0, 
[2025-12-17 20:33:49] INFO:     127.0.0.1:50656 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:51] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:51] INFO:     127.0.0.1:50660 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:51] Prefill batch, #new-seq: 1, #new-token: 1387, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:51] Decode batch, #running-req: 1, #token: 1412, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.24, #queue-req: 0, 
[2025-12-17 20:33:51] INFO:     127.0.0.1:50664 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:53] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:53] INFO:     127.0.0.1:50668 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:53] Prefill batch, #new-seq: 1, #new-token: 1124, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:53] INFO:     127.0.0.1:50672 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:55] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:55] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.29, #queue-req: 0, 
[2025-12-17 20:33:55] INFO:     127.0.0.1:50678 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:55] Prefill batch, #new-seq: 1, #new-token: 1247, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:55] INFO:     127.0.0.1:50682 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:57] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:57] INFO:     127.0.0.1:50686 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:57] Prefill batch, #new-seq: 1, #new-token: 1435, #cached-token: 37, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:57] Decode batch, #running-req: 1, #token: 1474, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.30, #queue-req: 0, 
[2025-12-17 20:33:57] INFO:     127.0.0.1:50690 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:59] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:59] INFO:     127.0.0.1:50694 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:33:59] Prefill batch, #new-seq: 1, #new-token: 1264, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:33:59] INFO:     127.0.0.1:50698 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:01] Prefill batch, #new-seq: 1, #new-token: 66, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:01] Decode batch, #running-req: 1, #token: 103, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.76, #queue-req: 0, 
[2025-12-17 20:34:01] INFO:     127.0.0.1:50702 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:01] Prefill batch, #new-seq: 1, #new-token: 992, #cached-token: 17, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:01] INFO:     127.0.0.1:50706 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:03] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:03] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.49, #queue-req: 0, 
[2025-12-17 20:34:03] INFO:     127.0.0.1:50710 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:03] Prefill batch, #new-seq: 1, #new-token: 1176, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:03] INFO:     127.0.0.1:50714 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:05] Prefill batch, #new-seq: 1, #new-token: 65, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:05] Decode batch, #running-req: 1, #token: 98, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.32, #queue-req: 0, 
[2025-12-17 20:34:05] INFO:     127.0.0.1:50718 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:05] Prefill batch, #new-seq: 1, #new-token: 31, #cached-token: 1026, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:05] INFO:     127.0.0.1:50722 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:07] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:07] INFO:     127.0.0.1:50728 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:07] Prefill batch, #new-seq: 1, #new-token: 992, #cached-token: 94, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:07] Decode batch, #running-req: 1, #token: 1091, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.31, #queue-req: 0, 
[2025-12-17 20:34:07] INFO:     127.0.0.1:50732 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:09] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:09] INFO:     127.0.0.1:50736 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:09] Prefill batch, #new-seq: 1, #new-token: 1217, #cached-token: 171, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:09] INFO:     127.0.0.1:50740 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:10] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:11] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.98, #queue-req: 0, 
[2025-12-17 20:34:11] INFO:     127.0.0.1:50744 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:11] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 979, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:11] Decode batch, #running-req: 1, #token: 1027, token usage: 0.00, cuda graph: True, gen throughput (token/s): 198.03, #queue-req: 0, 
[2025-12-17 20:34:11] INFO:     127.0.0.1:50748 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:12] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:13] INFO:     127.0.0.1:50752 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:13] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 1027, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:13] Decode batch, #running-req: 1, #token: 1052, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.38, #queue-req: 0, 
[2025-12-17 20:34:13] INFO:     127.0.0.1:50756 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:14] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:14] INFO:     127.0.0.1:50760 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:14] Prefill batch, #new-seq: 1, #new-token: 23, #cached-token: 981, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:15] Decode batch, #running-req: 1, #token: 1024, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.81, #queue-req: 0, 
[2025-12-17 20:34:15] INFO:     127.0.0.1:50764 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:16] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:16] INFO:     127.0.0.1:50768 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:16] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 1069, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:16] INFO:     127.0.0.1:50772 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:18] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:18] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.25, #queue-req: 0, 
[2025-12-17 20:34:18] INFO:     127.0.0.1:50776 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:18] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 979, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:19] INFO:     127.0.0.1:50780 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:20] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:20] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.05, #queue-req: 0, 
[2025-12-17 20:34:20] INFO:     127.0.0.1:50784 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:20] Prefill batch, #new-seq: 1, #new-token: 1189, #cached-token: 107, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:21] Decode batch, #running-req: 1, #token: 1336, token usage: 0.00, cuda graph: True, gen throughput (token/s): 188.68, #queue-req: 0, 
[2025-12-17 20:34:21] INFO:     127.0.0.1:50788 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:22] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:23] INFO:     127.0.0.1:50792 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:23] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 1092, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:23] Decode batch, #running-req: 1, #token: 1119, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.96, #queue-req: 0, 
[2025-12-17 20:34:23] INFO:     127.0.0.1:50796 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:24] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:24] INFO:     127.0.0.1:50800 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:24] Prefill batch, #new-seq: 1, #new-token: 1553, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:25] INFO:     127.0.0.1:50804 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:25] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.00, #queue-req: 0, 
[2025-12-17 20:34:26] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:26] INFO:     127.0.0.1:50810 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:26] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 1069, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:26] INFO:     127.0.0.1:50814 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:29] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:29] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.71, #queue-req: 0, 
[2025-12-17 20:34:29] INFO:     127.0.0.1:50818 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:29] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 980, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:29] INFO:     127.0.0.1:50822 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:30] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:31] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.94, #queue-req: 0, 
[2025-12-17 20:34:31] INFO:     127.0.0.1:50826 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:31] Prefill batch, #new-seq: 1, #new-token: 1291, #cached-token: 173, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:31] INFO:     127.0.0.1:50830 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:32] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:32] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.29, #queue-req: 0, 
[2025-12-17 20:34:33] INFO:     127.0.0.1:50834 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:33] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 979, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:33] INFO:     127.0.0.1:50838 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:35] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:35] INFO:     127.0.0.1:50844 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:35] Prefill batch, #new-seq: 1, #new-token: 1212, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:35] Decode batch, #running-req: 1, #token: 1227, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.37, #queue-req: 0, 
[2025-12-17 20:34:35] INFO:     127.0.0.1:50848 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:37] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:37] INFO:     127.0.0.1:50856 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:37] Prefill batch, #new-seq: 1, #new-token: 780, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:37] Decode batch, #running-req: 1, #token: 829, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.85, #queue-req: 0, 
[2025-12-17 20:34:37] INFO:     127.0.0.1:50860 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:39] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:39] INFO:     127.0.0.1:50866 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:39] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 1026, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:39] Decode batch, #running-req: 1, #token: 1050, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.66, #queue-req: 0, 
[2025-12-17 20:34:39] INFO:     127.0.0.1:50870 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:41] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:41] INFO:     127.0.0.1:50874 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:41] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 1069, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:41] INFO:     127.0.0.1:50878 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:43] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:43] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.86, #queue-req: 0, 
[2025-12-17 20:34:43] INFO:     127.0.0.1:50884 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:43] Prefill batch, #new-seq: 1, #new-token: 24, #cached-token: 980, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:43] INFO:     127.0.0.1:50888 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:45] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:45] Decode batch, #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.20, #queue-req: 0, 
[2025-12-17 20:34:45] INFO:     127.0.0.1:50894 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:45] Prefill batch, #new-seq: 1, #new-token: 1354, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:45] INFO:     127.0.0.1:50898 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:46] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:47] INFO:     127.0.0.1:50902 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:47] Prefill batch, #new-seq: 1, #new-token: 1253, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:47] Decode batch, #running-req: 1, #token: 1287, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.70, #queue-req: 0, 
[2025-12-17 20:34:47] INFO:     127.0.0.1:50906 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:49] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:49] INFO:     127.0.0.1:50910 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:49] Prefill batch, #new-seq: 1, #new-token: 1308, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:49] Decode batch, #running-req: 1, #token: 1356, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.94, #queue-req: 0, 
[2025-12-17 20:34:49] INFO:     127.0.0.1:50914 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:51] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:51] INFO:     127.0.0.1:50918 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:51] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 979, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:51] Decode batch, #running-req: 1, #token: 1000, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.28, #queue-req: 0, 
[2025-12-17 20:34:51] INFO:     127.0.0.1:50924 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:53] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:53] INFO:     127.0.0.1:50928 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:53] Prefill batch, #new-seq: 1, #new-token: 1517, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:53] Decode batch, #running-req: 1, #token: 1551, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.72, #queue-req: 0, 
[2025-12-17 20:34:53] INFO:     127.0.0.1:50932 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:55] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:55] INFO:     127.0.0.1:50936 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:55] Prefill batch, #new-seq: 1, #new-token: 1332, #cached-token: 179, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:55] INFO:     127.0.0.1:50940 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:57] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:57] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.20, #queue-req: 0, 
[2025-12-17 20:34:57] INFO:     127.0.0.1:50944 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:57] Prefill batch, #new-seq: 1, #new-token: 803, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:57] INFO:     127.0.0.1:50948 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:58] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:59] INFO:     127.0.0.1:50952 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:34:59] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 979, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:34:59] Decode batch, #running-req: 1, #token: 1000, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.97, #queue-req: 0, 
[2025-12-17 20:34:59] INFO:     127.0.0.1:50956 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:00] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:00] INFO:     127.0.0.1:50960 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:00] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 982, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:00] INFO:     127.0.0.1:50964 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:00] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.40, #queue-req: 0, 
[2025-12-17 20:35:02] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:02] INFO:     127.0.0.1:50970 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:02] Prefill batch, #new-seq: 1, #new-token: 1243, #cached-token: 141, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:02] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.33, #queue-req: 0, 
[2025-12-17 20:35:02] INFO:     127.0.0.1:50974 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:04] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:04] INFO:     127.0.0.1:50978 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:04] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 1069, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:04] INFO:     127.0.0.1:50982 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:06] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:06] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.14, #queue-req: 0, 
[2025-12-17 20:35:06] INFO:     127.0.0.1:50986 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:06] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 1069, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:06] INFO:     127.0.0.1:50990 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:08] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:08] INFO:     127.0.0.1:50994 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:08] Prefill batch, #new-seq: 1, #new-token: 1229, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:08] Decode batch, #running-req: 1, #token: 1263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.56, #queue-req: 0, 
[2025-12-17 20:35:08] INFO:     127.0.0.1:50998 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:10] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:10] INFO:     127.0.0.1:51004 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:10] Prefill batch, #new-seq: 1, #new-token: 1314, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:10] INFO:     127.0.0.1:51008 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:12] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:12] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.75, #queue-req: 0, 
[2025-12-17 20:35:12] INFO:     127.0.0.1:51012 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:12] Prefill batch, #new-seq: 1, #new-token: 804, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:12] INFO:     127.0.0.1:51016 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:14] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:14] INFO:     127.0.0.1:51020 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:14] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.02, #queue-req: 0, 
[2025-12-17 20:35:14] Prefill batch, #new-seq: 1, #new-token: 24, #cached-token: 981, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:14] INFO:     127.0.0.1:51024 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:15] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:16] INFO:     127.0.0.1:51028 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:16] Prefill batch, #new-seq: 1, #new-token: 1148, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:16] Decode batch, #running-req: 1, #token: 1189, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.19, #queue-req: 0, 
[2025-12-17 20:35:16] INFO:     127.0.0.1:51032 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:17] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:18] INFO:     127.0.0.1:51036 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:18] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 1092, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:18] INFO:     127.0.0.1:51040 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:19] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:19] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.68, #queue-req: 0, 
[2025-12-17 20:35:19] INFO:     127.0.0.1:51044 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:19] Prefill batch, #new-seq: 1, #new-token: 1365, #cached-token: 171, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:20] INFO:     127.0.0.1:51048 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:21] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:21] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.18, #queue-req: 0, 
[2025-12-17 20:35:21] INFO:     127.0.0.1:51054 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:21] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 1062, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:22] INFO:     127.0.0.1:51058 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:23] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:23] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.38, #queue-req: 0, 
[2025-12-17 20:35:23] INFO:     127.0.0.1:51062 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:23] Prefill batch, #new-seq: 1, #new-token: 866, #cached-token: 200, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:23] INFO:     127.0.0.1:51066 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:25] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:25] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.50, #queue-req: 0, 
[2025-12-17 20:35:25] INFO:     127.0.0.1:51070 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:25] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 980, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:25] INFO:     127.0.0.1:51074 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:27] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:27] INFO:     127.0.0.1:51078 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:27] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 1028, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:27] Decode batch, #running-req: 1, #token: 1052, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.47, #queue-req: 0, 
[2025-12-17 20:35:27] INFO:     127.0.0.1:51082 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:29] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:29] INFO:     127.0.0.1:51086 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:29] Prefill batch, #new-seq: 1, #new-token: 29, #cached-token: 1070, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:29] Decode batch, #running-req: 1, #token: 1108, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.53, #queue-req: 0, 
[2025-12-17 20:35:29] INFO:     127.0.0.1:51090 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:31] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:31] INFO:     127.0.0.1:51094 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:31] Prefill batch, #new-seq: 1, #new-token: 1226, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:31] INFO:     127.0.0.1:51098 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:33] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:33] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.90, #queue-req: 0, 
[2025-12-17 20:35:33] INFO:     127.0.0.1:51102 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:33] Prefill batch, #new-seq: 1, #new-token: 1330, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:33] INFO:     127.0.0.1:51106 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:35] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:35] INFO:     127.0.0.1:51110 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:35] Prefill batch, #new-seq: 1, #new-token: 1080, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:35] Decode batch, #running-req: 1, #token: 1103, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.19, #queue-req: 0, 
[2025-12-17 20:35:35] INFO:     127.0.0.1:51114 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:37] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:37] INFO:     127.0.0.1:51120 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:37] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 1047, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:37] INFO:     127.0.0.1:51124 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:37] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.90, #queue-req: 0, 
[2025-12-17 20:35:39] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:39] INFO:     127.0.0.1:51128 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:39] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 957, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:39] INFO:     127.0.0.1:51132 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:40] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:40] INFO:     127.0.0.1:51136 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:40] Prefill batch, #new-seq: 1, #new-token: 1377, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:41] Decode batch, #running-req: 1, #token: 1416, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.85, #queue-req: 0, 
[2025-12-17 20:35:41] INFO:     127.0.0.1:51140 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:42] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:42] INFO:     127.0.0.1:51144 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:42] Prefill batch, #new-seq: 1, #new-token: 1218, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:42] Decode batch, #running-req: 1, #token: 1263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.66, #queue-req: 0, 
[2025-12-17 20:35:43] INFO:     127.0.0.1:51148 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:44] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:44] INFO:     127.0.0.1:51162 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:44] Prefill batch, #new-seq: 1, #new-token: 1198, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:44] Decode batch, #running-req: 1, #token: 1226, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.40, #queue-req: 0, 
[2025-12-17 20:35:44] INFO:     127.0.0.1:51166 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:46] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:46] INFO:     127.0.0.1:51170 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:46] Prefill batch, #new-seq: 1, #new-token: 817, #cached-token: 301, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:46] INFO:     127.0.0.1:51174 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:48] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:48] Decode batch, #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.92, #queue-req: 0, 
[2025-12-17 20:35:48] INFO:     127.0.0.1:51178 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:48] Prefill batch, #new-seq: 1, #new-token: 1059, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:48] INFO:     127.0.0.1:51182 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:50] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:50] Decode batch, #running-req: 1, #token: 72, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.52, #queue-req: 0, 
[2025-12-17 20:35:50] INFO:     127.0.0.1:51186 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:50] Prefill batch, #new-seq: 1, #new-token: 1352, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:50] INFO:     127.0.0.1:51190 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:52] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:52] INFO:     127.0.0.1:51194 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:52] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 1047, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:52] Decode batch, #running-req: 1, #token: 1103, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.21, #queue-req: 0, 
[2025-12-17 20:35:52] INFO:     127.0.0.1:51198 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:54] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:54] INFO:     127.0.0.1:51202 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:54] Prefill batch, #new-seq: 1, #new-token: 957, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:54] INFO:     127.0.0.1:51206 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:56] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:56] Decode batch, #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.88, #queue-req: 0, 
[2025-12-17 20:35:56] INFO:     127.0.0.1:51210 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:56] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 960, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:56] INFO:     127.0.0.1:51214 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:58] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:58] INFO:     127.0.0.1:51218 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:35:58] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 958, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:35:58] Decode batch, #running-req: 1, #token: 1005, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.38, #queue-req: 0, 
[2025-12-17 20:35:58] INFO:     127.0.0.1:51222 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:00] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:00] INFO:     127.0.0.1:51226 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:00] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 958, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:00] Decode batch, #running-req: 1, #token: 993, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.49, #queue-req: 0, 
[2025-12-17 20:36:00] INFO:     127.0.0.1:51230 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:02] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:02] INFO:     127.0.0.1:51234 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:02] Prefill batch, #new-seq: 1, #new-token: 1266, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:02] Decode batch, #running-req: 1, #token: 1292, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.12, #queue-req: 0, 
[2025-12-17 20:36:02] INFO:     127.0.0.1:51238 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:04] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:04] INFO:     127.0.0.1:51242 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:04] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 957, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:04] INFO:     127.0.0.1:51246 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:05] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:05] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.92, #queue-req: 0, 
[2025-12-17 20:36:06] INFO:     127.0.0.1:51250 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:06] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 1050, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:06] INFO:     127.0.0.1:51254 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:07] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:07] INFO:     127.0.0.1:51258 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:07] Prefill batch, #new-seq: 1, #new-token: 1408, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:07] Decode batch, #running-req: 1, #token: 1433, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.20, #queue-req: 0, 
[2025-12-17 20:36:07] INFO:     127.0.0.1:51262 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:09] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:10] INFO:     127.0.0.1:51266 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:10] Prefill batch, #new-seq: 1, #new-token: 1057, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:10] INFO:     127.0.0.1:51270 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:11] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:11] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.16, #queue-req: 0, 
[2025-12-17 20:36:11] INFO:     127.0.0.1:51276 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:11] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 959, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:12] INFO:     127.0.0.1:51280 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:13] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:13] INFO:     127.0.0.1:51284 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:13] Prefill batch, #new-seq: 1, #new-token: 852, #cached-token: 573, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:13] Decode batch, #running-req: 1, #token: 1429, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.28, #queue-req: 0, 
[2025-12-17 20:36:13] INFO:     127.0.0.1:51288 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:15] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:15] INFO:     127.0.0.1:51292 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:15] Prefill batch, #new-seq: 1, #new-token: 1322, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:15] INFO:     127.0.0.1:51296 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:17] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:17] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.84, #queue-req: 0, 
[2025-12-17 20:36:17] INFO:     127.0.0.1:51302 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:18] Prefill batch, #new-seq: 1, #new-token: 1331, #cached-token: 40, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:18] INFO:     127.0.0.1:51306 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:20] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:20] INFO:     127.0.0.1:51310 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:20] Prefill batch, #new-seq: 1, #new-token: 1344, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:20] Decode batch, #running-req: 1, #token: 1378, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.02, #queue-req: 0, 
[2025-12-17 20:36:20] INFO:     127.0.0.1:51314 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:22] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:22] INFO:     127.0.0.1:51320 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:22] Prefill batch, #new-seq: 1, #new-token: 979, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:22] Decode batch, #running-req: 1, #token: 1004, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.96, #queue-req: 0, 
[2025-12-17 20:36:22] INFO:     127.0.0.1:51324 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:24] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:24] INFO:     127.0.0.1:51328 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:24] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 1057, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:24] INFO:     127.0.0.1:51332 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:26] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:26] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.95, #queue-req: 0, 
[2025-12-17 20:36:26] INFO:     127.0.0.1:51336 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:26] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 1048, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:26] INFO:     127.0.0.1:51340 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:28] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:28] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.89, #queue-req: 0, 
[2025-12-17 20:36:28] INFO:     127.0.0.1:51352 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:28] Prefill batch, #new-seq: 1, #new-token: 818, #cached-token: 119, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:28] INFO:     127.0.0.1:51356 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:30] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:30] INFO:     127.0.0.1:51362 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:30] Prefill batch, #new-seq: 1, #new-token: 29, #cached-token: 958, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:30] Decode batch, #running-req: 1, #token: 990, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.14, #queue-req: 0, 
[2025-12-17 20:36:30] INFO:     127.0.0.1:51366 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:31] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:31] INFO:     127.0.0.1:51370 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:31] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 960, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:32] INFO:     127.0.0.1:51374 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:33] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:33] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.32, #queue-req: 0, 
[2025-12-17 20:36:33] INFO:     127.0.0.1:51378 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:33] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 957, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:33] INFO:     127.0.0.1:51382 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:36] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:36] INFO:     127.0.0.1:51386 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:36] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 1048, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:36] Decode batch, #running-req: 1, #token: 1090, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.54, #queue-req: 0, 
[2025-12-17 20:36:36] INFO:     127.0.0.1:51390 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:42] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:42] INFO:     127.0.0.1:51398 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:42] Prefill batch, #new-seq: 1, #new-token: 1026, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:42] Decode batch, #running-req: 1, #token: 1062, token usage: 0.00, cuda graph: True, gen throughput (token/s): 6.20, #queue-req: 0, 
[2025-12-17 20:36:42] INFO:     127.0.0.1:51402 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:44] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:44] INFO:     127.0.0.1:51406 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:44] Prefill batch, #new-seq: 1, #new-token: 1022, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:44] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.19, #queue-req: 0, 
[2025-12-17 20:36:44] INFO:     127.0.0.1:51410 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:46] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:46] INFO:     127.0.0.1:51414 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:46] Prefill batch, #new-seq: 1, #new-token: 873, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:46] INFO:     127.0.0.1:51418 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:48] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:48] INFO:     127.0.0.1:51424 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:48] Prefill batch, #new-seq: 1, #new-token: 1168, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:48] Decode batch, #running-req: 1, #token: 1182, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.23, #queue-req: 0, 
[2025-12-17 20:36:48] INFO:     127.0.0.1:51428 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:50] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:50] INFO:     127.0.0.1:51432 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:50] Prefill batch, #new-seq: 1, #new-token: 812, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:50] Decode batch, #running-req: 1, #token: 844, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.45, #queue-req: 0, 
[2025-12-17 20:36:50] INFO:     127.0.0.1:51436 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:51] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:51] INFO:     127.0.0.1:51440 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:51] Prefill batch, #new-seq: 1, #new-token: 1240, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:52] Decode batch, #running-req: 1, #token: 1295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.43, #queue-req: 0, 
[2025-12-17 20:36:52] Decode batch, #running-req: 1, #token: 1335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:36:52] Decode batch, #running-req: 1, #token: 1375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:36:52] Decode batch, #running-req: 1, #token: 1415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:36:52] Decode batch, #running-req: 1, #token: 1455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 20:36:52] Decode batch, #running-req: 1, #token: 1495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 20:36:53] Decode batch, #running-req: 1, #token: 1535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.96, #queue-req: 0, 
[2025-12-17 20:36:53] Decode batch, #running-req: 1, #token: 1575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:36:53] Decode batch, #running-req: 1, #token: 1615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 20:36:53] Decode batch, #running-req: 1, #token: 1655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:36:53] Decode batch, #running-req: 1, #token: 1695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.90, #queue-req: 0, 
[2025-12-17 20:36:54] Decode batch, #running-req: 1, #token: 1735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:36:54] Decode batch, #running-req: 1, #token: 1775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 20:36:54] Decode batch, #running-req: 1, #token: 1815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:36:54] Decode batch, #running-req: 1, #token: 1855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 20:36:54] Decode batch, #running-req: 1, #token: 1895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 20:36:54] Decode batch, #running-req: 1, #token: 1935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:36:55] Decode batch, #running-req: 1, #token: 1975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:36:55] Decode batch, #running-req: 1, #token: 2015, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.09, #queue-req: 0, 
[2025-12-17 20:36:55] Decode batch, #running-req: 1, #token: 2055, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:36:55] Decode batch, #running-req: 1, #token: 2095, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 20:36:55] Decode batch, #running-req: 1, #token: 2135, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.31, #queue-req: 0, 
[2025-12-17 20:36:56] Decode batch, #running-req: 1, #token: 2175, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.36, #queue-req: 0, 
[2025-12-17 20:36:56] Decode batch, #running-req: 1, #token: 2215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.29, #queue-req: 0, 
[2025-12-17 20:36:56] Decode batch, #running-req: 1, #token: 2255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.35, #queue-req: 0, 
[2025-12-17 20:36:56] INFO:     127.0.0.1:51444 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:58] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:58] INFO:     127.0.0.1:51452 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:58] Prefill batch, #new-seq: 1, #new-token: 1147, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:58] INFO:     127.0.0.1:51456 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:36:59] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:36:59] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.34, #queue-req: 0, 
[2025-12-17 20:36:59] INFO:     127.0.0.1:51460 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:00] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 768, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:00] INFO:     127.0.0.1:51464 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:01] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:01] INFO:     127.0.0.1:51468 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:01] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 868, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:01] Decode batch, #running-req: 1, #token: 886, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.27, #queue-req: 0, 
[2025-12-17 20:37:01] INFO:     127.0.0.1:51472 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:03] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:03] INFO:     127.0.0.1:51476 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:03] Prefill batch, #new-seq: 1, #new-token: 795, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:03] INFO:     127.0.0.1:51480 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:05] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:05] INFO:     127.0.0.1:51484 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:05] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 1123, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:05] Decode batch, #running-req: 1, #token: 1180, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.64, #queue-req: 0, 
[2025-12-17 20:37:06] Decode batch, #running-req: 1, #token: 1220, token usage: 0.00, cuda graph: True, gen throughput (token/s): 205.84, #queue-req: 0, 
[2025-12-17 20:37:06] Decode batch, #running-req: 1, #token: 1260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.94, #queue-req: 0, 
[2025-12-17 20:37:06] Decode batch, #running-req: 1, #token: 1300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:37:06] Decode batch, #running-req: 1, #token: 1340, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:37:06] Decode batch, #running-req: 1, #token: 1380, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.92, #queue-req: 0, 
[2025-12-17 20:37:07] Decode batch, #running-req: 1, #token: 1420, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:37:07] Decode batch, #running-req: 1, #token: 1460, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.02, #queue-req: 0, 
[2025-12-17 20:37:07] Decode batch, #running-req: 1, #token: 1500, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.01, #queue-req: 0, 
[2025-12-17 20:37:07] Decode batch, #running-req: 1, #token: 1540, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.09, #queue-req: 0, 
[2025-12-17 20:37:07] Decode batch, #running-req: 1, #token: 1580, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 20:37:07] Decode batch, #running-req: 1, #token: 1620, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:37:08] Decode batch, #running-req: 1, #token: 1660, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:37:08] Decode batch, #running-req: 1, #token: 1700, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:37:08] Decode batch, #running-req: 1, #token: 1740, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:37:08] Decode batch, #running-req: 1, #token: 1780, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:37:08] Decode batch, #running-req: 1, #token: 1820, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:37:09] Decode batch, #running-req: 1, #token: 1860, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:37:09] Decode batch, #running-req: 1, #token: 1900, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:37:09] Decode batch, #running-req: 1, #token: 1940, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:37:09] Decode batch, #running-req: 1, #token: 1980, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:37:09] Decode batch, #running-req: 1, #token: 2020, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.94, #queue-req: 0, 
[2025-12-17 20:37:09] Decode batch, #running-req: 1, #token: 2060, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:37:10] Decode batch, #running-req: 1, #token: 2100, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.26, #queue-req: 0, 
[2025-12-17 20:37:10] Decode batch, #running-req: 1, #token: 2140, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.33, #queue-req: 0, 
[2025-12-17 20:37:10] INFO:     127.0.0.1:51488 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:12] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:12] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.52, #queue-req: 0, 
[2025-12-17 20:37:12] INFO:     127.0.0.1:51494 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:12] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 812, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:12] INFO:     127.0.0.1:51498 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:14] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:14] INFO:     127.0.0.1:51502 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:14] Prefill batch, #new-seq: 1, #new-token: 1033, #cached-token: 20, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:14] Decode batch, #running-req: 1, #token: 1058, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.23, #queue-req: 0, 
[2025-12-17 20:37:14] INFO:     127.0.0.1:51506 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:15] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:15] INFO:     127.0.0.1:51510 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:15] Prefill batch, #new-seq: 1, #new-token: 8, #cached-token: 814, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:16] INFO:     127.0.0.1:51514 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:17] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:17] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.27, #queue-req: 0, 
[2025-12-17 20:37:17] INFO:     127.0.0.1:51518 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:17] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 1170, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:17] INFO:     127.0.0.1:51522 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:20] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:20] INFO:     127.0.0.1:51526 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:20] Prefill batch, #new-seq: 1, #new-token: 1220, #cached-token: 19, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:20] Decode batch, #running-req: 1, #token: 1253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 15.06, #queue-req: 0, 
[2025-12-17 20:37:20] INFO:     127.0.0.1:51530 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:22] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:22] INFO:     127.0.0.1:51534 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:22] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 796, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:22] Decode batch, #running-req: 1, #token: 834, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.99, #queue-req: 0, 
[2025-12-17 20:37:22] INFO:     127.0.0.1:51538 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:24] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:24] INFO:     127.0.0.1:51542 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:24] Prefill batch, #new-seq: 1, #new-token: 697, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:24] Decode batch, #running-req: 1, #token: 723, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.48, #queue-req: 0, 
[2025-12-17 20:37:24] INFO:     127.0.0.1:51546 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:26] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:26] INFO:     127.0.0.1:51552 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:26] Prefill batch, #new-seq: 1, #new-token: 1232, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:26] Decode batch, #running-req: 1, #token: 1254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.25, #queue-req: 0, 
[2025-12-17 20:37:26] INFO:     127.0.0.1:51556 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:29] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:29] INFO:     127.0.0.1:51560 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:29] Prefill batch, #new-seq: 1, #new-token: 1149, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:29] INFO:     127.0.0.1:51564 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:30] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:31] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.76, #queue-req: 0, 
[2025-12-17 20:37:31] INFO:     127.0.0.1:51568 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:31] Prefill batch, #new-seq: 1, #new-token: 1289, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:31] INFO:     127.0.0.1:51572 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:32] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:32] INFO:     127.0.0.1:51576 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:32] Prefill batch, #new-seq: 1, #new-token: 1332, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:32] Decode batch, #running-req: 1, #token: 1357, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.94, #queue-req: 0, 
[2025-12-17 20:37:32] INFO:     127.0.0.1:51580 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:34] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:34] INFO:     127.0.0.1:51584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:34] Prefill batch, #new-seq: 1, #new-token: 1172, #cached-token: 121, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:34] INFO:     127.0.0.1:51588 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:36] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:36] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.27, #queue-req: 0, 
[2025-12-17 20:37:36] INFO:     127.0.0.1:51594 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:36] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 1168, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:36] INFO:     127.0.0.1:51598 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:38] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:38] INFO:     127.0.0.1:51602 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:38] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 868, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:38] Decode batch, #running-req: 1, #token: 889, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.17, #queue-req: 0, 
[2025-12-17 20:37:38] INFO:     127.0.0.1:51606 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:40] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:40] INFO:     127.0.0.1:51610 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:40] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 688, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:40] Decode batch, #running-req: 1, #token: 714, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.41, #queue-req: 0, 
[2025-12-17 20:37:40] INFO:     127.0.0.1:51614 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:42] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:42] INFO:     127.0.0.1:51618 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:42] Prefill batch, #new-seq: 1, #new-token: 1130, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:42] INFO:     127.0.0.1:51622 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:43] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:43] Decode batch, #running-req: 1, #token: 70, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.19, #queue-req: 0, 
[2025-12-17 20:37:43] INFO:     127.0.0.1:51626 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:43] Prefill batch, #new-seq: 1, #new-token: 960, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:44] Decode batch, #running-req: 1, #token: 1005, token usage: 0.00, cuda graph: True, gen throughput (token/s): 192.42, #queue-req: 0, 
[2025-12-17 20:37:44] Decode batch, #running-req: 1, #token: 1045, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.42, #queue-req: 0, 
[2025-12-17 20:37:44] Decode batch, #running-req: 1, #token: 1085, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.90, #queue-req: 0, 
[2025-12-17 20:37:44] Decode batch, #running-req: 1, #token: 1125, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:37:44] Decode batch, #running-req: 1, #token: 1165, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:37:44] Decode batch, #running-req: 1, #token: 1205, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:37:45] Decode batch, #running-req: 1, #token: 1245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.04, #queue-req: 0, 
[2025-12-17 20:37:45] Decode batch, #running-req: 1, #token: 1285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:37:45] Decode batch, #running-req: 1, #token: 1325, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:37:45] Decode batch, #running-req: 1, #token: 1365, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.96, #queue-req: 0, 
[2025-12-17 20:37:45] Decode batch, #running-req: 1, #token: 1405, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:37:46] Decode batch, #running-req: 1, #token: 1445, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.03, #queue-req: 0, 
[2025-12-17 20:37:46] Decode batch, #running-req: 1, #token: 1485, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 20:37:46] Decode batch, #running-req: 1, #token: 1525, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 20:37:46] Decode batch, #running-req: 1, #token: 1565, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:37:46] Decode batch, #running-req: 1, #token: 1605, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:37:46] Decode batch, #running-req: 1, #token: 1645, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:37:47] Decode batch, #running-req: 1, #token: 1685, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:37:47] Decode batch, #running-req: 1, #token: 1725, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:37:47] Decode batch, #running-req: 1, #token: 1765, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:37:47] Decode batch, #running-req: 1, #token: 1805, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:37:47] Decode batch, #running-req: 1, #token: 1845, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:37:48] Decode batch, #running-req: 1, #token: 1885, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:37:48] Decode batch, #running-req: 1, #token: 1925, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.55, #queue-req: 0, 
[2025-12-17 20:37:48] Decode batch, #running-req: 1, #token: 1965, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:37:48] INFO:     127.0.0.1:51630 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:50] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:50] INFO:     127.0.0.1:51634 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:50] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 815, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:50] Decode batch, #running-req: 1, #token: 844, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.29, #queue-req: 0, 
[2025-12-17 20:37:50] INFO:     127.0.0.1:51638 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:51] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:52] INFO:     127.0.0.1:51642 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:52] Prefill batch, #new-seq: 1, #new-token: 772, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:52] INFO:     127.0.0.1:51646 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:53] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:53] Decode batch, #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.16, #queue-req: 0, 
[2025-12-17 20:37:53] INFO:     127.0.0.1:51650 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:53] Prefill batch, #new-seq: 1, #new-token: 987, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:53] INFO:     127.0.0.1:51654 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:55] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:55] INFO:     127.0.0.1:51658 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:55] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 1167, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:55] INFO:     127.0.0.1:51662 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:57] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:57] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.19, #queue-req: 0, 
[2025-12-17 20:37:57] INFO:     127.0.0.1:51668 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:57] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 812, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:57] INFO:     127.0.0.1:51672 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:59] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:59] INFO:     127.0.0.1:51676 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:37:59] Prefill batch, #new-seq: 1, #new-token: 909, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:37:59] INFO:     127.0.0.1:51680 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:01] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:01] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.94, #queue-req: 0, 
[2025-12-17 20:38:01] INFO:     127.0.0.1:51684 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:01] Prefill batch, #new-seq: 1, #new-token: 691, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:01] INFO:     127.0.0.1:51688 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:03] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:03] INFO:     127.0.0.1:51692 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:03] Prefill batch, #new-seq: 1, #new-token: 1061, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:03] Decode batch, #running-req: 1, #token: 1076, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.93, #queue-req: 0, 
[2025-12-17 20:38:03] INFO:     127.0.0.1:51696 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:05] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:05] INFO:     127.0.0.1:51702 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:05] Prefill batch, #new-seq: 1, #new-token: 8, #cached-token: 796, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:05] INFO:     127.0.0.1:51706 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:07] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:07] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.14, #queue-req: 0, 
[2025-12-17 20:38:07] INFO:     127.0.0.1:51710 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:07] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 1169, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:07] INFO:     127.0.0.1:51714 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:09] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:09] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.39, #queue-req: 0, 
[2025-12-17 20:38:09] INFO:     127.0.0.1:51718 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:09] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 869, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:09] INFO:     127.0.0.1:51722 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:11] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:11] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.24, #queue-req: 0, 
[2025-12-17 20:38:11] INFO:     127.0.0.1:51726 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:11] Prefill batch, #new-seq: 1, #new-token: 1152, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:11] INFO:     127.0.0.1:51730 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:13] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:13] INFO:     127.0.0.1:51734 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:13] Prefill batch, #new-seq: 1, #new-token: 1259, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:13] Decode batch, #running-req: 1, #token: 1283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.60, #queue-req: 0, 
[2025-12-17 20:38:13] INFO:     127.0.0.1:51738 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:15] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:15] INFO:     127.0.0.1:51742 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:15] Prefill batch, #new-seq: 1, #new-token: 1019, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:15] Decode batch, #running-req: 1, #token: 1039, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.25, #queue-req: 0, 
[2025-12-17 20:38:15] INFO:     127.0.0.1:51746 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:16] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:16] INFO:     127.0.0.1:51754 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:16] Prefill batch, #new-seq: 1, #new-token: 1228, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:17] INFO:     127.0.0.1:51758 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:18] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:18] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.19, #queue-req: 0, 
[2025-12-17 20:38:18] INFO:     127.0.0.1:51762 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:18] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 815, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:18] INFO:     127.0.0.1:51766 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:20] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:20] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.32, #queue-req: 0, 
[2025-12-17 20:38:20] INFO:     127.0.0.1:51770 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:20] Prefill batch, #new-seq: 1, #new-token: 1126, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:20] INFO:     127.0.0.1:51774 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:22] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:22] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.23, #queue-req: 0, 
[2025-12-17 20:38:22] INFO:     127.0.0.1:51778 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:22] Prefill batch, #new-seq: 1, #new-token: 1124, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:22] INFO:     127.0.0.1:51782 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:24] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:24] INFO:     127.0.0.1:51786 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:24] Prefill batch, #new-seq: 1, #new-token: 1045, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:24] Decode batch, #running-req: 1, #token: 1081, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.10, #queue-req: 0, 
[2025-12-17 20:38:24] INFO:     127.0.0.1:51790 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:26] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:26] INFO:     127.0.0.1:51796 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:26] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 660, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:26] Decode batch, #running-req: 1, #token: 734, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.42, #queue-req: 0, 
[2025-12-17 20:38:26] INFO:     127.0.0.1:51800 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:27] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:28] INFO:     127.0.0.1:51804 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:28] Prefill batch, #new-seq: 1, #new-token: 1141, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:28] Decode batch, #running-req: 1, #token: 1191, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.50, #queue-req: 0, 
[2025-12-17 20:38:28] INFO:     127.0.0.1:51808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:29] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:29] INFO:     127.0.0.1:51812 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:29] Prefill batch, #new-seq: 1, #new-token: 1328, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:30] Decode batch, #running-req: 1, #token: 1354, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.44, #queue-req: 0, 
[2025-12-17 20:38:30] INFO:     127.0.0.1:51816 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:31] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:31] INFO:     127.0.0.1:51822 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:31] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 815, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:31] INFO:     127.0.0.1:51826 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:33] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:33] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.17, #queue-req: 0, 
[2025-12-17 20:38:33] INFO:     127.0.0.1:51830 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:33] Prefill batch, #new-seq: 1, #new-token: 1092, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:33] INFO:     127.0.0.1:51834 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:35] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:35] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.19, #queue-req: 0, 
[2025-12-17 20:38:35] INFO:     127.0.0.1:51838 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:35] Prefill batch, #new-seq: 1, #new-token: 832, #cached-token: 72, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:35] INFO:     127.0.0.1:51842 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:37] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:37] INFO:     127.0.0.1:51846 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:37] Prefill batch, #new-seq: 1, #new-token: 1306, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:37] INFO:     127.0.0.1:51850 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:39] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:39] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.24, #queue-req: 0, 
[2025-12-17 20:38:39] INFO:     127.0.0.1:51854 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:39] Prefill batch, #new-seq: 1, #new-token: 1163, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:39] INFO:     127.0.0.1:51858 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:40] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:40] INFO:     127.0.0.1:51864 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:40] Prefill batch, #new-seq: 1, #new-token: 1398, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:40] Decode batch, #running-req: 1, #token: 1417, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.92, #queue-req: 0, 
[2025-12-17 20:38:41] INFO:     127.0.0.1:51870 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:42] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:43] INFO:     127.0.0.1:51874 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:43] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 794, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:43] INFO:     127.0.0.1:51878 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:44] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:44] INFO:     127.0.0.1:51882 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:44] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 888, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:44] Decode batch, #running-req: 1, #token: 903, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.41, #queue-req: 0, 
[2025-12-17 20:38:44] INFO:     127.0.0.1:51886 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:46] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:46] INFO:     127.0.0.1:51892 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:46] Prefill batch, #new-seq: 1, #new-token: 797, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:46] INFO:     127.0.0.1:51896 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:48] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:48] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.21, #queue-req: 0, 
[2025-12-17 20:38:48] INFO:     127.0.0.1:51900 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:48] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 1170, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:48] INFO:     127.0.0.1:51904 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:50] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:50] INFO:     127.0.0.1:51912 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:50] Prefill batch, #new-seq: 1, #new-token: 1404, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:50] INFO:     127.0.0.1:51916 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:51] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:51] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.20, #queue-req: 0, 
[2025-12-17 20:38:52] INFO:     127.0.0.1:51920 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:52] Prefill batch, #new-seq: 1, #new-token: 1055, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:52] INFO:     127.0.0.1:51924 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:53] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:53] INFO:     127.0.0.1:51928 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:53] Prefill batch, #new-seq: 1, #new-token: 1250, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:53] Decode batch, #running-req: 1, #token: 1288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.93, #queue-req: 0, 
[2025-12-17 20:38:53] INFO:     127.0.0.1:51932 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:55] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:55] INFO:     127.0.0.1:51936 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:55] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 707, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:55] Decode batch, #running-req: 1, #token: 731, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.34, #queue-req: 0, 
[2025-12-17 20:38:55] INFO:     127.0.0.1:51940 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:57] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:57] INFO:     127.0.0.1:51944 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:57] Prefill batch, #new-seq: 1, #new-token: 1133, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:57] Decode batch, #running-req: 1, #token: 1169, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.80, #queue-req: 0, 
[2025-12-17 20:38:57] INFO:     127.0.0.1:51948 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:59] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:59] INFO:     127.0.0.1:51952 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:38:59] Prefill batch, #new-seq: 1, #new-token: 1025, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:38:59] INFO:     127.0.0.1:51956 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:01] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:01] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.30, #queue-req: 0, 
[2025-12-17 20:39:01] INFO:     127.0.0.1:51960 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:01] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 1170, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:01] INFO:     127.0.0.1:51964 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:03] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:03] INFO:     127.0.0.1:51968 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:03] Prefill batch, #new-seq: 1, #new-token: 1116, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:03] Decode batch, #running-req: 1, #token: 1157, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.49, #queue-req: 0, 
[2025-12-17 20:39:03] INFO:     127.0.0.1:51972 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:04] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:05] INFO:     127.0.0.1:51976 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:05] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 795, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:05] INFO:     127.0.0.1:51980 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:06] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:06] INFO:     127.0.0.1:51984 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:06] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.33, #queue-req: 0, 
[2025-12-17 20:39:06] Prefill batch, #new-seq: 1, #new-token: 1324, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:06] INFO:     127.0.0.1:51988 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:08] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:08] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.33, #queue-req: 0, 
[2025-12-17 20:39:08] INFO:     127.0.0.1:51992 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:08] Prefill batch, #new-seq: 1, #new-token: 754, #cached-token: 90, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:08] Decode batch, #running-req: 1, #token: 882, token usage: 0.00, cuda graph: True, gen throughput (token/s): 196.45, #queue-req: 0, 
[2025-12-17 20:39:09] Decode batch, #running-req: 1, #token: 922, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.66, #queue-req: 0, 
[2025-12-17 20:39:09] Decode batch, #running-req: 1, #token: 962, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.82, #queue-req: 0, 
[2025-12-17 20:39:09] Decode batch, #running-req: 1, #token: 1002, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.63, #queue-req: 0, 
[2025-12-17 20:39:09] Decode batch, #running-req: 1, #token: 1042, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.53, #queue-req: 0, 
[2025-12-17 20:39:09] Decode batch, #running-req: 1, #token: 1082, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.98, #queue-req: 0, 
[2025-12-17 20:39:09] Decode batch, #running-req: 1, #token: 1122, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.97, #queue-req: 0, 
[2025-12-17 20:39:10] Decode batch, #running-req: 1, #token: 1162, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:39:10] Decode batch, #running-req: 1, #token: 1202, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.02, #queue-req: 0, 
[2025-12-17 20:39:10] Decode batch, #running-req: 1, #token: 1242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 20:39:10] Decode batch, #running-req: 1, #token: 1282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.90, #queue-req: 0, 
[2025-12-17 20:39:10] Decode batch, #running-req: 1, #token: 1322, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.90, #queue-req: 0, 
[2025-12-17 20:39:11] Decode batch, #running-req: 1, #token: 1362, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.90, #queue-req: 0, 
[2025-12-17 20:39:11] Decode batch, #running-req: 1, #token: 1402, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:39:11] Decode batch, #running-req: 1, #token: 1442, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 20:39:11] Decode batch, #running-req: 1, #token: 1482, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.05, #queue-req: 0, 
[2025-12-17 20:39:11] Decode batch, #running-req: 1, #token: 1522, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.98, #queue-req: 0, 
[2025-12-17 20:39:11] Decode batch, #running-req: 1, #token: 1562, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:39:12] Decode batch, #running-req: 1, #token: 1602, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 20:39:12] Decode batch, #running-req: 1, #token: 1642, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:39:12] Decode batch, #running-req: 1, #token: 1682, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:39:12] Decode batch, #running-req: 1, #token: 1722, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:39:12] Decode batch, #running-req: 1, #token: 1762, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:39:13] Decode batch, #running-req: 1, #token: 1802, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:39:13] Decode batch, #running-req: 1, #token: 1842, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:39:13] INFO:     127.0.0.1:51996 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:14] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:14] INFO:     127.0.0.1:52002 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:14] Prefill batch, #new-seq: 1, #new-token: 1033, #cached-token: 131, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:15] INFO:     127.0.0.1:52006 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:17] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:17] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.93, #queue-req: 0, 
[2025-12-17 20:39:17] INFO:     127.0.0.1:52010 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:17] Prefill batch, #new-seq: 1, #new-token: 1216, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:17] INFO:     127.0.0.1:52014 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:19] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:19] INFO:     127.0.0.1:52018 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:19] Prefill batch, #new-seq: 1, #new-token: 25, #cached-token: 1149, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:19] Decode batch, #running-req: 1, #token: 1191, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.93, #queue-req: 0, 
[2025-12-17 20:39:19] INFO:     127.0.0.1:52022 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:20] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:20] INFO:     127.0.0.1:52026 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:20] Prefill batch, #new-seq: 1, #new-token: 1137, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:21] INFO:     127.0.0.1:52030 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:22] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:23] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.43, #queue-req: 0, 
[2025-12-17 20:39:23] INFO:     127.0.0.1:52034 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:23] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 1147, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:23] INFO:     127.0.0.1:52038 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:24] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:24] INFO:     127.0.0.1:52042 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:24] Prefill batch, #new-seq: 1, #new-token: 1014, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:24] Decode batch, #running-req: 1, #token: 1031, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.98, #queue-req: 0, 
[2025-12-17 20:39:24] INFO:     127.0.0.1:52046 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:26] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:26] INFO:     127.0.0.1:52050 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:26] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 795, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:26] Decode batch, #running-req: 1, #token: 828, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.49, #queue-req: 0, 
[2025-12-17 20:39:26] INFO:     127.0.0.1:52054 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:28] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:28] INFO:     127.0.0.1:52058 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:28] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 795, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:28] INFO:     127.0.0.1:52064 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:30] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:30] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.36, #queue-req: 0, 
[2025-12-17 20:39:30] INFO:     127.0.0.1:52068 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:30] Prefill batch, #new-seq: 1, #new-token: 1271, #cached-token: 59, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:30] INFO:     127.0.0.1:52072 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:32] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:32] Decode batch, #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.10, #queue-req: 0, 
[2025-12-17 20:39:32] INFO:     127.0.0.1:52076 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:32] Prefill batch, #new-seq: 1, #new-token: 1222, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:32] Decode batch, #running-req: 1, #token: 1255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 191.25, #queue-req: 0, 
[2025-12-17 20:39:32] Decode batch, #running-req: 1, #token: 1295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:39:33] Decode batch, #running-req: 1, #token: 1335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:39:33] Decode batch, #running-req: 1, #token: 1375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:39:33] Decode batch, #running-req: 1, #token: 1415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.97, #queue-req: 0, 
[2025-12-17 20:39:33] Decode batch, #running-req: 1, #token: 1455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.06, #queue-req: 0, 
[2025-12-17 20:39:33] Decode batch, #running-req: 1, #token: 1495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.09, #queue-req: 0, 
[2025-12-17 20:39:34] Decode batch, #running-req: 1, #token: 1535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:39:34] Decode batch, #running-req: 1, #token: 1575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.90, #queue-req: 0, 
[2025-12-17 20:39:34] Decode batch, #running-req: 1, #token: 1615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:39:34] Decode batch, #running-req: 1, #token: 1655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:39:34] Decode batch, #running-req: 1, #token: 1695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:39:34] Decode batch, #running-req: 1, #token: 1735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:39:35] Decode batch, #running-req: 1, #token: 1775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 20:39:35] Decode batch, #running-req: 1, #token: 1815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 20:39:35] Decode batch, #running-req: 1, #token: 1855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:39:35] Decode batch, #running-req: 1, #token: 1895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:39:35] Decode batch, #running-req: 1, #token: 1935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 20:39:35] Decode batch, #running-req: 1, #token: 1975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:39:36] Decode batch, #running-req: 1, #token: 2015, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:39:36] Decode batch, #running-req: 1, #token: 2055, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:39:36] Decode batch, #running-req: 1, #token: 2095, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.34, #queue-req: 0, 
[2025-12-17 20:39:36] Decode batch, #running-req: 1, #token: 2135, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.42, #queue-req: 0, 
[2025-12-17 20:39:36] Decode batch, #running-req: 1, #token: 2175, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.33, #queue-req: 0, 
[2025-12-17 20:39:37] Decode batch, #running-req: 1, #token: 2215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.38, #queue-req: 0, 
[2025-12-17 20:39:37] INFO:     127.0.0.1:52080 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:38] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:38] INFO:     127.0.0.1:52086 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:38] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 869, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:38] Decode batch, #running-req: 1, #token: 892, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.41, #queue-req: 0, 
[2025-12-17 20:39:39] INFO:     127.0.0.1:52090 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:40] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:40] INFO:     127.0.0.1:52094 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:40] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 869, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:40] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.45, #queue-req: 0, 
[2025-12-17 20:39:40] INFO:     127.0.0.1:52098 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:42] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:42] INFO:     127.0.0.1:52102 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:42] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 795, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:42] Decode batch, #running-req: 1, #token: 831, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.15, #queue-req: 0, 
[2025-12-17 20:39:42] Decode batch, #running-req: 1, #token: 871, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.65, #queue-req: 0, 
[2025-12-17 20:39:43] Decode batch, #running-req: 1, #token: 911, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.60, #queue-req: 0, 
[2025-12-17 20:39:43] Decode batch, #running-req: 1, #token: 951, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.65, #queue-req: 0, 
[2025-12-17 20:39:43] Decode batch, #running-req: 1, #token: 991, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.59, #queue-req: 0, 
[2025-12-17 20:39:43] Decode batch, #running-req: 1, #token: 1031, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.40, #queue-req: 0, 
[2025-12-17 20:39:43] Decode batch, #running-req: 1, #token: 1071, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.12, #queue-req: 0, 
[2025-12-17 20:39:43] Decode batch, #running-req: 1, #token: 1111, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.03, #queue-req: 0, 
[2025-12-17 20:39:44] Decode batch, #running-req: 1, #token: 1151, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:39:44] Decode batch, #running-req: 1, #token: 1191, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.97, #queue-req: 0, 
[2025-12-17 20:39:44] Decode batch, #running-req: 1, #token: 1231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.02, #queue-req: 0, 
[2025-12-17 20:39:44] Decode batch, #running-req: 1, #token: 1271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.88, #queue-req: 0, 
[2025-12-17 20:39:44] Decode batch, #running-req: 1, #token: 1311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.09, #queue-req: 0, 
[2025-12-17 20:39:45] Decode batch, #running-req: 1, #token: 1351, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:39:45] Decode batch, #running-req: 1, #token: 1391, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:39:45] Decode batch, #running-req: 1, #token: 1431, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:39:45] Decode batch, #running-req: 1, #token: 1471, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.01, #queue-req: 0, 
[2025-12-17 20:39:45] Decode batch, #running-req: 1, #token: 1511, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.88, #queue-req: 0, 
[2025-12-17 20:39:45] Decode batch, #running-req: 1, #token: 1551, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:39:46] Decode batch, #running-req: 1, #token: 1591, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:39:46] Decode batch, #running-req: 1, #token: 1631, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 20:39:46] Decode batch, #running-req: 1, #token: 1671, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.55, #queue-req: 0, 
[2025-12-17 20:39:46] Decode batch, #running-req: 1, #token: 1711, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:39:46] Decode batch, #running-req: 1, #token: 1751, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 20:39:47] Decode batch, #running-req: 1, #token: 1791, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 20:39:47] INFO:     127.0.0.1:52106 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:48] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:48] INFO:     127.0.0.1:52112 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:48] Prefill batch, #new-seq: 1, #new-token: 1174, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:48] INFO:     127.0.0.1:52116 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:50] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:50] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.48, #queue-req: 0, 
[2025-12-17 20:39:50] INFO:     127.0.0.1:52120 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:50] Prefill batch, #new-seq: 1, #new-token: 719, #cached-token: 377, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:50] INFO:     127.0.0.1:52124 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:52] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:52] INFO:     127.0.0.1:52128 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:52] Prefill batch, #new-seq: 1, #new-token: 986, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:52] INFO:     127.0.0.1:52132 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:52] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.78, #queue-req: 0, 
[2025-12-17 20:39:54] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:54] INFO:     127.0.0.1:52136 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:54] Prefill batch, #new-seq: 1, #new-token: 1015, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:54] INFO:     127.0.0.1:52140 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:56] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:56] INFO:     127.0.0.1:52144 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:56] Prefill batch, #new-seq: 1, #new-token: 801, #cached-token: 90, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:56] Decode batch, #running-req: 1, #token: 893, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.32, #queue-req: 0, 
[2025-12-17 20:39:56] INFO:     127.0.0.1:52148 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:58] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:58] INFO:     127.0.0.1:52152 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:39:58] Prefill batch, #new-seq: 1, #new-token: 1186, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:39:58] Decode batch, #running-req: 1, #token: 1230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.23, #queue-req: 0, 
[2025-12-17 20:39:58] INFO:     127.0.0.1:52156 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:00] Prefill batch, #new-seq: 1, #new-token: 63, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:00] INFO:     127.0.0.1:52160 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:00] Prefill batch, #new-seq: 1, #new-token: 30, #cached-token: 795, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:00] Decode batch, #running-req: 1, #token: 844, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.20, #queue-req: 0, 
[2025-12-17 20:40:00] INFO:     127.0.0.1:52164 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:02] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:02] INFO:     127.0.0.1:52168 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:02] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 796, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:02] Decode batch, #running-req: 1, #token: 826, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.15, #queue-req: 0, 
[2025-12-17 20:40:02] INFO:     127.0.0.1:52172 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:04] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:04] INFO:     127.0.0.1:52176 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:04] Prefill batch, #new-seq: 1, #new-token: 950, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:04] INFO:     127.0.0.1:52180 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:06] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:06] INFO:     127.0.0.1:52186 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:06] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 1151, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:06] Decode batch, #running-req: 1, #token: 1167, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.21, #queue-req: 0, 
[2025-12-17 20:40:06] INFO:     127.0.0.1:52190 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:07] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:07] INFO:     127.0.0.1:52194 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:07] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 795, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:08] Decode batch, #running-req: 1, #token: 830, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.25, #queue-req: 0, 
[2025-12-17 20:40:08] INFO:     127.0.0.1:52198 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:09] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:09] INFO:     127.0.0.1:52202 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:09] Prefill batch, #new-seq: 1, #new-token: 1122, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:09] INFO:     127.0.0.1:52206 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:11] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:11] INFO:     127.0.0.1:52210 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:11] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.97, #queue-req: 0, 
[2025-12-17 20:40:11] Prefill batch, #new-seq: 1, #new-token: 1152, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:11] INFO:     127.0.0.1:52216 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:13] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:13] INFO:     127.0.0.1:52220 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:13] Prefill batch, #new-seq: 1, #new-token: 1027, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:13] Decode batch, #running-req: 1, #token: 1072, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.02, #queue-req: 0, 
[2025-12-17 20:40:13] INFO:     127.0.0.1:52224 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:15] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:15] INFO:     127.0.0.1:52228 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:15] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 1150, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:15] Decode batch, #running-req: 1, #token: 1183, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.44, #queue-req: 0, 
[2025-12-17 20:40:15] INFO:     127.0.0.1:52232 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:17] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:17] INFO:     127.0.0.1:52236 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:17] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 795, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:17] INFO:     127.0.0.1:52240 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:19] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:19] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.73, #queue-req: 0, 
[2025-12-17 20:40:19] INFO:     127.0.0.1:52248 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:19] Prefill batch, #new-seq: 1, #new-token: 1336, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:20] INFO:     127.0.0.1:52252 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:21] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:21] INFO:     127.0.0.1:52256 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:21] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 869, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:21] Decode batch, #running-req: 1, #token: 904, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.99, #queue-req: 0, 
[2025-12-17 20:40:22] Decode batch, #running-req: 1, #token: 944, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.65, #queue-req: 0, 
[2025-12-17 20:40:22] Decode batch, #running-req: 1, #token: 984, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.56, #queue-req: 0, 
[2025-12-17 20:40:22] Decode batch, #running-req: 1, #token: 1024, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.51, #queue-req: 0, 
[2025-12-17 20:40:22] Decode batch, #running-req: 1, #token: 1064, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.04, #queue-req: 0, 
[2025-12-17 20:40:22] Decode batch, #running-req: 1, #token: 1104, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:40:22] Decode batch, #running-req: 1, #token: 1144, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.05, #queue-req: 0, 
[2025-12-17 20:40:23] Decode batch, #running-req: 1, #token: 1184, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:40:23] Decode batch, #running-req: 1, #token: 1224, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:40:23] Decode batch, #running-req: 1, #token: 1264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:40:23] Decode batch, #running-req: 1, #token: 1304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 20:40:23] Decode batch, #running-req: 1, #token: 1344, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:40:24] Decode batch, #running-req: 1, #token: 1384, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 20:40:24] Decode batch, #running-req: 1, #token: 1424, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 20:40:24] Decode batch, #running-req: 1, #token: 1464, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.02, #queue-req: 0, 
[2025-12-17 20:40:24] Decode batch, #running-req: 1, #token: 1504, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.03, #queue-req: 0, 
[2025-12-17 20:40:24] Decode batch, #running-req: 1, #token: 1544, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:40:24] Decode batch, #running-req: 1, #token: 1584, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:40:25] Decode batch, #running-req: 1, #token: 1624, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:40:25] Decode batch, #running-req: 1, #token: 1664, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:40:25] Decode batch, #running-req: 1, #token: 1704, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.55, #queue-req: 0, 
[2025-12-17 20:40:25] Decode batch, #running-req: 1, #token: 1744, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:40:25] Decode batch, #running-req: 1, #token: 1784, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 20:40:25] Decode batch, #running-req: 1, #token: 1824, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:40:26] Decode batch, #running-req: 1, #token: 1864, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:40:26] INFO:     127.0.0.1:52260 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:27] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:28] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.80, #queue-req: 0, 
[2025-12-17 20:40:28] INFO:     127.0.0.1:52266 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:28] Prefill batch, #new-seq: 1, #new-token: 1120, #cached-token: 17, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:28] INFO:     127.0.0.1:52270 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:29] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:29] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.36, #queue-req: 0, 
[2025-12-17 20:40:29] INFO:     127.0.0.1:52274 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:29] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 795, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:29] INFO:     127.0.0.1:52278 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:31] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:31] INFO:     127.0.0.1:52284 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:31] Prefill batch, #new-seq: 1, #new-token: 1097, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:31] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.11, #queue-req: 0, 
[2025-12-17 20:40:31] INFO:     127.0.0.1:52288 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:33] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:33] INFO:     127.0.0.1:52292 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:33] Prefill batch, #new-seq: 1, #new-token: 826, #cached-token: 311, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:33] INFO:     127.0.0.1:52296 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:35] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:35] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.25, #queue-req: 0, 
[2025-12-17 20:40:35] INFO:     127.0.0.1:52302 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:35] Prefill batch, #new-seq: 1, #new-token: 1134, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:35] INFO:     127.0.0.1:52306 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:37] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:37] INFO:     127.0.0.1:52310 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:37] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 1150, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:37] INFO:     127.0.0.1:52314 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:38] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:38] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.12, #queue-req: 0, 
[2025-12-17 20:40:38] INFO:     127.0.0.1:52318 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:38] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 795, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:39] INFO:     127.0.0.1:52322 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:40] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:40] INFO:     127.0.0.1:52326 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:40] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 795, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:40] Decode batch, #running-req: 1, #token: 815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.04, #queue-req: 0, 
[2025-12-17 20:40:40] INFO:     127.0.0.1:52330 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:42] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:42] INFO:     127.0.0.1:52334 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:42] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 795, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:42] Decode batch, #running-req: 1, #token: 813, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.20, #queue-req: 0, 
[2025-12-17 20:40:42] INFO:     127.0.0.1:52340 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:44] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:44] INFO:     127.0.0.1:52344 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:44] Prefill batch, #new-seq: 1, #new-token: 1215, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:44] Decode batch, #running-req: 1, #token: 1248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.42, #queue-req: 0, 
[2025-12-17 20:40:44] INFO:     127.0.0.1:52348 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:46] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:46] INFO:     127.0.0.1:52352 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:46] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 686, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:46] Decode batch, #running-req: 1, #token: 719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.37, #queue-req: 0, 
[2025-12-17 20:40:46] INFO:     127.0.0.1:52356 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:48] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:48] INFO:     127.0.0.1:52360 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:48] Prefill batch, #new-seq: 1, #new-token: 1063, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:48] INFO:     127.0.0.1:52364 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:49] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:50] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.21, #queue-req: 0, 
[2025-12-17 20:40:50] INFO:     127.0.0.1:52368 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:50] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 796, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:50] INFO:     127.0.0.1:52372 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:51] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:51] INFO:     127.0.0.1:52376 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:51] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 1151, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:51] Decode batch, #running-req: 1, #token: 1173, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.17, #queue-req: 0, 
[2025-12-17 20:40:51] INFO:     127.0.0.1:52380 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:53] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:54] INFO:     127.0.0.1:52384 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:54] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 797, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:54] INFO:     127.0.0.1:52388 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:55] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:55] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.12, #queue-req: 0, 
[2025-12-17 20:40:55] INFO:     127.0.0.1:52392 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:55] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 869, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:56] Decode batch, #running-req: 1, #token: 916, token usage: 0.00, cuda graph: True, gen throughput (token/s): 198.01, #queue-req: 0, 
[2025-12-17 20:40:56] INFO:     127.0.0.1:52396 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:58] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:58] INFO:     127.0.0.1:52404 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:58] Prefill batch, #new-seq: 1, #new-token: 1186, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:58] INFO:     127.0.0.1:52408 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:59] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:40:59] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.29, #queue-req: 0, 
[2025-12-17 20:40:59] INFO:     127.0.0.1:52412 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:40:59] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 795, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:00] Decode batch, #running-req: 1, #token: 843, token usage: 0.00, cuda graph: True, gen throughput (token/s): 197.46, #queue-req: 0, 
[2025-12-17 20:41:00] Decode batch, #running-req: 1, #token: 883, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.51, #queue-req: 0, 
[2025-12-17 20:41:00] Decode batch, #running-req: 1, #token: 923, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.77, #queue-req: 0, 
[2025-12-17 20:41:00] Decode batch, #running-req: 1, #token: 963, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.60, #queue-req: 0, 
[2025-12-17 20:41:00] Decode batch, #running-req: 1, #token: 1003, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.67, #queue-req: 0, 
[2025-12-17 20:41:01] Decode batch, #running-req: 1, #token: 1043, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.28, #queue-req: 0, 
[2025-12-17 20:41:01] Decode batch, #running-req: 1, #token: 1083, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.09, #queue-req: 0, 
[2025-12-17 20:41:01] Decode batch, #running-req: 1, #token: 1123, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.02, #queue-req: 0, 
[2025-12-17 20:41:01] Decode batch, #running-req: 1, #token: 1163, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.92, #queue-req: 0, 
[2025-12-17 20:41:01] Decode batch, #running-req: 1, #token: 1203, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.92, #queue-req: 0, 
[2025-12-17 20:41:01] Decode batch, #running-req: 1, #token: 1243, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.97, #queue-req: 0, 
[2025-12-17 20:41:02] Decode batch, #running-req: 1, #token: 1283, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:41:02] Decode batch, #running-req: 1, #token: 1323, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:41:02] Decode batch, #running-req: 1, #token: 1363, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:41:02] Decode batch, #running-req: 1, #token: 1403, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.96, #queue-req: 0, 
[2025-12-17 20:41:02] Decode batch, #running-req: 1, #token: 1443, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.98, #queue-req: 0, 
[2025-12-17 20:41:03] Decode batch, #running-req: 1, #token: 1483, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.99, #queue-req: 0, 
[2025-12-17 20:41:03] Decode batch, #running-req: 1, #token: 1523, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.05, #queue-req: 0, 
[2025-12-17 20:41:03] Decode batch, #running-req: 1, #token: 1563, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:41:03] Decode batch, #running-req: 1, #token: 1603, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:41:03] Decode batch, #running-req: 1, #token: 1643, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:41:03] Decode batch, #running-req: 1, #token: 1683, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:41:04] Decode batch, #running-req: 1, #token: 1723, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:41:04] Decode batch, #running-req: 1, #token: 1763, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:41:04] Decode batch, #running-req: 1, #token: 1803, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:41:04] INFO:     127.0.0.1:52416 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:06] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:06] INFO:     127.0.0.1:52420 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:06] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 869, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:06] Decode batch, #running-req: 1, #token: 903, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.37, #queue-req: 0, 
[2025-12-17 20:41:06] INFO:     127.0.0.1:52424 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:08] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:08] INFO:     127.0.0.1:52428 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:08] Prefill batch, #new-seq: 1, #new-token: 914, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:08] INFO:     127.0.0.1:52432 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:09] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:09] Decode batch, #running-req: 1, #token: 72, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.34, #queue-req: 0, 
[2025-12-17 20:41:09] INFO:     127.0.0.1:52436 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:09] Prefill batch, #new-seq: 1, #new-token: 921, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:10] INFO:     127.0.0.1:52440 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:11] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:11] Decode batch, #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.25, #queue-req: 0, 
[2025-12-17 20:41:11] INFO:     127.0.0.1:52444 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:11] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 1146, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:11] INFO:     127.0.0.1:52448 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:13] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:13] INFO:     127.0.0.1:52452 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:13] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 1149, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:13] Decode batch, #running-req: 1, #token: 1176, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.12, #queue-req: 0, 
[2025-12-17 20:41:13] Decode batch, #running-req: 1, #token: 1216, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.04, #queue-req: 0, 
[2025-12-17 20:41:14] Decode batch, #running-req: 1, #token: 1256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:41:14] Decode batch, #running-req: 1, #token: 1296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.98, #queue-req: 0, 
[2025-12-17 20:41:14] Decode batch, #running-req: 1, #token: 1336, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 20:41:14] Decode batch, #running-req: 1, #token: 1376, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:41:14] Decode batch, #running-req: 1, #token: 1416, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.05, #queue-req: 0, 
[2025-12-17 20:41:14] Decode batch, #running-req: 1, #token: 1456, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:41:15] Decode batch, #running-req: 1, #token: 1496, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.02, #queue-req: 0, 
[2025-12-17 20:41:15] Decode batch, #running-req: 1, #token: 1536, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.01, #queue-req: 0, 
[2025-12-17 20:41:15] Decode batch, #running-req: 1, #token: 1576, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:41:15] Decode batch, #running-req: 1, #token: 1616, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.90, #queue-req: 0, 
[2025-12-17 20:41:15] Decode batch, #running-req: 1, #token: 1656, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:41:16] Decode batch, #running-req: 1, #token: 1696, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:41:16] Decode batch, #running-req: 1, #token: 1736, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 20:41:16] Decode batch, #running-req: 1, #token: 1776, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:41:16] Decode batch, #running-req: 1, #token: 1816, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:41:16] Decode batch, #running-req: 1, #token: 1856, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.88, #queue-req: 0, 
[2025-12-17 20:41:16] Decode batch, #running-req: 1, #token: 1896, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:41:17] Decode batch, #running-req: 1, #token: 1936, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:41:17] Decode batch, #running-req: 1, #token: 1976, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.94, #queue-req: 0, 
[2025-12-17 20:41:17] Decode batch, #running-req: 1, #token: 2016, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:41:17] Decode batch, #running-req: 1, #token: 2056, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:41:17] Decode batch, #running-req: 1, #token: 2096, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:41:18] Decode batch, #running-req: 1, #token: 2136, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.24, #queue-req: 0, 
[2025-12-17 20:41:18] INFO:     127.0.0.1:52456 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:19] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:19] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.61, #queue-req: 0, 
[2025-12-17 20:41:19] INFO:     127.0.0.1:52460 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:19] Prefill batch, #new-seq: 1, #new-token: 1169, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:19] INFO:     127.0.0.1:52464 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:21] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:21] INFO:     127.0.0.1:52468 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:21] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 797, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:21] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.14, #queue-req: 0, 
[2025-12-17 20:41:21] INFO:     127.0.0.1:52472 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:23] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:23] INFO:     127.0.0.1:52476 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:23] Prefill batch, #new-seq: 1, #new-token: 1292, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:23] INFO:     127.0.0.1:52480 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:25] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:25] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.47, #queue-req: 0, 
[2025-12-17 20:41:25] INFO:     127.0.0.1:52484 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:25] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 797, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:25] INFO:     127.0.0.1:52488 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:27] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:27] INFO:     127.0.0.1:52494 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:27] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 797, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:27] Decode batch, #running-req: 1, #token: 812, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.17, #queue-req: 0, 
[2025-12-17 20:41:27] INFO:     127.0.0.1:52498 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:29] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:29] INFO:     127.0.0.1:52504 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:29] Prefill batch, #new-seq: 1, #new-token: 1191, #cached-token: 107, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:29] INFO:     127.0.0.1:52508 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:31] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:31] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.72, #queue-req: 0, 
[2025-12-17 20:41:31] INFO:     127.0.0.1:52512 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:31] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 1147, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:32] INFO:     127.0.0.1:52516 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:33] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:33] INFO:     127.0.0.1:52520 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:33] Prefill batch, #new-seq: 1, #new-token: 1246, #cached-token: 18, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:33] Decode batch, #running-req: 1, #token: 1266, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.96, #queue-req: 0, 
[2025-12-17 20:41:33] INFO:     127.0.0.1:52524 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:35] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:35] INFO:     127.0.0.1:52528 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:35] Prefill batch, #new-seq: 1, #new-token: 1087, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:35] INFO:     127.0.0.1:52532 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:37] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:37] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.22, #queue-req: 0, 
[2025-12-17 20:41:37] INFO:     127.0.0.1:52536 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:37] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 795, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:37] INFO:     127.0.0.1:52540 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:39] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:39] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.46, #queue-req: 0, 
[2025-12-17 20:41:39] INFO:     127.0.0.1:52544 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:39] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 797, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:39] Decode batch, #running-req: 1, #token: 853, token usage: 0.00, cuda graph: True, gen throughput (token/s): 197.00, #queue-req: 0, 
[2025-12-17 20:41:39] Decode batch, #running-req: 1, #token: 893, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.64, #queue-req: 0, 
[2025-12-17 20:41:39] Decode batch, #running-req: 1, #token: 933, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.66, #queue-req: 0, 
[2025-12-17 20:41:39] Decode batch, #running-req: 1, #token: 973, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.80, #queue-req: 0, 
[2025-12-17 20:41:40] Decode batch, #running-req: 1, #token: 1013, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.63, #queue-req: 0, 
[2025-12-17 20:41:40] Decode batch, #running-req: 1, #token: 1053, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.33, #queue-req: 0, 
[2025-12-17 20:41:40] Decode batch, #running-req: 1, #token: 1093, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.99, #queue-req: 0, 
[2025-12-17 20:41:40] Decode batch, #running-req: 1, #token: 1133, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.13, #queue-req: 0, 
[2025-12-17 20:41:40] Decode batch, #running-req: 1, #token: 1173, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 20:41:41] Decode batch, #running-req: 1, #token: 1213, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:41:41] Decode batch, #running-req: 1, #token: 1253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:41:41] Decode batch, #running-req: 1, #token: 1293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:41:41] Decode batch, #running-req: 1, #token: 1333, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:41:41] Decode batch, #running-req: 1, #token: 1373, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:41:41] Decode batch, #running-req: 1, #token: 1413, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:41:42] Decode batch, #running-req: 1, #token: 1453, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:41:42] Decode batch, #running-req: 1, #token: 1493, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.05, #queue-req: 0, 
[2025-12-17 20:41:42] Decode batch, #running-req: 1, #token: 1533, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.04, #queue-req: 0, 
[2025-12-17 20:41:42] Decode batch, #running-req: 1, #token: 1573, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 20:41:42] Decode batch, #running-req: 1, #token: 1613, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.88, #queue-req: 0, 
[2025-12-17 20:41:43] Decode batch, #running-req: 1, #token: 1653, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:41:43] Decode batch, #running-req: 1, #token: 1693, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:41:43] Decode batch, #running-req: 1, #token: 1733, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:41:43] Decode batch, #running-req: 1, #token: 1773, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:41:43] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.34, #queue-req: 0, 
[2025-12-17 20:41:43] INFO:     127.0.0.1:52548 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:45] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:45] INFO:     127.0.0.1:52552 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:45] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 869, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:45] INFO:     127.0.0.1:52556 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:47] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:47] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.29, #queue-req: 0, 
[2025-12-17 20:41:47] INFO:     127.0.0.1:52560 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:47] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 1260, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:47] INFO:     127.0.0.1:52564 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:49] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:49] INFO:     127.0.0.1:52570 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:49] Prefill batch, #new-seq: 1, #new-token: 1148, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:49] Decode batch, #running-req: 1, #token: 1199, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.03, #queue-req: 0, 
[2025-12-17 20:41:49] Decode batch, #running-req: 1, #token: 1239, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.07, #queue-req: 0, 
[2025-12-17 20:41:49] Decode batch, #running-req: 1, #token: 1279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:41:49] Decode batch, #running-req: 1, #token: 1319, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:41:49] Decode batch, #running-req: 1, #token: 1359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:41:50] Decode batch, #running-req: 1, #token: 1399, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:41:50] Decode batch, #running-req: 1, #token: 1439, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 20:41:50] Decode batch, #running-req: 1, #token: 1479, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.37, #queue-req: 0, 
[2025-12-17 20:41:50] Decode batch, #running-req: 1, #token: 1519, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.27, #queue-req: 0, 
[2025-12-17 20:41:50] Decode batch, #running-req: 1, #token: 1559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:41:51] Decode batch, #running-req: 1, #token: 1599, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:41:51] Decode batch, #running-req: 1, #token: 1639, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 20:41:51] Decode batch, #running-req: 1, #token: 1679, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:41:51] Decode batch, #running-req: 1, #token: 1719, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:41:51] Decode batch, #running-req: 1, #token: 1759, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:41:51] Decode batch, #running-req: 1, #token: 1799, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.88, #queue-req: 0, 
[2025-12-17 20:41:52] Decode batch, #running-req: 1, #token: 1839, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:41:52] Decode batch, #running-req: 1, #token: 1879, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:41:52] Decode batch, #running-req: 1, #token: 1919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:41:52] Decode batch, #running-req: 1, #token: 1959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:41:52] Decode batch, #running-req: 1, #token: 1999, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.90, #queue-req: 0, 
[2025-12-17 20:41:53] Decode batch, #running-req: 1, #token: 2039, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:41:53] Decode batch, #running-req: 1, #token: 2079, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:41:53] Decode batch, #running-req: 1, #token: 2119, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.17, #queue-req: 0, 
[2025-12-17 20:41:53] Decode batch, #running-req: 1, #token: 2159, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.36, #queue-req: 0, 
[2025-12-17 20:41:53] INFO:     127.0.0.1:52574 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:55] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:55] INFO:     127.0.0.1:52580 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:55] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 795, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:55] Decode batch, #running-req: 1, #token: 814, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.35, #queue-req: 0, 
[2025-12-17 20:41:55] INFO:     127.0.0.1:52584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:57] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:57] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.70, #queue-req: 0, 
[2025-12-17 20:41:57] INFO:     127.0.0.1:52588 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:41:57] Prefill batch, #new-seq: 1, #new-token: 1195, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:41:57] Decode batch, #running-req: 1, #token: 1267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 188.63, #queue-req: 0, 
[2025-12-17 20:41:57] Decode batch, #running-req: 1, #token: 1307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.92, #queue-req: 0, 
[2025-12-17 20:41:57] Decode batch, #running-req: 1, #token: 1347, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:41:58] Decode batch, #running-req: 1, #token: 1387, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.94, #queue-req: 0, 
[2025-12-17 20:41:58] Decode batch, #running-req: 1, #token: 1427, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.98, #queue-req: 0, 
[2025-12-17 20:41:58] Decode batch, #running-req: 1, #token: 1467, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.02, #queue-req: 0, 
[2025-12-17 20:41:58] Decode batch, #running-req: 1, #token: 1507, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.06, #queue-req: 0, 
[2025-12-17 20:41:58] Decode batch, #running-req: 1, #token: 1547, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.08, #queue-req: 0, 
[2025-12-17 20:41:58] Decode batch, #running-req: 1, #token: 1587, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:41:59] Decode batch, #running-req: 1, #token: 1627, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:41:59] Decode batch, #running-req: 1, #token: 1667, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:41:59] Decode batch, #running-req: 1, #token: 1707, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:41:59] Decode batch, #running-req: 1, #token: 1747, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:41:59] Decode batch, #running-req: 1, #token: 1787, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:42:00] Decode batch, #running-req: 1, #token: 1827, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:42:00] Decode batch, #running-req: 1, #token: 1867, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:42:00] Decode batch, #running-req: 1, #token: 1907, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:42:00] Decode batch, #running-req: 1, #token: 1947, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:42:00] Decode batch, #running-req: 1, #token: 1987, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.94, #queue-req: 0, 
[2025-12-17 20:42:00] Decode batch, #running-req: 1, #token: 2027, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:42:01] Decode batch, #running-req: 1, #token: 2067, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:42:01] Decode batch, #running-req: 1, #token: 2107, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.38, #queue-req: 0, 
[2025-12-17 20:42:01] Decode batch, #running-req: 1, #token: 2147, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.28, #queue-req: 0, 
[2025-12-17 20:42:01] Decode batch, #running-req: 1, #token: 2187, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.37, #queue-req: 0, 
[2025-12-17 20:42:01] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.98, #queue-req: 0, 
[2025-12-17 20:42:01] INFO:     127.0.0.1:52592 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:03] Prefill batch, #new-seq: 1, #new-token: 60, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:03] INFO:     127.0.0.1:52598 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:03] Prefill batch, #new-seq: 1, #new-token: 26, #cached-token: 795, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:03] INFO:     127.0.0.1:52602 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:05] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:05] Decode batch, #running-req: 1, #token: 97, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.94, #queue-req: 0, 
[2025-12-17 20:42:05] INFO:     127.0.0.1:52608 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:05] Prefill batch, #new-seq: 1, #new-token: 26, #cached-token: 1146, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:05] INFO:     127.0.0.1:52612 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:07] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:07] INFO:     127.0.0.1:52618 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:07] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 795, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:07] Decode batch, #running-req: 1, #token: 826, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.19, #queue-req: 0, 
[2025-12-17 20:42:07] INFO:     127.0.0.1:52622 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:10] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:10] INFO:     127.0.0.1:52626 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:10] Prefill batch, #new-seq: 1, #new-token: 25, #cached-token: 794, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:10] INFO:     127.0.0.1:52630 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:12] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:12] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.27, #queue-req: 0, 
[2025-12-17 20:42:12] INFO:     127.0.0.1:52636 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:12] Prefill batch, #new-seq: 1, #new-token: 1114, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:12] Decode batch, #running-req: 1, #token: 1176, token usage: 0.00, cuda graph: True, gen throughput (token/s): 191.76, #queue-req: 0, 
[2025-12-17 20:42:12] INFO:     127.0.0.1:52640 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:13] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:14] INFO:     127.0.0.1:52644 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:14] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 796, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:14] INFO:     127.0.0.1:52648 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:15] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:15] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.30, #queue-req: 0, 
[2025-12-17 20:42:15] INFO:     127.0.0.1:52652 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:15] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 796, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:15] INFO:     127.0.0.1:52656 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:17] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:17] INFO:     127.0.0.1:52662 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:17] Prefill batch, #new-seq: 1, #new-token: 24, #cached-token: 1150, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:17] Decode batch, #running-req: 1, #token: 1188, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.20, #queue-req: 0, 
[2025-12-17 20:42:17] INFO:     127.0.0.1:52666 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:19] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:19] INFO:     127.0.0.1:52670 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:19] Prefill batch, #new-seq: 1, #new-token: 1245, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:19] INFO:     127.0.0.1:52674 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:21] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:21] INFO:     127.0.0.1:52678 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:21] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 773, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:21] Decode batch, #running-req: 1, #token: 808, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.14, #queue-req: 0, 
[2025-12-17 20:42:21] INFO:     127.0.0.1:52682 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:22] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:23] Decode batch, #running-req: 1, #token: 104, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.88, #queue-req: 0, 
[2025-12-17 20:42:23] Decode batch, #running-req: 1, #token: 144, token usage: 0.00, cuda graph: True, gen throughput (token/s): 226.82, #queue-req: 0, 
[2025-12-17 20:42:23] Decode batch, #running-req: 1, #token: 184, token usage: 0.00, cuda graph: True, gen throughput (token/s): 225.84, #queue-req: 0, 
[2025-12-17 20:42:23] Decode batch, #running-req: 1, #token: 224, token usage: 0.00, cuda graph: True, gen throughput (token/s): 225.68, #queue-req: 0, 
[2025-12-17 20:42:23] Decode batch, #running-req: 1, #token: 264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 225.37, #queue-req: 0, 
[2025-12-17 20:42:24] Decode batch, #running-req: 1, #token: 304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 223.32, #queue-req: 0, 
[2025-12-17 20:42:24] Decode batch, #running-req: 1, #token: 344, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.84, #queue-req: 0, 
[2025-12-17 20:42:24] Decode batch, #running-req: 1, #token: 384, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.36, #queue-req: 0, 
[2025-12-17 20:42:24] Decode batch, #running-req: 1, #token: 424, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.69, #queue-req: 0, 
[2025-12-17 20:42:24] Decode batch, #running-req: 1, #token: 464, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.61, #queue-req: 0, 
[2025-12-17 20:42:24] Decode batch, #running-req: 1, #token: 504, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.53, #queue-req: 0, 
[2025-12-17 20:42:25] Decode batch, #running-req: 1, #token: 544, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.51, #queue-req: 0, 
[2025-12-17 20:42:25] Decode batch, #running-req: 1, #token: 584, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.58, #queue-req: 0, 
[2025-12-17 20:42:25] Decode batch, #running-req: 1, #token: 624, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.42, #queue-req: 0, 
[2025-12-17 20:42:25] Decode batch, #running-req: 1, #token: 664, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.40, #queue-req: 0, 
[2025-12-17 20:42:25] Decode batch, #running-req: 1, #token: 704, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.48, #queue-req: 0, 
[2025-12-17 20:42:26] Decode batch, #running-req: 1, #token: 744, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.45, #queue-req: 0, 
[2025-12-17 20:42:26] Decode batch, #running-req: 1, #token: 784, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.40, #queue-req: 0, 
[2025-12-17 20:42:26] Decode batch, #running-req: 1, #token: 824, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.23, #queue-req: 0, 
[2025-12-17 20:42:26] Decode batch, #running-req: 1, #token: 864, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.14, #queue-req: 0, 
[2025-12-17 20:42:26] Decode batch, #running-req: 1, #token: 904, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.15, #queue-req: 0, 
[2025-12-17 20:42:26] Decode batch, #running-req: 1, #token: 944, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.39, #queue-req: 0, 
[2025-12-17 20:42:27] Decode batch, #running-req: 1, #token: 984, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.25, #queue-req: 0, 
[2025-12-17 20:42:27] Decode batch, #running-req: 1, #token: 1024, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.15, #queue-req: 0, 
[2025-12-17 20:42:27] Decode batch, #running-req: 1, #token: 1064, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.64, #queue-req: 0, 
[2025-12-17 20:42:27] INFO:     127.0.0.1:52686 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:27] Prefill batch, #new-seq: 1, #new-token: 1206, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:27] INFO:     127.0.0.1:52692 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:29] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:29] INFO:     127.0.0.1:52696 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:29] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 665, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:29] Decode batch, #running-req: 1, #token: 708, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.04, #queue-req: 0, 
[2025-12-17 20:42:29] INFO:     127.0.0.1:52700 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:31] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:31] INFO:     127.0.0.1:52704 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:31] Prefill batch, #new-seq: 1, #new-token: 1047, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:31] Decode batch, #running-req: 1, #token: 1088, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.32, #queue-req: 0, 
[2025-12-17 20:42:31] INFO:     127.0.0.1:52708 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:32] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:32] INFO:     127.0.0.1:52712 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:33] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 774, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:33] INFO:     127.0.0.1:52716 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:34] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:34] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.32, #queue-req: 0, 
[2025-12-17 20:42:34] INFO:     127.0.0.1:52720 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:34] Prefill batch, #new-seq: 1, #new-token: 1265, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:34] INFO:     127.0.0.1:52724 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:36] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:36] Decode batch, #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.38, #queue-req: 0, 
[2025-12-17 20:42:36] INFO:     127.0.0.1:52730 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:36] Prefill batch, #new-seq: 1, #new-token: 1051, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:36] INFO:     127.0.0.1:52734 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:38] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:38] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.31, #queue-req: 0, 
[2025-12-17 20:42:38] INFO:     127.0.0.1:52738 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:38] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:38] INFO:     127.0.0.1:52742 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:40] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:40] INFO:     127.0.0.1:52746 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:40] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 847, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:40] Decode batch, #running-req: 1, #token: 899, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.69, #queue-req: 0, 
[2025-12-17 20:42:40] INFO:     127.0.0.1:52750 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:42] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:42] INFO:     127.0.0.1:52758 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:42] Prefill batch, #new-seq: 1, #new-token: 28, #cached-token: 773, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:43] INFO:     127.0.0.1:52762 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:44] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:44] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.33, #queue-req: 0, 
[2025-12-17 20:42:44] INFO:     127.0.0.1:52766 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:44] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 774, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:44] INFO:     127.0.0.1:52770 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:46] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:46] INFO:     127.0.0.1:52774 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:46] Prefill batch, #new-seq: 1, #new-token: 1294, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:46] Decode batch, #running-req: 1, #token: 1322, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.91, #queue-req: 0, 
[2025-12-17 20:42:46] INFO:     127.0.0.1:52778 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:48] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:48] INFO:     127.0.0.1:52782 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:48] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 1128, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:48] INFO:     127.0.0.1:52786 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:50] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:50] Decode batch, #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.24, #queue-req: 0, 
[2025-12-17 20:42:50] INFO:     127.0.0.1:52790 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:50] Prefill batch, #new-seq: 1, #new-token: 1207, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:50] INFO:     127.0.0.1:52794 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:52] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:52] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.31, #queue-req: 0, 
[2025-12-17 20:42:52] INFO:     127.0.0.1:52798 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:52] Prefill batch, #new-seq: 1, #new-token: 953, #cached-token: 83, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:52] INFO:     127.0.0.1:52802 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:53] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:53] INFO:     127.0.0.1:52806 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:53] Prefill batch, #new-seq: 1, #new-token: 1176, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:53] Decode batch, #running-req: 1, #token: 1198, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.95, #queue-req: 0, 
[2025-12-17 20:42:54] INFO:     127.0.0.1:52810 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:55] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:55] INFO:     127.0.0.1:52814 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:55] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 847, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:55] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.49, #queue-req: 0, 
[2025-12-17 20:42:55] INFO:     127.0.0.1:52818 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:57] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:57] INFO:     127.0.0.1:52822 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:57] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 1128, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:57] INFO:     127.0.0.1:52826 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:59] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:59] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.27, #queue-req: 0, 
[2025-12-17 20:42:59] INFO:     127.0.0.1:52830 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:42:59] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 1119, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:42:59] INFO:     127.0.0.1:52834 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:01] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:01] INFO:     127.0.0.1:52838 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:01] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 1129, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:01] Decode batch, #running-req: 1, #token: 1166, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.97, #queue-req: 0, 
[2025-12-17 20:43:01] INFO:     127.0.0.1:52842 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:03] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:03] INFO:     127.0.0.1:52846 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:03] Prefill batch, #new-seq: 1, #new-token: 27, #cached-token: 774, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:03] INFO:     127.0.0.1:52850 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:03] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.48, #queue-req: 0, 
[2025-12-17 20:43:04] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:04] INFO:     127.0.0.1:52854 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:04] Prefill batch, #new-seq: 1, #new-token: 1297, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:04] INFO:     127.0.0.1:52858 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:06] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:06] INFO:     127.0.0.1:52862 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:06] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:06] Decode batch, #running-req: 1, #token: 816, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.16, #queue-req: 0, 
[2025-12-17 20:43:06] INFO:     127.0.0.1:52866 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:08] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:08] INFO:     127.0.0.1:52870 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:08] Prefill batch, #new-seq: 1, #new-token: 1064, #cached-token: 42, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:08] INFO:     127.0.0.1:52874 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:10] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:10] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.26, #queue-req: 0, 
[2025-12-17 20:43:10] INFO:     127.0.0.1:52878 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:10] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 849, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:10] INFO:     127.0.0.1:52882 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:12] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:12] INFO:     127.0.0.1:52886 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:12] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:12] Decode batch, #running-req: 1, #token: 823, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.01, #queue-req: 0, 
[2025-12-17 20:43:12] INFO:     127.0.0.1:52890 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:13] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:13] INFO:     127.0.0.1:52894 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:13] Prefill batch, #new-seq: 1, #new-token: 1208, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:14] INFO:     127.0.0.1:52898 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:15] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:15] INFO:     127.0.0.1:52902 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:15] Prefill batch, #new-seq: 1, #new-token: 1243, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:15] Decode batch, #running-req: 1, #token: 1277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.12, #queue-req: 0, 
[2025-12-17 20:43:15] INFO:     127.0.0.1:52906 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:18] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:18] INFO:     127.0.0.1:52912 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:18] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 774, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:18] Decode batch, #running-req: 1, #token: 825, token usage: 0.00, cuda graph: True, gen throughput (token/s): 15.21, #queue-req: 0, 
[2025-12-17 20:43:18] INFO:     127.0.0.1:52916 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:20] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:20] INFO:     127.0.0.1:52920 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:20] Prefill batch, #new-seq: 1, #new-token: 668, #cached-token: 59, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:20] INFO:     127.0.0.1:52924 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:21] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:22] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.18, #queue-req: 0, 
[2025-12-17 20:43:22] INFO:     127.0.0.1:52928 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:22] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 776, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:22] INFO:     127.0.0.1:52932 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:23] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:23] INFO:     127.0.0.1:52936 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:23] Prefill batch, #new-seq: 1, #new-token: 1078, #cached-token: 126, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:23] Decode batch, #running-req: 1, #token: 1214, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.82, #queue-req: 0, 
[2025-12-17 20:43:23] INFO:     127.0.0.1:52940 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:25] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:25] INFO:     127.0.0.1:52944 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:25] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 848, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:25] INFO:     127.0.0.1:52948 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:27] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:27] Decode batch, #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.24, #queue-req: 0, 
[2025-12-17 20:43:27] INFO:     127.0.0.1:52952 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:27] Prefill batch, #new-seq: 1, #new-token: 1302, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:27] INFO:     127.0.0.1:52956 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:29] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:29] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.25, #queue-req: 0, 
[2025-12-17 20:43:29] INFO:     127.0.0.1:52960 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:29] Prefill batch, #new-seq: 1, #new-token: 904, #cached-token: 296, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:29] INFO:     127.0.0.1:52964 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:31] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:31] INFO:     127.0.0.1:52970 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:31] Prefill batch, #new-seq: 1, #new-token: 982, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:31] INFO:     127.0.0.1:52974 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:33] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:33] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.06, #queue-req: 0, 
[2025-12-17 20:43:33] INFO:     127.0.0.1:52978 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:33] Prefill batch, #new-seq: 1, #new-token: 1083, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:33] INFO:     127.0.0.1:52982 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:35] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:35] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.34, #queue-req: 0, 
[2025-12-17 20:43:35] INFO:     127.0.0.1:52986 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:35] Prefill batch, #new-seq: 1, #new-token: 815, #cached-token: 423, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:35] INFO:     127.0.0.1:52990 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:37] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:37] Decode batch, #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.26, #queue-req: 0, 
[2025-12-17 20:43:37] INFO:     127.0.0.1:52994 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:37] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 774, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:37] INFO:     127.0.0.1:52998 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:38] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:38] INFO:     127.0.0.1:53002 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:38] Prefill batch, #new-seq: 1, #new-token: 1135, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:38] Decode batch, #running-req: 1, #token: 1177, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.85, #queue-req: 0, 
[2025-12-17 20:43:39] INFO:     127.0.0.1:53006 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:45] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:45] INFO:     127.0.0.1:53014 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:45] Prefill batch, #new-seq: 1, #new-token: 1244, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:45] Decode batch, #running-req: 1, #token: 1262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 6.39, #queue-req: 0, 
[2025-12-17 20:43:45] INFO:     127.0.0.1:53018 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:47] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:47] INFO:     127.0.0.1:53022 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:47] Prefill batch, #new-seq: 1, #new-token: 777, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:47] INFO:     127.0.0.1:53026 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:49] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:49] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.90, #queue-req: 0, 
[2025-12-17 20:43:49] INFO:     127.0.0.1:53030 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:49] Prefill batch, #new-seq: 1, #new-token: 1097, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:49] INFO:     127.0.0.1:53034 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:51] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:51] Decode batch, #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.53, #queue-req: 0, 
[2025-12-17 20:43:51] INFO:     127.0.0.1:53038 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:51] Prefill batch, #new-seq: 1, #new-token: 1274, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:51] INFO:     127.0.0.1:53042 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:52] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:53] INFO:     127.0.0.1:53048 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:53] Prefill batch, #new-seq: 1, #new-token: 1079, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:53] INFO:     127.0.0.1:53052 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:54] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:54] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.06, #queue-req: 0, 
[2025-12-17 20:43:54] INFO:     127.0.0.1:53056 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:54] Prefill batch, #new-seq: 1, #new-token: 1096, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:54] INFO:     127.0.0.1:53060 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:56] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:56] INFO:     127.0.0.1:53064 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:56] Prefill batch, #new-seq: 1, #new-token: 805, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:56] Decode batch, #running-req: 1, #token: 820, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.12, #queue-req: 0, 
[2025-12-17 20:43:56] INFO:     127.0.0.1:53068 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:58] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:58] INFO:     127.0.0.1:53072 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:43:58] Prefill batch, #new-seq: 1, #new-token: 799, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:43:58] INFO:     127.0.0.1:53076 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:00] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:00] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.23, #queue-req: 0, 
[2025-12-17 20:44:00] INFO:     127.0.0.1:53082 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:00] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 774, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:00] INFO:     127.0.0.1:53086 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:02] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:02] INFO:     127.0.0.1:53092 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:02] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.40, #queue-req: 0, 
[2025-12-17 20:44:02] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 792, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:02] INFO:     127.0.0.1:53096 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:03] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:03] INFO:     127.0.0.1:53100 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:03] Prefill batch, #new-seq: 1, #new-token: 1070, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:04] Decode batch, #running-req: 1, #token: 1103, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.98, #queue-req: 0, 
[2025-12-17 20:44:04] Decode batch, #running-req: 1, #token: 1143, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:44:04] Decode batch, #running-req: 1, #token: 1183, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:44:04] Decode batch, #running-req: 1, #token: 1223, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.64, #queue-req: 0, 
[2025-12-17 20:44:04] Decode batch, #running-req: 1, #token: 1263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:44:04] Decode batch, #running-req: 1, #token: 1303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:44:05] Decode batch, #running-req: 1, #token: 1343, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:44:05] Decode batch, #running-req: 1, #token: 1383, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 20:44:05] Decode batch, #running-req: 1, #token: 1423, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.53, #queue-req: 0, 
[2025-12-17 20:44:05] Decode batch, #running-req: 1, #token: 1463, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:44:05] Decode batch, #running-req: 1, #token: 1503, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:44:06] Decode batch, #running-req: 1, #token: 1543, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:44:06] Decode batch, #running-req: 1, #token: 1583, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:44:06] Decode batch, #running-req: 1, #token: 1623, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 20:44:06] Decode batch, #running-req: 1, #token: 1663, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.36, #queue-req: 0, 
[2025-12-17 20:44:06] Decode batch, #running-req: 1, #token: 1703, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.40, #queue-req: 0, 
[2025-12-17 20:44:06] Decode batch, #running-req: 1, #token: 1743, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.43, #queue-req: 0, 
[2025-12-17 20:44:07] Decode batch, #running-req: 1, #token: 1783, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 20:44:07] Decode batch, #running-req: 1, #token: 1823, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.38, #queue-req: 0, 
[2025-12-17 20:44:07] Decode batch, #running-req: 1, #token: 1863, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.26, #queue-req: 0, 
[2025-12-17 20:44:07] Decode batch, #running-req: 1, #token: 1903, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.21, #queue-req: 0, 
[2025-12-17 20:44:07] Decode batch, #running-req: 1, #token: 1943, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.35, #queue-req: 0, 
[2025-12-17 20:44:08] Decode batch, #running-req: 1, #token: 1983, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 20:44:08] Decode batch, #running-req: 1, #token: 2023, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.37, #queue-req: 0, 
[2025-12-17 20:44:08] Decode batch, #running-req: 1, #token: 2063, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.21, #queue-req: 0, 
[2025-12-17 20:44:08] INFO:     127.0.0.1:53104 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:10] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:10] INFO:     127.0.0.1:53108 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:10] Prefill batch, #new-seq: 1, #new-token: 991, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:10] Decode batch, #running-req: 1, #token: 1032, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.50, #queue-req: 0, 
[2025-12-17 20:44:10] INFO:     127.0.0.1:53112 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:12] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:12] INFO:     127.0.0.1:53118 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:12] Prefill batch, #new-seq: 1, #new-token: 857, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:12] Decode batch, #running-req: 1, #token: 909, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.41, #queue-req: 0, 
[2025-12-17 20:44:12] INFO:     127.0.0.1:53122 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:14] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:14] INFO:     127.0.0.1:53126 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:14] Prefill batch, #new-seq: 1, #new-token: 684, #cached-token: 16, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:14] INFO:     127.0.0.1:53130 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:16] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:16] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.37, #queue-req: 0, 
[2025-12-17 20:44:16] INFO:     127.0.0.1:53134 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:16] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 691, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:16] Decode batch, #running-req: 1, #token: 742, token usage: 0.00, cuda graph: True, gen throughput (token/s): 188.04, #queue-req: 0, 
[2025-12-17 20:44:17] Decode batch, #running-req: 1, #token: 782, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.60, #queue-req: 0, 
[2025-12-17 20:44:17] Decode batch, #running-req: 1, #token: 822, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.55, #queue-req: 0, 
[2025-12-17 20:44:17] Decode batch, #running-req: 1, #token: 862, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.60, #queue-req: 0, 
[2025-12-17 20:44:17] Decode batch, #running-req: 1, #token: 902, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.27, #queue-req: 0, 
[2025-12-17 20:44:17] Decode batch, #running-req: 1, #token: 942, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.62, #queue-req: 0, 
[2025-12-17 20:44:17] Decode batch, #running-req: 1, #token: 982, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.65, #queue-req: 0, 
[2025-12-17 20:44:18] Decode batch, #running-req: 1, #token: 1022, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.53, #queue-req: 0, 
[2025-12-17 20:44:18] Decode batch, #running-req: 1, #token: 1062, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.18, #queue-req: 0, 
[2025-12-17 20:44:18] Decode batch, #running-req: 1, #token: 1102, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:44:18] Decode batch, #running-req: 1, #token: 1142, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 20:44:18] Decode batch, #running-req: 1, #token: 1182, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:44:19] Decode batch, #running-req: 1, #token: 1222, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.94, #queue-req: 0, 
[2025-12-17 20:44:19] Decode batch, #running-req: 1, #token: 1262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 20:44:19] Decode batch, #running-req: 1, #token: 1302, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:44:19] Decode batch, #running-req: 1, #token: 1342, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.05, #queue-req: 0, 
[2025-12-17 20:44:19] Decode batch, #running-req: 1, #token: 1382, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:44:19] Decode batch, #running-req: 1, #token: 1422, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.96, #queue-req: 0, 
[2025-12-17 20:44:20] Decode batch, #running-req: 1, #token: 1462, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.03, #queue-req: 0, 
[2025-12-17 20:44:20] Decode batch, #running-req: 1, #token: 1502, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.98, #queue-req: 0, 
[2025-12-17 20:44:20] Decode batch, #running-req: 1, #token: 1542, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.09, #queue-req: 0, 
[2025-12-17 20:44:20] Decode batch, #running-req: 1, #token: 1582, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:44:20] Decode batch, #running-req: 1, #token: 1622, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:44:20] Decode batch, #running-req: 1, #token: 1662, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:44:21] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.43, #queue-req: 0, 
[2025-12-17 20:44:21] INFO:     127.0.0.1:53138 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:22] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:22] INFO:     127.0.0.1:53146 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:22] Prefill batch, #new-seq: 1, #new-token: 1132, #cached-token: 128, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:23] Decode batch, #running-req: 1, #token: 1274, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.39, #queue-req: 0, 
[2025-12-17 20:44:23] INFO:     127.0.0.1:53150 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:24] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:24] INFO:     127.0.0.1:53154 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:24] Prefill batch, #new-seq: 1, #new-token: 1362, #cached-token: 16, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:24] INFO:     127.0.0.1:53158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:26] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:26] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.08, #queue-req: 0, 
[2025-12-17 20:44:26] INFO:     127.0.0.1:53164 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:26] Prefill batch, #new-seq: 1, #new-token: 596, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:26] INFO:     127.0.0.1:53168 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:28] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:28] INFO:     127.0.0.1:53172 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:28] Prefill batch, #new-seq: 1, #new-token: 691, #cached-token: 18, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:28] Decode batch, #running-req: 1, #token: 715, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.07, #queue-req: 0, 
[2025-12-17 20:44:28] INFO:     127.0.0.1:53176 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:30] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:30] INFO:     127.0.0.1:53180 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:30] Prefill batch, #new-seq: 1, #new-token: 1139, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:30] INFO:     127.0.0.1:53184 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:32] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:32] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.22, #queue-req: 0, 
[2025-12-17 20:44:32] INFO:     127.0.0.1:53188 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:32] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:32] INFO:     127.0.0.1:53192 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:33] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:34] Decode batch, #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.05, #queue-req: 0, 
[2025-12-17 20:44:34] INFO:     127.0.0.1:53196 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:34] Prefill batch, #new-seq: 1, #new-token: 1119, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:34] INFO:     127.0.0.1:53200 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:35] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:35] INFO:     127.0.0.1:53204 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:35] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 664, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:35] Decode batch, #running-req: 1, #token: 730, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.75, #queue-req: 0, 
[2025-12-17 20:44:35] INFO:     127.0.0.1:53208 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:37] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:37] INFO:     127.0.0.1:53212 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:37] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 748, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:37] Decode batch, #running-req: 1, #token: 807, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.96, #queue-req: 0, 
[2025-12-17 20:44:37] INFO:     127.0.0.1:53216 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:39] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:39] INFO:     127.0.0.1:53220 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:39] Prefill batch, #new-seq: 1, #new-token: 1257, #cached-token: 16, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:39] Decode batch, #running-req: 1, #token: 1290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.09, #queue-req: 0, 
[2025-12-17 20:44:39] INFO:     127.0.0.1:53224 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:41] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:41] INFO:     127.0.0.1:53228 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:41] Prefill batch, #new-seq: 1, #new-token: 1086, #cached-token: 17, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:41] INFO:     127.0.0.1:53232 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:43] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:43] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.25, #queue-req: 0, 
[2025-12-17 20:44:43] INFO:     127.0.0.1:53238 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:43] Prefill batch, #new-seq: 1, #new-token: 1160, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:43] INFO:     127.0.0.1:53242 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:45] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:45] INFO:     127.0.0.1:53246 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:45] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 793, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:45] Decode batch, #running-req: 1, #token: 813, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.42, #queue-req: 0, 
[2025-12-17 20:44:45] Decode batch, #running-req: 1, #token: 853, token usage: 0.00, cuda graph: True, gen throughput (token/s): 209.10, #queue-req: 0, 
[2025-12-17 20:44:45] Decode batch, #running-req: 1, #token: 893, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.39, #queue-req: 0, 
[2025-12-17 20:44:45] Decode batch, #running-req: 1, #token: 933, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.37, #queue-req: 0, 
[2025-12-17 20:44:46] Decode batch, #running-req: 1, #token: 973, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.41, #queue-req: 0, 
[2025-12-17 20:44:46] Decode batch, #running-req: 1, #token: 1013, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.29, #queue-req: 0, 
[2025-12-17 20:44:46] Decode batch, #running-req: 1, #token: 1053, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.88, #queue-req: 0, 
[2025-12-17 20:44:46] Decode batch, #running-req: 1, #token: 1093, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:44:46] Decode batch, #running-req: 1, #token: 1133, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:44:47] Decode batch, #running-req: 1, #token: 1173, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:44:47] Decode batch, #running-req: 1, #token: 1213, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:44:47] Decode batch, #running-req: 1, #token: 1253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.53, #queue-req: 0, 
[2025-12-17 20:44:47] Decode batch, #running-req: 1, #token: 1293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:44:47] Decode batch, #running-req: 1, #token: 1333, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.64, #queue-req: 0, 
[2025-12-17 20:44:47] Decode batch, #running-req: 1, #token: 1373, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.46, #queue-req: 0, 
[2025-12-17 20:44:48] Decode batch, #running-req: 1, #token: 1413, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:44:48] Decode batch, #running-req: 1, #token: 1453, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:44:48] Decode batch, #running-req: 1, #token: 1493, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:44:48] Decode batch, #running-req: 1, #token: 1533, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:44:48] Decode batch, #running-req: 1, #token: 1573, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:44:49] Decode batch, #running-req: 1, #token: 1613, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 20:44:49] Decode batch, #running-req: 1, #token: 1653, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 20:44:49] Decode batch, #running-req: 1, #token: 1693, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 20:44:49] Decode batch, #running-req: 1, #token: 1733, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 20:44:49] Decode batch, #running-req: 1, #token: 1773, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 20:44:49] INFO:     127.0.0.1:53250 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:51] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:51] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.52, #queue-req: 0, 
[2025-12-17 20:44:51] INFO:     127.0.0.1:53256 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:51] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 776, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:51] INFO:     127.0.0.1:53260 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:53] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:53] INFO:     127.0.0.1:53264 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:53] Prefill batch, #new-seq: 1, #new-token: 1314, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:53] Decode batch, #running-req: 1, #token: 1331, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.55, #queue-req: 0, 
[2025-12-17 20:44:53] INFO:     127.0.0.1:53268 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:55] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:55] INFO:     127.0.0.1:53272 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:55] Prefill batch, #new-seq: 1, #new-token: 1209, #cached-token: 88, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:55] INFO:     127.0.0.1:53276 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:57] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:57] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.35, #queue-req: 0, 
[2025-12-17 20:44:57] INFO:     127.0.0.1:53280 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:57] Prefill batch, #new-seq: 1, #new-token: 1104, #cached-token: 114, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:57] INFO:     127.0.0.1:53284 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:58] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:58] INFO:     127.0.0.1:53288 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:44:58] Prefill batch, #new-seq: 1, #new-token: 7, #cached-token: 1075, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:44:58] INFO:     127.0.0.1:53292 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:00] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:00] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.38, #queue-req: 0, 
[2025-12-17 20:45:00] INFO:     127.0.0.1:53296 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:00] Prefill batch, #new-seq: 1, #new-token: 1137, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:01] INFO:     127.0.0.1:53300 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:03] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:03] INFO:     127.0.0.1:53304 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:03] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 793, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:03] Decode batch, #running-req: 1, #token: 813, token usage: 0.00, cuda graph: True, gen throughput (token/s): 14.58, #queue-req: 0, 
[2025-12-17 20:45:03] INFO:     127.0.0.1:53308 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:05] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:05] INFO:     127.0.0.1:53312 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:05] Prefill batch, #new-seq: 1, #new-token: 1344, #cached-token: 18, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:05] INFO:     127.0.0.1:53316 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:07] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:07] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.25, #queue-req: 0, 
[2025-12-17 20:45:07] INFO:     127.0.0.1:53320 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:07] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 692, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:07] INFO:     127.0.0.1:53324 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:08] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:09] INFO:     127.0.0.1:53328 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:09] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 738, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:09] Decode batch, #running-req: 1, #token: 758, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.07, #queue-req: 0, 
[2025-12-17 20:45:09] INFO:     127.0.0.1:53332 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:11] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:11] INFO:     127.0.0.1:53336 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:11] Prefill batch, #new-seq: 1, #new-token: 1514, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:11] Decode batch, #running-req: 1, #token: 1576, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.65, #queue-req: 0, 
[2025-12-17 20:45:11] Decode batch, #running-req: 1, #token: 1616, token usage: 0.00, cuda graph: True, gen throughput (token/s): 216.14, #queue-req: 0, 
[2025-12-17 20:45:11] Decode batch, #running-req: 1, #token: 1656, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 20:45:12] Decode batch, #running-req: 1, #token: 1696, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:45:12] Decode batch, #running-req: 1, #token: 1736, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 20:45:12] Decode batch, #running-req: 1, #token: 1776, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:45:12] Decode batch, #running-req: 1, #token: 1816, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.45, #queue-req: 0, 
[2025-12-17 20:45:12] Decode batch, #running-req: 1, #token: 1856, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:45:12] Decode batch, #running-req: 1, #token: 1896, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 20:45:13] Decode batch, #running-req: 1, #token: 1936, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.34, #queue-req: 0, 
[2025-12-17 20:45:13] Decode batch, #running-req: 1, #token: 1976, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:45:13] Decode batch, #running-req: 1, #token: 2016, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.62, #queue-req: 0, 
[2025-12-17 20:45:13] Decode batch, #running-req: 1, #token: 2056, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.27, #queue-req: 0, 
[2025-12-17 20:45:13] Decode batch, #running-req: 1, #token: 2096, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.95, #queue-req: 0, 
[2025-12-17 20:45:14] Decode batch, #running-req: 1, #token: 2136, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.01, #queue-req: 0, 
[2025-12-17 20:45:14] Decode batch, #running-req: 1, #token: 2176, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.98, #queue-req: 0, 
[2025-12-17 20:45:14] Decode batch, #running-req: 1, #token: 2216, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.12, #queue-req: 0, 
[2025-12-17 20:45:14] Decode batch, #running-req: 1, #token: 2256, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.05, #queue-req: 0, 
[2025-12-17 20:45:14] Decode batch, #running-req: 1, #token: 2296, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.99, #queue-req: 0, 
[2025-12-17 20:45:14] Decode batch, #running-req: 1, #token: 2336, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.95, #queue-req: 0, 
[2025-12-17 20:45:15] Decode batch, #running-req: 1, #token: 2376, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.94, #queue-req: 0, 
[2025-12-17 20:45:15] Decode batch, #running-req: 1, #token: 2416, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.75, #queue-req: 0, 
[2025-12-17 20:45:15] Decode batch, #running-req: 1, #token: 2456, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.87, #queue-req: 0, 
[2025-12-17 20:45:15] Decode batch, #running-req: 1, #token: 2496, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.05, #queue-req: 0, 
[2025-12-17 20:45:15] Decode batch, #running-req: 1, #token: 2536, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.14, #queue-req: 0, 
[2025-12-17 20:45:15] INFO:     127.0.0.1:53340 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:18] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:18] INFO:     127.0.0.1:53346 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:18] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:18] Decode batch, #running-req: 1, #token: 802, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.67, #queue-req: 0, 
[2025-12-17 20:45:18] INFO:     127.0.0.1:53350 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:19] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:20] INFO:     127.0.0.1:53356 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:20] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 776, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:20] INFO:     127.0.0.1:53360 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:21] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:21] Decode batch, #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.18, #queue-req: 0, 
[2025-12-17 20:45:21] INFO:     127.0.0.1:53364 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:21] Prefill batch, #new-seq: 1, #new-token: 583, #cached-token: 151, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:22] INFO:     127.0.0.1:53368 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:23] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:23] INFO:     127.0.0.1:53372 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:23] Prefill batch, #new-seq: 1, #new-token: 1045, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:23] Decode batch, #running-req: 1, #token: 1060, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.97, #queue-req: 0, 
[2025-12-17 20:45:23] INFO:     127.0.0.1:53376 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:25] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:25] INFO:     127.0.0.1:53380 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:25] Prefill batch, #new-seq: 1, #new-token: 1525, #cached-token: 18, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:25] Decode batch, #running-req: 1, #token: 1553, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.19, #queue-req: 0, 
[2025-12-17 20:45:25] INFO:     127.0.0.1:53384 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:27] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:27] INFO:     127.0.0.1:53388 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:27] Prefill batch, #new-seq: 1, #new-token: 1020, #cached-token: 89, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:27] Decode batch, #running-req: 1, #token: 1127, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.17, #queue-req: 0, 
[2025-12-17 20:45:27] INFO:     127.0.0.1:53392 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:29] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:29] INFO:     127.0.0.1:53396 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:29] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 794, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:29] INFO:     127.0.0.1:53400 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:31] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:31] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.90, #queue-req: 0, 
[2025-12-17 20:45:31] INFO:     127.0.0.1:53404 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:31] Prefill batch, #new-seq: 1, #new-token: 1490, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:32] INFO:     127.0.0.1:53408 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:33] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:33] INFO:     127.0.0.1:53412 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:33] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 797, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:33] Decode batch, #running-req: 1, #token: 811, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.76, #queue-req: 0, 
[2025-12-17 20:45:34] Decode batch, #running-req: 1, #token: 851, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.27, #queue-req: 0, 
[2025-12-17 20:45:34] Decode batch, #running-req: 1, #token: 891, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.31, #queue-req: 0, 
[2025-12-17 20:45:34] Decode batch, #running-req: 1, #token: 931, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.27, #queue-req: 0, 
[2025-12-17 20:45:34] Decode batch, #running-req: 1, #token: 971, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.43, #queue-req: 0, 
[2025-12-17 20:45:34] Decode batch, #running-req: 1, #token: 1011, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.32, #queue-req: 0, 
[2025-12-17 20:45:34] Decode batch, #running-req: 1, #token: 1051, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:45:35] Decode batch, #running-req: 1, #token: 1091, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 20:45:35] Decode batch, #running-req: 1, #token: 1131, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:45:35] Decode batch, #running-req: 1, #token: 1171, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.83, #queue-req: 0, 
[2025-12-17 20:45:35] Decode batch, #running-req: 1, #token: 1211, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 20:45:35] Decode batch, #running-req: 1, #token: 1251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.55, #queue-req: 0, 
[2025-12-17 20:45:35] Decode batch, #running-req: 1, #token: 1291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 20:45:36] Decode batch, #running-req: 1, #token: 1331, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.63, #queue-req: 0, 
[2025-12-17 20:45:36] Decode batch, #running-req: 1, #token: 1371, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:45:36] Decode batch, #running-req: 1, #token: 1411, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:45:36] Decode batch, #running-req: 1, #token: 1451, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:45:36] Decode batch, #running-req: 1, #token: 1491, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:45:37] Decode batch, #running-req: 1, #token: 1531, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:45:37] Decode batch, #running-req: 1, #token: 1571, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.49, #queue-req: 0, 
[2025-12-17 20:45:37] Decode batch, #running-req: 1, #token: 1611, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:45:37] Decode batch, #running-req: 1, #token: 1651, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 20:45:37] Decode batch, #running-req: 1, #token: 1691, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 20:45:37] Decode batch, #running-req: 1, #token: 1731, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.43, #queue-req: 0, 
[2025-12-17 20:45:38] Decode batch, #running-req: 1, #token: 1771, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.46, #queue-req: 0, 
[2025-12-17 20:45:38] INFO:     127.0.0.1:53416 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:39] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:40] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.78, #queue-req: 0, 
[2025-12-17 20:45:40] INFO:     127.0.0.1:53422 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:40] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 776, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:40] INFO:     127.0.0.1:53426 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:41] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:41] INFO:     127.0.0.1:53430 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:41] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 774, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:41] Decode batch, #running-req: 1, #token: 797, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.12, #queue-req: 0, 
[2025-12-17 20:45:41] INFO:     127.0.0.1:53434 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:43] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:43] INFO:     127.0.0.1:53440 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:43] Prefill batch, #new-seq: 1, #new-token: 8, #cached-token: 798, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:43] INFO:     127.0.0.1:53444 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:45] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:45] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.05, #queue-req: 0, 
[2025-12-17 20:45:45] INFO:     127.0.0.1:53448 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:45] Prefill batch, #new-seq: 1, #new-token: 1305, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:45] INFO:     127.0.0.1:53452 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:47] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:47] INFO:     127.0.0.1:53458 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:47] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 797, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:47] Decode batch, #running-req: 1, #token: 823, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.11, #queue-req: 0, 
[2025-12-17 20:45:47] INFO:     127.0.0.1:53462 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:49] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:49] INFO:     127.0.0.1:53466 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:49] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 797, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:49] INFO:     127.0.0.1:53470 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:51] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:51] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.23, #queue-req: 0, 
[2025-12-17 20:45:51] INFO:     127.0.0.1:53478 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:51] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 793, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:51] INFO:     127.0.0.1:53482 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:53] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:53] INFO:     127.0.0.1:53486 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:53] Prefill batch, #new-seq: 1, #new-token: 1126, #cached-token: 154, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:53] Decode batch, #running-req: 1, #token: 1284, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.01, #queue-req: 0, 
[2025-12-17 20:45:53] INFO:     127.0.0.1:53490 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:54] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:55] INFO:     127.0.0.1:53496 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:55] Prefill batch, #new-seq: 1, #new-token: 1341, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:55] INFO:     127.0.0.1:53500 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:56] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:56] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.14, #queue-req: 0, 
[2025-12-17 20:45:56] INFO:     127.0.0.1:53506 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:56] Prefill batch, #new-seq: 1, #new-token: 1304, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:56] INFO:     127.0.0.1:53510 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:58] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:58] INFO:     127.0.0.1:53514 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:45:58] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:45:58] Decode batch, #running-req: 1, #token: 795, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.03, #queue-req: 0, 
[2025-12-17 20:45:58] INFO:     127.0.0.1:53518 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:00] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:00] INFO:     127.0.0.1:53522 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:00] Prefill batch, #new-seq: 1, #new-token: 1196, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:00] INFO:     127.0.0.1:53526 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:02] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:02] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.08, #queue-req: 0, 
[2025-12-17 20:46:02] INFO:     127.0.0.1:53530 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:02] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 735, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:02] INFO:     127.0.0.1:53534 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:04] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:04] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.23, #queue-req: 0, 
[2025-12-17 20:46:04] INFO:     127.0.0.1:53538 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:04] Prefill batch, #new-seq: 1, #new-token: 1221, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:04] INFO:     127.0.0.1:53542 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:05] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:06] INFO:     127.0.0.1:53548 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:06] Prefill batch, #new-seq: 1, #new-token: 1260, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:06] Decode batch, #running-req: 1, #token: 1278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.13, #queue-req: 0, 
[2025-12-17 20:46:06] INFO:     127.0.0.1:53552 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:07] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:07] INFO:     127.0.0.1:53556 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:07] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 715, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:07] INFO:     127.0.0.1:53560 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:09] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:09] Decode batch, #running-req: 1, #token: 72, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.03, #queue-req: 0, 
[2025-12-17 20:46:09] INFO:     127.0.0.1:53564 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:09] Prefill batch, #new-seq: 1, #new-token: 977, #cached-token: 86, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:09] INFO:     127.0.0.1:53568 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:11] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:11] INFO:     127.0.0.1:53572 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:11] Prefill batch, #new-seq: 1, #new-token: 1011, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:11] Decode batch, #running-req: 1, #token: 1048, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.02, #queue-req: 0, 
[2025-12-17 20:46:11] INFO:     127.0.0.1:53576 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:13] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:13] INFO:     127.0.0.1:53580 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:13] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 797, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:13] INFO:     127.0.0.1:53584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:15] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:15] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.33, #queue-req: 0, 
[2025-12-17 20:46:15] INFO:     127.0.0.1:53588 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:15] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:15] INFO:     127.0.0.1:53592 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:16] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:17] INFO:     127.0.0.1:53596 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:17] Prefill batch, #new-seq: 1, #new-token: 697, #cached-token: 130, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:17] Decode batch, #running-req: 1, #token: 829, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.75, #queue-req: 0, 
[2025-12-17 20:46:17] INFO:     127.0.0.1:53600 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:18] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:18] INFO:     127.0.0.1:53604 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:18] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 774, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:18] INFO:     127.0.0.1:53608 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:20] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:20] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.30, #queue-req: 0, 
[2025-12-17 20:46:20] INFO:     127.0.0.1:53612 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:20] Prefill batch, #new-seq: 1, #new-token: 902, #cached-token: 94, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:20] INFO:     127.0.0.1:53616 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:22] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:22] INFO:     127.0.0.1:53620 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:22] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 795, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:22] Decode batch, #running-req: 1, #token: 813, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.78, #queue-req: 0, 
[2025-12-17 20:46:22] INFO:     127.0.0.1:53624 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:24] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:24] INFO:     127.0.0.1:53628 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:24] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 1054, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:24] INFO:     127.0.0.1:53632 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:26] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:26] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.06, #queue-req: 0, 
[2025-12-17 20:46:26] INFO:     127.0.0.1:53636 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:26] Prefill batch, #new-seq: 1, #new-token: 1083, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:26] INFO:     127.0.0.1:53640 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:28] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:28] INFO:     127.0.0.1:53644 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:28] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 1054, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:28] Decode batch, #running-req: 1, #token: 1084, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.18, #queue-req: 0, 
[2025-12-17 20:46:28] INFO:     127.0.0.1:53648 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:30] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:30] INFO:     127.0.0.1:53652 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:30] Prefill batch, #new-seq: 1, #new-token: 933, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:30] Decode batch, #running-req: 1, #token: 973, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.22, #queue-req: 0, 
[2025-12-17 20:46:30] INFO:     127.0.0.1:53656 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:31] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:32] INFO:     127.0.0.1:53660 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:32] Prefill batch, #new-seq: 1, #new-token: 1220, #cached-token: 18, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:32] INFO:     127.0.0.1:53664 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:33] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:33] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.29, #queue-req: 0, 
[2025-12-17 20:46:33] INFO:     127.0.0.1:53668 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:33] Prefill batch, #new-seq: 1, #new-token: 1140, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:33] INFO:     127.0.0.1:53672 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:35] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:35] INFO:     127.0.0.1:53676 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:35] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 792, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:35] INFO:     127.0.0.1:53680 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:35] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.88, #queue-req: 0, 
[2025-12-17 20:46:37] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:37] INFO:     127.0.0.1:53684 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:37] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 1054, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:37] INFO:     127.0.0.1:53688 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:39] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:39] INFO:     127.0.0.1:53692 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:39] Prefill batch, #new-seq: 1, #new-token: 1263, #cached-token: 87, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:39] Decode batch, #running-req: 1, #token: 1360, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.19, #queue-req: 0, 
[2025-12-17 20:46:39] INFO:     127.0.0.1:53696 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:40] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:41] INFO:     127.0.0.1:53700 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:41] Prefill batch, #new-seq: 1, #new-token: 1259, #cached-token: 18, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:41] INFO:     127.0.0.1:53704 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:42] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:42] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.29, #queue-req: 0, 
[2025-12-17 20:46:42] INFO:     127.0.0.1:53708 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:42] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 690, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:43] INFO:     127.0.0.1:53712 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:44] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:44] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.07, #queue-req: 0, 
[2025-12-17 20:46:44] INFO:     127.0.0.1:54730 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:44] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 691, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:44] INFO:     127.0.0.1:54734 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:46] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:46] INFO:     127.0.0.1:54738 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:46] Prefill batch, #new-seq: 1, #new-token: 1446, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:46] Decode batch, #running-req: 1, #token: 1482, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.09, #queue-req: 0, 
[2025-12-17 20:46:46] INFO:     127.0.0.1:54742 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:48] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:48] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.87, #queue-req: 0, 
[2025-12-17 20:46:48] INFO:     127.0.0.1:54746 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:48] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 715, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:48] Decode batch, #running-req: 1, #token: 762, token usage: 0.00, cuda graph: True, gen throughput (token/s): 193.27, #queue-req: 0, 
[2025-12-17 20:46:48] INFO:     127.0.0.1:54750 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:50] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:50] INFO:     127.0.0.1:54756 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:50] Prefill batch, #new-seq: 1, #new-token: 1333, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:50] INFO:     127.0.0.1:54760 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:52] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:52] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.01, #queue-req: 0, 
[2025-12-17 20:46:52] INFO:     127.0.0.1:54764 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:52] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:52] INFO:     127.0.0.1:54768 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:54] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:54] INFO:     127.0.0.1:54772 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:54] Prefill batch, #new-seq: 1, #new-token: 1589, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:54] Decode batch, #running-req: 1, #token: 1631, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.06, #queue-req: 0, 
[2025-12-17 20:46:54] INFO:     127.0.0.1:54776 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:56] Prefill batch, #new-seq: 1, #new-token: 1, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:56] INFO:     127.0.0.1:54780 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:56] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:56] INFO:     127.0.0.1:54784 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:58] Prefill batch, #new-seq: 1, #new-token: 1, #cached-token: 68, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:58] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.30, #queue-req: 0, 
[2025-12-17 20:46:58] INFO:     127.0.0.1:54788 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:58] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 1055, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:58] INFO:     127.0.0.1:54792 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:59] Prefill batch, #new-seq: 1, #new-token: 1, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:59] INFO:     127.0.0.1:54796 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:46:59] Prefill batch, #new-seq: 1, #new-token: 1, #cached-token: 1056, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:46:59] Decode batch, #running-req: 1, #token: 1064, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.31, #queue-req: 0, 
[2025-12-17 20:46:59] INFO:     127.0.0.1:54800 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:01] Prefill batch, #new-seq: 1, #new-token: 1, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:01] INFO:     127.0.0.1:54804 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:01] Prefill batch, #new-seq: 1, #new-token: 1188, #cached-token: 89, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:01] Decode batch, #running-req: 1, #token: 1297, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.27, #queue-req: 0, 
[2025-12-17 20:47:01] Decode batch, #running-req: 1, #token: 1337, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 20:47:02] Decode batch, #running-req: 1, #token: 1377, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:47:02] Decode batch, #running-req: 1, #token: 1417, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.99, #queue-req: 0, 
[2025-12-17 20:47:02] Decode batch, #running-req: 1, #token: 1457, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.04, #queue-req: 0, 
[2025-12-17 20:47:02] Decode batch, #running-req: 1, #token: 1497, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.04, #queue-req: 0, 
[2025-12-17 20:47:02] Decode batch, #running-req: 1, #token: 1537, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.04, #queue-req: 0, 
[2025-12-17 20:47:03] Decode batch, #running-req: 1, #token: 1577, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:47:03] Decode batch, #running-req: 1, #token: 1617, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:47:03] Decode batch, #running-req: 1, #token: 1657, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:47:03] Decode batch, #running-req: 1, #token: 1697, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:47:03] Decode batch, #running-req: 1, #token: 1737, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:47:03] Decode batch, #running-req: 1, #token: 1777, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:47:04] Decode batch, #running-req: 1, #token: 1817, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:47:04] Decode batch, #running-req: 1, #token: 1857, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:47:04] Decode batch, #running-req: 1, #token: 1897, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 20:47:04] Decode batch, #running-req: 1, #token: 1937, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:47:04] Decode batch, #running-req: 1, #token: 1977, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:47:05] Decode batch, #running-req: 1, #token: 2017, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:47:05] Decode batch, #running-req: 1, #token: 2057, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.62, #queue-req: 0, 
[2025-12-17 20:47:05] Decode batch, #running-req: 1, #token: 2097, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.22, #queue-req: 0, 
[2025-12-17 20:47:05] Decode batch, #running-req: 1, #token: 2137, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.30, #queue-req: 0, 
[2025-12-17 20:47:05] Decode batch, #running-req: 1, #token: 2177, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.42, #queue-req: 0, 
[2025-12-17 20:47:05] Decode batch, #running-req: 1, #token: 2217, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.28, #queue-req: 0, 
[2025-12-17 20:47:06] Decode batch, #running-req: 1, #token: 2257, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.19, #queue-req: 0, 
[2025-12-17 20:47:06] INFO:     127.0.0.1:54808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:07] Prefill batch, #new-seq: 1, #new-token: 1, #cached-token: 70, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:07] INFO:     127.0.0.1:54812 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:07] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:08] Decode batch, #running-req: 1, #token: 795, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.47, #queue-req: 0, 
[2025-12-17 20:47:08] INFO:     127.0.0.1:54816 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:09] Prefill batch, #new-seq: 1, #new-token: 1, #cached-token: 66, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:09] INFO:     127.0.0.1:54820 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:09] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 715, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:09] INFO:     127.0.0.1:54824 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:12] Prefill batch, #new-seq: 1, #new-token: 1, #cached-token: 66, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:12] Decode batch, #running-req: 1, #token: 70, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.95, #queue-req: 0, 
[2025-12-17 20:47:12] INFO:     127.0.0.1:54828 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:12] Prefill batch, #new-seq: 1, #new-token: 1175, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:12] INFO:     127.0.0.1:54832 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:14] Prefill batch, #new-seq: 1, #new-token: 1, #cached-token: 73, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:14] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.48, #queue-req: 0, 
[2025-12-17 20:47:14] INFO:     127.0.0.1:54836 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:14] Prefill batch, #new-seq: 1, #new-token: 1290, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:14] INFO:     127.0.0.1:54840 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:16] Prefill batch, #new-seq: 1, #new-token: 1, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:16] INFO:     127.0.0.1:54844 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:16] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 1054, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:16] Decode batch, #running-req: 1, #token: 1075, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.94, #queue-req: 0, 
[2025-12-17 20:47:16] INFO:     127.0.0.1:54848 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:18] Prefill batch, #new-seq: 1, #new-token: 1, #cached-token: 71, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:18] INFO:     127.0.0.1:54852 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:18] Prefill batch, #new-seq: 1, #new-token: 1, #cached-token: 1069, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:18] INFO:     127.0.0.1:54856 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:19] Prefill batch, #new-seq: 1, #new-token: 1, #cached-token: 77, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:19] INFO:     127.0.0.1:54862 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:19] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.45, #queue-req: 0, 
[2025-12-17 20:47:19] Prefill batch, #new-seq: 1, #new-token: 1, #cached-token: 1075, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:20] INFO:     127.0.0.1:54866 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:21] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:21] INFO:     127.0.0.1:54874 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:21] Prefill batch, #new-seq: 1, #new-token: 24, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:21] INFO:     127.0.0.1:54878 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:21] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.04, #queue-req: 0, 
[2025-12-17 20:47:23] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:23] INFO:     127.0.0.1:54882 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:23] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 774, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:23] INFO:     127.0.0.1:54886 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:23] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.45, #queue-req: 0, 
[2025-12-17 20:47:25] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:25] INFO:     127.0.0.1:54892 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:25] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 776, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:25] INFO:     127.0.0.1:54896 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:27] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:27] INFO:     127.0.0.1:54900 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:27] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 1054, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:27] Decode batch, #running-req: 1, #token: 1070, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.13, #queue-req: 0, 
[2025-12-17 20:47:27] INFO:     127.0.0.1:54904 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:29] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:29] INFO:     127.0.0.1:54908 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:29] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:29] INFO:     127.0.0.1:54912 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:30] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:30] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.33, #queue-req: 0, 
[2025-12-17 20:47:30] INFO:     127.0.0.1:54918 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:30] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 691, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:30] INFO:     127.0.0.1:54922 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:32] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:32] INFO:     127.0.0.1:54926 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:32] Prefill batch, #new-seq: 1, #new-token: 1150, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:32] Decode batch, #running-req: 1, #token: 1185, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.19, #queue-req: 0, 
[2025-12-17 20:47:32] INFO:     127.0.0.1:54930 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:34] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:34] INFO:     127.0.0.1:54934 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:34] Prefill batch, #new-seq: 1, #new-token: 639, #cached-token: 54, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:34] INFO:     127.0.0.1:54938 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:36] Prefill batch, #new-seq: 1, #new-token: 60, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:36] Decode batch, #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.37, #queue-req: 0, 
[2025-12-17 20:47:36] INFO:     127.0.0.1:54942 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:36] Prefill batch, #new-seq: 1, #new-token: 26, #cached-token: 800, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:36] Decode batch, #running-req: 1, #token: 859, token usage: 0.00, cuda graph: True, gen throughput (token/s): 197.42, #queue-req: 0, 
[2025-12-17 20:47:36] INFO:     127.0.0.1:54946 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:38] Prefill batch, #new-seq: 1, #new-token: 60, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:38] INFO:     127.0.0.1:54952 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:38] Prefill batch, #new-seq: 1, #new-token: 639, #cached-token: 100, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:38] Decode batch, #running-req: 1, #token: 741, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.37, #queue-req: 0, 
[2025-12-17 20:47:38] INFO:     127.0.0.1:54956 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:40] Prefill batch, #new-seq: 1, #new-token: 65, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:40] Decode batch, #running-req: 1, #token: 110, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.46, #queue-req: 0, 
[2025-12-17 20:47:40] INFO:     127.0.0.1:54960 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:40] Prefill batch, #new-seq: 1, #new-token: 1020, #cached-token: 308, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:40] INFO:     127.0.0.1:54964 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:42] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:42] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.95, #queue-req: 0, 
[2025-12-17 20:47:42] INFO:     127.0.0.1:54968 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:42] Prefill batch, #new-seq: 1, #new-token: 24, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:42] Decode batch, #running-req: 1, #token: 827, token usage: 0.00, cuda graph: True, gen throughput (token/s): 196.80, #queue-req: 0, 
[2025-12-17 20:47:42] INFO:     127.0.0.1:54972 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:44] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:44] INFO:     127.0.0.1:54976 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:44] Prefill batch, #new-seq: 1, #new-token: 1179, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:44] INFO:     127.0.0.1:54982 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:46] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:46] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.22, #queue-req: 0, 
[2025-12-17 20:47:46] INFO:     127.0.0.1:54986 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:46] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 690, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:46] Decode batch, #running-req: 1, #token: 735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 198.54, #queue-req: 0, 
[2025-12-17 20:47:46] INFO:     127.0.0.1:54990 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:48] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:48] INFO:     127.0.0.1:54996 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:48] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 690, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:48] INFO:     127.0.0.1:55000 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:50] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:50] Decode batch, #running-req: 1, #token: 89, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.98, #queue-req: 0, 
[2025-12-17 20:47:50] INFO:     127.0.0.1:55004 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:50] Prefill batch, #new-seq: 1, #new-token: 21, #cached-token: 776, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:50] INFO:     127.0.0.1:55008 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:52] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:52] INFO:     127.0.0.1:55012 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:52] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 690, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:52] Decode batch, #running-req: 1, #token: 721, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.46, #queue-req: 0, 
[2025-12-17 20:47:52] INFO:     127.0.0.1:55016 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:53] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:54] INFO:     127.0.0.1:55022 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:54] Prefill batch, #new-seq: 1, #new-token: 988, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:54] Decode batch, #running-req: 1, #token: 1009, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.31, #queue-req: 0, 
[2025-12-17 20:47:54] INFO:     127.0.0.1:55026 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:55] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:55] INFO:     127.0.0.1:55030 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:55] Prefill batch, #new-seq: 1, #new-token: 1249, #cached-token: 17, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:55] INFO:     127.0.0.1:55034 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:58] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:58] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.76, #queue-req: 0, 
[2025-12-17 20:47:58] INFO:     127.0.0.1:55038 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:47:58] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 716, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:47:58] INFO:     127.0.0.1:55042 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:00] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:00] Decode batch, #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.34, #queue-req: 0, 
[2025-12-17 20:48:00] INFO:     127.0.0.1:55046 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:00] Prefill batch, #new-seq: 1, #new-token: 1158, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:00] INFO:     127.0.0.1:55050 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:01] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:01] INFO:     127.0.0.1:55054 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:01] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.27, #queue-req: 0, 
[2025-12-17 20:48:01] Prefill batch, #new-seq: 1, #new-token: 25, #cached-token: 1055, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:02] INFO:     127.0.0.1:55058 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:03] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:03] INFO:     127.0.0.1:55062 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:03] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 1149, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:03] Decode batch, #running-req: 1, #token: 1175, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.57, #queue-req: 0, 
[2025-12-17 20:48:04] Decode batch, #running-req: 1, #token: 1215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 20:48:04] Decode batch, #running-req: 1, #token: 1255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:48:04] Decode batch, #running-req: 1, #token: 1295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 20:48:04] Decode batch, #running-req: 1, #token: 1335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 20:48:04] Decode batch, #running-req: 1, #token: 1375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.62, #queue-req: 0, 
[2025-12-17 20:48:04] Decode batch, #running-req: 1, #token: 1415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.49, #queue-req: 0, 
[2025-12-17 20:48:05] Decode batch, #running-req: 1, #token: 1455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.55, #queue-req: 0, 
[2025-12-17 20:48:05] Decode batch, #running-req: 1, #token: 1495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.62, #queue-req: 0, 
[2025-12-17 20:48:05] Decode batch, #running-req: 1, #token: 1535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:48:05] Decode batch, #running-req: 1, #token: 1575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.25, #queue-req: 0, 
[2025-12-17 20:48:05] Decode batch, #running-req: 1, #token: 1615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 20:48:06] Decode batch, #running-req: 1, #token: 1655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.28, #queue-req: 0, 
[2025-12-17 20:48:06] Decode batch, #running-req: 1, #token: 1695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.29, #queue-req: 0, 
[2025-12-17 20:48:06] Decode batch, #running-req: 1, #token: 1735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.27, #queue-req: 0, 
[2025-12-17 20:48:06] Decode batch, #running-req: 1, #token: 1775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.25, #queue-req: 0, 
[2025-12-17 20:48:06] Decode batch, #running-req: 1, #token: 1815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.23, #queue-req: 0, 
[2025-12-17 20:48:06] Decode batch, #running-req: 1, #token: 1855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.21, #queue-req: 0, 
[2025-12-17 20:48:07] Decode batch, #running-req: 1, #token: 1895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.27, #queue-req: 0, 
[2025-12-17 20:48:07] Decode batch, #running-req: 1, #token: 1935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.17, #queue-req: 0, 
[2025-12-17 20:48:07] Decode batch, #running-req: 1, #token: 1975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.37, #queue-req: 0, 
[2025-12-17 20:48:07] Decode batch, #running-req: 1, #token: 2015, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.37, #queue-req: 0, 
[2025-12-17 20:48:07] Decode batch, #running-req: 1, #token: 2055, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.21, #queue-req: 0, 
[2025-12-17 20:48:08] Decode batch, #running-req: 1, #token: 2095, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.89, #queue-req: 0, 
[2025-12-17 20:48:08] Decode batch, #running-req: 1, #token: 2135, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.80, #queue-req: 0, 
[2025-12-17 20:48:08] INFO:     127.0.0.1:55066 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:10] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:10] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.75, #queue-req: 0, 
[2025-12-17 20:48:10] INFO:     127.0.0.1:55072 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:10] Prefill batch, #new-seq: 1, #new-token: 1255, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:10] Decode batch, #running-req: 1, #token: 1310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 168.34, #queue-req: 0, 
[2025-12-17 20:48:10] INFO:     127.0.0.1:55076 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:12] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:12] Decode batch, #running-req: 1, #token: 112, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.69, #queue-req: 0, 
[2025-12-17 20:48:12] INFO:     127.0.0.1:55080 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:12] Prefill batch, #new-seq: 1, #new-token: 1011, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:12] Decode batch, #running-req: 1, #token: 1054, token usage: 0.00, cuda graph: True, gen throughput (token/s): 194.43, #queue-req: 0, 
[2025-12-17 20:48:12] INFO:     127.0.0.1:55084 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:14] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:14] INFO:     127.0.0.1:55088 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:14] Prefill batch, #new-seq: 1, #new-token: 1118, #cached-token: 112, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:14] Decode batch, #running-req: 1, #token: 1253, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.27, #queue-req: 0, 
[2025-12-17 20:48:14] Decode batch, #running-req: 1, #token: 1293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 20:48:14] Decode batch, #running-req: 1, #token: 1333, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 20:48:15] Decode batch, #running-req: 1, #token: 1373, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.49, #queue-req: 0, 
[2025-12-17 20:48:15] Decode batch, #running-req: 1, #token: 1413, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:48:15] Decode batch, #running-req: 1, #token: 1453, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:48:15] Decode batch, #running-req: 1, #token: 1493, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.63, #queue-req: 0, 
[2025-12-17 20:48:15] Decode batch, #running-req: 1, #token: 1533, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:48:16] Decode batch, #running-req: 1, #token: 1573, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.42, #queue-req: 0, 
[2025-12-17 20:48:16] Decode batch, #running-req: 1, #token: 1613, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:48:16] Decode batch, #running-req: 1, #token: 1653, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 20:48:16] Decode batch, #running-req: 1, #token: 1693, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:48:16] Decode batch, #running-req: 1, #token: 1733, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 20:48:16] Decode batch, #running-req: 1, #token: 1773, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.45, #queue-req: 0, 
[2025-12-17 20:48:17] Decode batch, #running-req: 1, #token: 1813, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.35, #queue-req: 0, 
[2025-12-17 20:48:17] Decode batch, #running-req: 1, #token: 1853, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.39, #queue-req: 0, 
[2025-12-17 20:48:17] Decode batch, #running-req: 1, #token: 1893, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.27, #queue-req: 0, 
[2025-12-17 20:48:17] Decode batch, #running-req: 1, #token: 1933, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.43, #queue-req: 0, 
[2025-12-17 20:48:17] Decode batch, #running-req: 1, #token: 1973, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 20:48:18] Decode batch, #running-req: 1, #token: 2013, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 20:48:18] Decode batch, #running-req: 1, #token: 2053, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.42, #queue-req: 0, 
[2025-12-17 20:48:18] Decode batch, #running-req: 1, #token: 2093, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.06, #queue-req: 0, 
[2025-12-17 20:48:18] Decode batch, #running-req: 1, #token: 2133, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.03, #queue-req: 0, 
[2025-12-17 20:48:18] Decode batch, #running-req: 1, #token: 2173, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.03, #queue-req: 0, 
[2025-12-17 20:48:18] Decode batch, #running-req: 1, #token: 2213, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.17, #queue-req: 0, 
[2025-12-17 20:48:18] INFO:     127.0.0.1:55092 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:20] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:20] INFO:     127.0.0.1:55098 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:20] Prefill batch, #new-seq: 1, #new-token: 1251, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:20] INFO:     127.0.0.1:55102 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:22] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:22] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.25, #queue-req: 0, 
[2025-12-17 20:48:22] INFO:     127.0.0.1:55106 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:22] Prefill batch, #new-seq: 1, #new-token: 23, #cached-token: 690, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:22] INFO:     127.0.0.1:55110 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:24] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:24] INFO:     127.0.0.1:55114 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:24] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:24] Decode batch, #running-req: 1, #token: 797, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.12, #queue-req: 0, 
[2025-12-17 20:48:24] INFO:     127.0.0.1:55118 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:26] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:26] INFO:     127.0.0.1:55126 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:26] Prefill batch, #new-seq: 1, #new-token: 23, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:26] Decode batch, #running-req: 1, #token: 810, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.65, #queue-req: 0, 
[2025-12-17 20:48:26] INFO:     127.0.0.1:55130 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:28] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:28] INFO:     127.0.0.1:55134 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:28] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 1055, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:28] INFO:     127.0.0.1:55138 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:30] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:30] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.17, #queue-req: 0, 
[2025-12-17 20:48:30] INFO:     127.0.0.1:55142 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:30] Prefill batch, #new-seq: 1, #new-token: 1029, #cached-token: 300, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:30] Decode batch, #running-req: 1, #token: 1360, token usage: 0.00, cuda graph: True, gen throughput (token/s): 189.93, #queue-req: 0, 
[2025-12-17 20:48:30] INFO:     127.0.0.1:55146 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:31] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:32] INFO:     127.0.0.1:55150 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:32] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 691, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:32] INFO:     127.0.0.1:55154 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:33] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:33] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.27, #queue-req: 0, 
[2025-12-17 20:48:33] INFO:     127.0.0.1:55158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:33] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 716, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:34] Decode batch, #running-req: 1, #token: 765, token usage: 0.00, cuda graph: True, gen throughput (token/s): 197.88, #queue-req: 0, 
[2025-12-17 20:48:34] Decode batch, #running-req: 1, #token: 805, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.69, #queue-req: 0, 
[2025-12-17 20:48:34] Decode batch, #running-req: 1, #token: 845, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.46, #queue-req: 0, 
[2025-12-17 20:48:34] Decode batch, #running-req: 1, #token: 885, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.51, #queue-req: 0, 
[2025-12-17 20:48:34] Decode batch, #running-req: 1, #token: 925, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.68, #queue-req: 0, 
[2025-12-17 20:48:34] Decode batch, #running-req: 1, #token: 965, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.57, #queue-req: 0, 
[2025-12-17 20:48:35] Decode batch, #running-req: 1, #token: 1005, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.60, #queue-req: 0, 
[2025-12-17 20:48:35] Decode batch, #running-req: 1, #token: 1045, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.34, #queue-req: 0, 
[2025-12-17 20:48:35] Decode batch, #running-req: 1, #token: 1085, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:48:35] Decode batch, #running-req: 1, #token: 1125, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 20:48:35] Decode batch, #running-req: 1, #token: 1165, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:48:36] Decode batch, #running-req: 1, #token: 1205, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 20:48:36] Decode batch, #running-req: 1, #token: 1245, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:48:36] Decode batch, #running-req: 1, #token: 1285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.92, #queue-req: 0, 
[2025-12-17 20:48:36] Decode batch, #running-req: 1, #token: 1325, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:48:36] Decode batch, #running-req: 1, #token: 1365, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:48:36] Decode batch, #running-req: 1, #token: 1405, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 20:48:37] Decode batch, #running-req: 1, #token: 1445, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 20:48:37] Decode batch, #running-req: 1, #token: 1485, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.94, #queue-req: 0, 
[2025-12-17 20:48:37] Decode batch, #running-req: 1, #token: 1525, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.88, #queue-req: 0, 
[2025-12-17 20:48:37] Decode batch, #running-req: 1, #token: 1565, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:48:37] Decode batch, #running-req: 1, #token: 1605, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:48:38] Decode batch, #running-req: 1, #token: 1645, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:48:38] Decode batch, #running-req: 1, #token: 1685, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:48:38] Decode batch, #running-req: 1, #token: 1725, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:48:38] INFO:     127.0.0.1:55162 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:40] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:40] INFO:     127.0.0.1:55166 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:40] Prefill batch, #new-seq: 1, #new-token: 1094, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:40] INFO:     127.0.0.1:55170 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:40] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.13, #queue-req: 0, 
[2025-12-17 20:48:41] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:42] INFO:     127.0.0.1:55176 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:42] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 716, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:42] INFO:     127.0.0.1:55180 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:43] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:43] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.08, #queue-req: 0, 
[2025-12-17 20:48:43] INFO:     127.0.0.1:55184 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:43] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:44] INFO:     127.0.0.1:55188 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:45] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:45] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.43, #queue-req: 0, 
[2025-12-17 20:48:45] INFO:     127.0.0.1:55192 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:45] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 716, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:45] INFO:     127.0.0.1:55196 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:47] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:47] INFO:     127.0.0.1:55200 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:47] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 1214, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:47] Decode batch, #running-req: 1, #token: 1237, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.63, #queue-req: 0, 
[2025-12-17 20:48:47] INFO:     127.0.0.1:55204 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:49] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:49] INFO:     127.0.0.1:55208 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:49] Prefill batch, #new-seq: 1, #new-token: 1319, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:49] Decode batch, #running-req: 1, #token: 1359, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.81, #queue-req: 0, 
[2025-12-17 20:48:49] INFO:     127.0.0.1:55212 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:51] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:51] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.61, #queue-req: 0, 
[2025-12-17 20:48:51] INFO:     127.0.0.1:55216 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:51] Prefill batch, #new-seq: 1, #new-token: 1185, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:51] INFO:     127.0.0.1:55220 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:53] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:53] INFO:     127.0.0.1:55224 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:53] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 1055, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:53] INFO:     127.0.0.1:55228 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:55] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:55] Decode batch, #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.52, #queue-req: 0, 
[2025-12-17 20:48:55] INFO:     127.0.0.1:55232 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:55] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 779, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:55] Decode batch, #running-req: 1, #token: 832, token usage: 0.00, cuda graph: True, gen throughput (token/s): 186.05, #queue-req: 0, 
[2025-12-17 20:48:55] INFO:     127.0.0.1:55236 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:57] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:57] Decode batch, #running-req: 1, #token: 92, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.08, #queue-req: 0, 
[2025-12-17 20:48:57] INFO:     127.0.0.1:55240 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:48:57] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 715, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:48:57] Decode batch, #running-req: 1, #token: 774, token usage: 0.00, cuda graph: True, gen throughput (token/s): 196.63, #queue-req: 0, 
[2025-12-17 20:48:57] Decode batch, #running-req: 1, #token: 814, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.46, #queue-req: 0, 
[2025-12-17 20:48:57] Decode batch, #running-req: 1, #token: 854, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.44, #queue-req: 0, 
[2025-12-17 20:48:58] Decode batch, #running-req: 1, #token: 894, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.30, #queue-req: 0, 
[2025-12-17 20:48:58] Decode batch, #running-req: 1, #token: 934, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.53, #queue-req: 0, 
[2025-12-17 20:48:58] Decode batch, #running-req: 1, #token: 974, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.56, #queue-req: 0, 
[2025-12-17 20:48:58] Decode batch, #running-req: 1, #token: 1014, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.47, #queue-req: 0, 
[2025-12-17 20:48:58] Decode batch, #running-req: 1, #token: 1054, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.03, #queue-req: 0, 
[2025-12-17 20:48:59] Decode batch, #running-req: 1, #token: 1094, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.98, #queue-req: 0, 
[2025-12-17 20:48:59] Decode batch, #running-req: 1, #token: 1134, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.98, #queue-req: 0, 
[2025-12-17 20:48:59] Decode batch, #running-req: 1, #token: 1174, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 20:48:59] Decode batch, #running-req: 1, #token: 1214, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:48:59] Decode batch, #running-req: 1, #token: 1254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.01, #queue-req: 0, 
[2025-12-17 20:48:59] Decode batch, #running-req: 1, #token: 1294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:49:00] Decode batch, #running-req: 1, #token: 1334, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:49:00] Decode batch, #running-req: 1, #token: 1374, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:49:00] Decode batch, #running-req: 1, #token: 1414, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 20:49:00] Decode batch, #running-req: 1, #token: 1454, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:49:00] Decode batch, #running-req: 1, #token: 1494, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.96, #queue-req: 0, 
[2025-12-17 20:49:01] Decode batch, #running-req: 1, #token: 1534, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:49:01] Decode batch, #running-req: 1, #token: 1574, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:49:01] Decode batch, #running-req: 1, #token: 1614, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:49:01] Decode batch, #running-req: 1, #token: 1654, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:49:01] Decode batch, #running-req: 1, #token: 1694, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.69, #queue-req: 0, 
[2025-12-17 20:49:01] Decode batch, #running-req: 1, #token: 1734, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:49:01] INFO:     127.0.0.1:55244 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:03] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:03] INFO:     127.0.0.1:55252 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:03] Prefill batch, #new-seq: 1, #new-token: 1103, #cached-token: 240, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:03] INFO:     127.0.0.1:55256 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:05] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:05] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.27, #queue-req: 0, 
[2025-12-17 20:49:05] INFO:     127.0.0.1:55260 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:05] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 716, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:05] INFO:     127.0.0.1:55264 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:07] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:07] INFO:     127.0.0.1:55268 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:07] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 1055, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:07] Decode batch, #running-req: 1, #token: 1075, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.11, #queue-req: 0, 
[2025-12-17 20:49:07] INFO:     127.0.0.1:55272 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:09] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:09] INFO:     127.0.0.1:55278 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:09] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:09] INFO:     127.0.0.1:55282 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:10] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:10] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.23, #queue-req: 0, 
[2025-12-17 20:49:10] INFO:     127.0.0.1:55286 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:11] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:11] INFO:     127.0.0.1:55290 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:12] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:12] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.93, #queue-req: 0, 
[2025-12-17 20:49:12] INFO:     127.0.0.1:55294 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:12] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:12] INFO:     127.0.0.1:55298 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:14] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:14] INFO:     127.0.0.1:55302 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:14] Prefill batch, #new-seq: 1, #new-token: 21, #cached-token: 800, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:14] Decode batch, #running-req: 1, #token: 834, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.09, #queue-req: 0, 
[2025-12-17 20:49:14] INFO:     127.0.0.1:55306 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:16] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:16] INFO:     127.0.0.1:55310 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:16] Prefill batch, #new-seq: 1, #new-token: 786, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:16] INFO:     127.0.0.1:55314 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:18] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:18] INFO:     127.0.0.1:55318 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:18] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:18] Decode batch, #running-req: 1, #token: 798, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.28, #queue-req: 0, 
[2025-12-17 20:49:18] INFO:     127.0.0.1:55322 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:20] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:20] INFO:     127.0.0.1:55328 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:20] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 716, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:20] Decode batch, #running-req: 1, #token: 745, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.56, #queue-req: 0, 
[2025-12-17 20:49:20] INFO:     127.0.0.1:55332 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:21] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:22] INFO:     127.0.0.1:55336 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:22] Prefill batch, #new-seq: 1, #new-token: 23, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:22] Decode batch, #running-req: 1, #token: 803, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.18, #queue-req: 0, 
[2025-12-17 20:49:22] INFO:     127.0.0.1:55340 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:23] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:23] INFO:     127.0.0.1:55344 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:23] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:23] Decode batch, #running-req: 1, #token: 797, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.38, #queue-req: 0, 
[2025-12-17 20:49:24] INFO:     127.0.0.1:55348 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:25] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:25] INFO:     127.0.0.1:55352 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:25] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 691, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:25] Decode batch, #running-req: 1, #token: 715, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.44, #queue-req: 0, 
[2025-12-17 20:49:25] Decode batch, #running-req: 1, #token: 755, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.36, #queue-req: 0, 
[2025-12-17 20:49:26] Decode batch, #running-req: 1, #token: 795, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.21, #queue-req: 0, 
[2025-12-17 20:49:26] Decode batch, #running-req: 1, #token: 835, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.29, #queue-req: 0, 
[2025-12-17 20:49:26] Decode batch, #running-req: 1, #token: 875, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.26, #queue-req: 0, 
[2025-12-17 20:49:26] Decode batch, #running-req: 1, #token: 915, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.26, #queue-req: 0, 
[2025-12-17 20:49:26] Decode batch, #running-req: 1, #token: 955, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.44, #queue-req: 0, 
[2025-12-17 20:49:27] Decode batch, #running-req: 1, #token: 995, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.23, #queue-req: 0, 
[2025-12-17 20:49:27] Decode batch, #running-req: 1, #token: 1035, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.21, #queue-req: 0, 
[2025-12-17 20:49:27] Decode batch, #running-req: 1, #token: 1075, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 20:49:27] Decode batch, #running-req: 1, #token: 1115, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:49:27] Decode batch, #running-req: 1, #token: 1155, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:49:27] Decode batch, #running-req: 1, #token: 1195, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:49:28] Decode batch, #running-req: 1, #token: 1235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 20:49:28] Decode batch, #running-req: 1, #token: 1275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.55, #queue-req: 0, 
[2025-12-17 20:49:28] Decode batch, #running-req: 1, #token: 1315, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.36, #queue-req: 0, 
[2025-12-17 20:49:28] Decode batch, #running-req: 1, #token: 1355, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.43, #queue-req: 0, 
[2025-12-17 20:49:28] Decode batch, #running-req: 1, #token: 1395, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 20:49:29] Decode batch, #running-req: 1, #token: 1435, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 20:49:29] Decode batch, #running-req: 1, #token: 1475, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:49:29] Decode batch, #running-req: 1, #token: 1515, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:49:29] Decode batch, #running-req: 1, #token: 1555, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 20:49:29] Decode batch, #running-req: 1, #token: 1595, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.31, #queue-req: 0, 
[2025-12-17 20:49:29] Decode batch, #running-req: 1, #token: 1635, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 20:49:30] Decode batch, #running-req: 1, #token: 1675, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 20:49:30] INFO:     127.0.0.1:55356 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:32] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:32] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.82, #queue-req: 0, 
[2025-12-17 20:49:32] INFO:     127.0.0.1:55364 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:32] Prefill batch, #new-seq: 1, #new-token: 800, #cached-token: 105, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:32] INFO:     127.0.0.1:55368 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:34] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:34] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.98, #queue-req: 0, 
[2025-12-17 20:49:34] INFO:     127.0.0.1:55372 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:34] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 1153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:34] INFO:     127.0.0.1:55376 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:36] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:36] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.53, #queue-req: 0, 
[2025-12-17 20:49:36] INFO:     127.0.0.1:55382 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:36] Prefill batch, #new-seq: 1, #new-token: 1197, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:36] INFO:     127.0.0.1:55386 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:37] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:37] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.26, #queue-req: 0, 
[2025-12-17 20:49:38] INFO:     127.0.0.1:55390 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:38] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:38] INFO:     127.0.0.1:55394 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:39] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:39] INFO:     127.0.0.1:55398 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:39] Prefill batch, #new-seq: 1, #new-token: 26, #cached-token: 717, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:39] Decode batch, #running-req: 1, #token: 748, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.22, #queue-req: 0, 
[2025-12-17 20:49:39] INFO:     127.0.0.1:55402 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:41] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:41] INFO:     127.0.0.1:55410 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:41] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:41] INFO:     127.0.0.1:55414 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:43] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:43] INFO:     127.0.0.1:55420 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:43] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.99, #queue-req: 0, 
[2025-12-17 20:49:43] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 1054, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:43] INFO:     127.0.0.1:55424 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:45] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:45] INFO:     127.0.0.1:55428 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:45] Prefill batch, #new-seq: 1, #new-token: 1116, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:45] INFO:     127.0.0.1:55432 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:47] Prefill batch, #new-seq: 1, #new-token: 66, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:47] Decode batch, #running-req: 1, #token: 101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.88, #queue-req: 0, 
[2025-12-17 20:49:47] INFO:     127.0.0.1:55436 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:47] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 777, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:47] Decode batch, #running-req: 1, #token: 845, token usage: 0.00, cuda graph: True, gen throughput (token/s): 196.02, #queue-req: 0, 
[2025-12-17 20:49:47] INFO:     127.0.0.1:55440 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:49] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:49] INFO:     127.0.0.1:55444 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:49] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 777, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:49] Decode batch, #running-req: 1, #token: 811, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.49, #queue-req: 0, 
[2025-12-17 20:49:49] Decode batch, #running-req: 1, #token: 851, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.57, #queue-req: 0, 
[2025-12-17 20:49:49] Decode batch, #running-req: 1, #token: 891, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.40, #queue-req: 0, 
[2025-12-17 20:49:49] Decode batch, #running-req: 1, #token: 931, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.56, #queue-req: 0, 
[2025-12-17 20:49:50] Decode batch, #running-req: 1, #token: 971, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.59, #queue-req: 0, 
[2025-12-17 20:49:50] Decode batch, #running-req: 1, #token: 1011, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.60, #queue-req: 0, 
[2025-12-17 20:49:50] Decode batch, #running-req: 1, #token: 1051, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.10, #queue-req: 0, 
[2025-12-17 20:49:50] Decode batch, #running-req: 1, #token: 1091, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.92, #queue-req: 0, 
[2025-12-17 20:49:50] Decode batch, #running-req: 1, #token: 1131, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:49:50] Decode batch, #running-req: 1, #token: 1171, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:49:51] Decode batch, #running-req: 1, #token: 1211, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:49:51] Decode batch, #running-req: 1, #token: 1251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:49:51] Decode batch, #running-req: 1, #token: 1291, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:49:51] Decode batch, #running-req: 1, #token: 1331, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.02, #queue-req: 0, 
[2025-12-17 20:49:51] Decode batch, #running-req: 1, #token: 1371, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:49:52] Decode batch, #running-req: 1, #token: 1411, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:49:52] Decode batch, #running-req: 1, #token: 1451, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:49:52] Decode batch, #running-req: 1, #token: 1491, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:49:52] Decode batch, #running-req: 1, #token: 1531, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.01, #queue-req: 0, 
[2025-12-17 20:49:52] Decode batch, #running-req: 1, #token: 1571, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.79, #queue-req: 0, 
[2025-12-17 20:49:52] Decode batch, #running-req: 1, #token: 1611, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:49:53] Decode batch, #running-req: 1, #token: 1651, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 20:49:53] Decode batch, #running-req: 1, #token: 1691, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 20:49:53] Decode batch, #running-req: 1, #token: 1731, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:49:53] Decode batch, #running-req: 1, #token: 1771, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:49:53] INFO:     127.0.0.1:55448 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:55] Prefill batch, #new-seq: 1, #new-token: 62, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:55] INFO:     127.0.0.1:55452 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:55] Prefill batch, #new-seq: 1, #new-token: 29, #cached-token: 691, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:55] Decode batch, #running-req: 1, #token: 726, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.69, #queue-req: 0, 
[2025-12-17 20:49:55] INFO:     127.0.0.1:55456 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:57] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:57] INFO:     127.0.0.1:55460 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:57] Prefill batch, #new-seq: 1, #new-token: 1041, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:57] INFO:     127.0.0.1:55464 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:59] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:59] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.08, #queue-req: 0, 
[2025-12-17 20:49:59] INFO:     127.0.0.1:55468 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:49:59] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 1055, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:49:59] INFO:     127.0.0.1:55472 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:01] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:01] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.31, #queue-req: 0, 
[2025-12-17 20:50:01] INFO:     127.0.0.1:55476 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:01] Prefill batch, #new-seq: 1, #new-token: 1128, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:01] INFO:     127.0.0.1:55480 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:03] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:03] INFO:     127.0.0.1:55484 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:03] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 776, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:03] INFO:     127.0.0.1:55488 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:04] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:04] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.34, #queue-req: 0, 
[2025-12-17 20:50:05] INFO:     127.0.0.1:55492 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:05] Prefill batch, #new-seq: 1, #new-token: 26, #cached-token: 776, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:05] INFO:     127.0.0.1:55496 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:06] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:06] INFO:     127.0.0.1:55500 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:06] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 775, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:06] Decode batch, #running-req: 1, #token: 801, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.43, #queue-req: 0, 
[2025-12-17 20:50:07] INFO:     127.0.0.1:55504 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:08] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:08] INFO:     127.0.0.1:55508 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:08] Prefill batch, #new-seq: 1, #new-token: 27, #cached-token: 716, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:08] Decode batch, #running-req: 1, #token: 748, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.81, #queue-req: 0, 
[2025-12-17 20:50:08] INFO:     127.0.0.1:55512 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:10] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:10] Decode batch, #running-req: 1, #token: 97, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.35, #queue-req: 0, 
[2025-12-17 20:50:10] INFO:     127.0.0.1:55520 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:10] Prefill batch, #new-seq: 1, #new-token: 1259, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:10] INFO:     127.0.0.1:55524 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:12] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:12] INFO:     127.0.0.1:55528 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:12] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 777, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:12] Decode batch, #running-req: 1, #token: 803, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.15, #queue-req: 0, 
[2025-12-17 20:50:12] INFO:     127.0.0.1:55532 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:14] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:14] INFO:     127.0.0.1:55538 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:14] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 716, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:14] Decode batch, #running-req: 1, #token: 744, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.76, #queue-req: 0, 
[2025-12-17 20:50:14] INFO:     127.0.0.1:55542 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:16] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:16] INFO:     127.0.0.1:55546 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:16] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 714, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:16] Decode batch, #running-req: 1, #token: 739, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.31, #queue-req: 0, 
[2025-12-17 20:50:16] INFO:     127.0.0.1:55550 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:18] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:18] INFO:     127.0.0.1:55560 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:18] Prefill batch, #new-seq: 1, #new-token: 1025, #cached-token: 86, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:18] Decode batch, #running-req: 1, #token: 1118, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.00, #queue-req: 0, 
[2025-12-17 20:50:18] INFO:     127.0.0.1:55564 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:20] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:20] INFO:     127.0.0.1:55568 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:20] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 776, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:20] INFO:     127.0.0.1:55572 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:22] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:22] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.17, #queue-req: 0, 
[2025-12-17 20:50:22] INFO:     127.0.0.1:55576 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:22] Prefill batch, #new-seq: 1, #new-token: 964, #cached-token: 189, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:22] INFO:     127.0.0.1:55580 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:24] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:24] INFO:     127.0.0.1:55584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:24] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 692, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:24] Decode batch, #running-req: 1, #token: 718, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.91, #queue-req: 0, 
[2025-12-17 20:50:24] INFO:     127.0.0.1:55588 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:26] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:26] INFO:     127.0.0.1:55592 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:26] Prefill batch, #new-seq: 1, #new-token: 8, #cached-token: 780, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:26] INFO:     127.0.0.1:55596 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:27] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:28] INFO:     127.0.0.1:55602 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:28] Prefill batch, #new-seq: 1, #new-token: 27, #cached-token: 691, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:28] Decode batch, #running-req: 1, #token: 721, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.22, #queue-req: 0, 
[2025-12-17 20:50:28] INFO:     127.0.0.1:55606 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:29] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:29] INFO:     127.0.0.1:55610 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:29] Prefill batch, #new-seq: 1, #new-token: 1073, #cached-token: 16, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:29] Decode batch, #running-req: 1, #token: 1098, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.23, #queue-req: 0, 
[2025-12-17 20:50:29] INFO:     127.0.0.1:55614 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:31] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:31] INFO:     127.0.0.1:55618 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:31] Prefill batch, #new-seq: 1, #new-token: 1107, #cached-token: 16, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:31] INFO:     127.0.0.1:55622 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:33] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:33] INFO:     127.0.0.1:55626 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:33] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 1057, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:33] Decode batch, #running-req: 1, #token: 1077, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.14, #queue-req: 0, 
[2025-12-17 20:50:33] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.12, #queue-req: 0, 
[2025-12-17 20:50:33] INFO:     127.0.0.1:55630 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:35] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:35] INFO:     127.0.0.1:55634 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:35] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 691, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:35] INFO:     127.0.0.1:55638 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:37] Prefill batch, #new-seq: 1, #new-token: 60, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:37] Decode batch, #running-req: 1, #token: 94, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.20, #queue-req: 0, 
[2025-12-17 20:50:37] INFO:     127.0.0.1:55642 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:37] Prefill batch, #new-seq: 1, #new-token: 27, #cached-token: 691, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:37] INFO:     127.0.0.1:55646 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:39] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:39] INFO:     127.0.0.1:55650 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:39] Prefill batch, #new-seq: 1, #new-token: 1349, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:39] Decode batch, #running-req: 1, #token: 1392, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.02, #queue-req: 0, 
[2025-12-17 20:50:39] INFO:     127.0.0.1:55654 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:40] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:40] INFO:     127.0.0.1:55658 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:40] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 753, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:41] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.14, #queue-req: 0, 
[2025-12-17 20:50:41] INFO:     127.0.0.1:55662 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:43] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:43] Decode batch, #running-req: 1, #token: 107, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.56, #queue-req: 0, 
[2025-12-17 20:50:43] Decode batch, #running-req: 1, #token: 147, token usage: 0.00, cuda graph: True, gen throughput (token/s): 224.40, #queue-req: 0, 
[2025-12-17 20:50:43] Decode batch, #running-req: 1, #token: 187, token usage: 0.00, cuda graph: True, gen throughput (token/s): 226.22, #queue-req: 0, 
[2025-12-17 20:50:43] Decode batch, #running-req: 1, #token: 227, token usage: 0.00, cuda graph: True, gen throughput (token/s): 226.15, #queue-req: 0, 
[2025-12-17 20:50:43] Decode batch, #running-req: 1, #token: 267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 225.64, #queue-req: 0, 
[2025-12-17 20:50:44] Decode batch, #running-req: 1, #token: 307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 223.43, #queue-req: 0, 
[2025-12-17 20:50:44] Decode batch, #running-req: 1, #token: 347, token usage: 0.00, cuda graph: True, gen throughput (token/s): 223.09, #queue-req: 0, 
[2025-12-17 20:50:44] Decode batch, #running-req: 1, #token: 387, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.55, #queue-req: 0, 
[2025-12-17 20:50:44] Decode batch, #running-req: 1, #token: 427, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.86, #queue-req: 0, 
[2025-12-17 20:50:44] Decode batch, #running-req: 1, #token: 467, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.91, #queue-req: 0, 
[2025-12-17 20:50:45] Decode batch, #running-req: 1, #token: 507, token usage: 0.00, cuda graph: True, gen throughput (token/s): 222.04, #queue-req: 0, 
[2025-12-17 20:50:45] Decode batch, #running-req: 1, #token: 547, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.56, #queue-req: 0, 
[2025-12-17 20:50:45] Decode batch, #running-req: 1, #token: 587, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.59, #queue-req: 0, 
[2025-12-17 20:50:45] Decode batch, #running-req: 1, #token: 627, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.58, #queue-req: 0, 
[2025-12-17 20:50:45] Decode batch, #running-req: 1, #token: 667, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.44, #queue-req: 0, 
[2025-12-17 20:50:45] Decode batch, #running-req: 1, #token: 707, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.59, #queue-req: 0, 
[2025-12-17 20:50:46] Decode batch, #running-req: 1, #token: 747, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.53, #queue-req: 0, 
[2025-12-17 20:50:46] Decode batch, #running-req: 1, #token: 787, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.46, #queue-req: 0, 
[2025-12-17 20:50:46] Decode batch, #running-req: 1, #token: 827, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.42, #queue-req: 0, 
[2025-12-17 20:50:46] Decode batch, #running-req: 1, #token: 867, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.39, #queue-req: 0, 
[2025-12-17 20:50:46] Decode batch, #running-req: 1, #token: 907, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.58, #queue-req: 0, 
[2025-12-17 20:50:46] Decode batch, #running-req: 1, #token: 947, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.61, #queue-req: 0, 
[2025-12-17 20:50:47] Decode batch, #running-req: 1, #token: 987, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.44, #queue-req: 0, 
[2025-12-17 20:50:47] Decode batch, #running-req: 1, #token: 1027, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.46, #queue-req: 0, 
[2025-12-17 20:50:47] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:50:47] INFO:     127.0.0.1:55666 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:47] Prefill batch, #new-seq: 1, #new-token: 934, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:47] INFO:     127.0.0.1:55670 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:49] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:49] INFO:     127.0.0.1:55674 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:49] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 753, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:49] Decode batch, #running-req: 1, #token: 798, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.03, #queue-req: 0, 
[2025-12-17 20:50:49] INFO:     127.0.0.1:55678 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:51] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:51] INFO:     127.0.0.1:55682 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:51] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 753, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:51] INFO:     127.0.0.1:55686 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:52] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:53] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.17, #queue-req: 0, 
[2025-12-17 20:50:53] INFO:     127.0.0.1:55690 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:53] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 1033, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:53] INFO:     127.0.0.1:55694 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:55] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:55] INFO:     127.0.0.1:55698 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:55] Prefill batch, #new-seq: 1, #new-token: 1181, #cached-token: 118, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:55] INFO:     127.0.0.1:55702 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:57] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:57] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.81, #queue-req: 0, 
[2025-12-17 20:50:57] INFO:     127.0.0.1:55706 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:57] Prefill batch, #new-seq: 1, #new-token: 1061, #cached-token: 88, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:57] INFO:     127.0.0.1:55712 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:58] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:58] INFO:     127.0.0.1:55718 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:50:59] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.95, #queue-req: 0, 
[2025-12-17 20:50:59] Prefill batch, #new-seq: 1, #new-token: 1130, #cached-token: 88, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:50:59] INFO:     127.0.0.1:55722 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:00] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:00] INFO:     127.0.0.1:55734 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:00] Prefill batch, #new-seq: 1, #new-token: 1235, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:00] Decode batch, #running-req: 1, #token: 1279, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.45, #queue-req: 0, 
[2025-12-17 20:51:01] INFO:     127.0.0.1:55738 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:02] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:02] INFO:     127.0.0.1:55750 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:02] Prefill batch, #new-seq: 1, #new-token: 1329, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:02] Decode batch, #running-req: 1, #token: 1372, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.47, #queue-req: 0, 
[2025-12-17 20:51:02] INFO:     127.0.0.1:55756 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:04] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:04] INFO:     127.0.0.1:55774 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:04] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 669, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:04] Decode batch, #running-req: 1, #token: 720, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.44, #queue-req: 0, 
[2025-12-17 20:51:04] INFO:     127.0.0.1:55778 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:06] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:06] INFO:     127.0.0.1:55786 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:06] Prefill batch, #new-seq: 1, #new-token: 1250, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:06] INFO:     127.0.0.1:55790 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:08] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:08] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.81, #queue-req: 0, 
[2025-12-17 20:51:08] INFO:     127.0.0.1:55796 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:08] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 1033, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:08] INFO:     127.0.0.1:55800 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:10] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:10] INFO:     127.0.0.1:55848 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:10] Prefill batch, #new-seq: 1, #new-token: 1403, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:10] Decode batch, #running-req: 1, #token: 1419, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.99, #queue-req: 0, 
[2025-12-17 20:51:10] INFO:     127.0.0.1:55860 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:12] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:12] INFO:     127.0.0.1:56040 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:12] Prefill batch, #new-seq: 1, #new-token: 1220, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:12] Decode batch, #running-req: 1, #token: 1255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.55, #queue-req: 0, 
[2025-12-17 20:51:12] INFO:     127.0.0.1:56052 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:14] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:14] INFO:     127.0.0.1:56224 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:14] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 669, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:14] INFO:     127.0.0.1:56242 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:16] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:16] Decode batch, #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.85, #queue-req: 0, 
[2025-12-17 20:51:16] INFO:     127.0.0.1:59264 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:16] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 753, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:16] INFO:     127.0.0.1:59304 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:18] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:18] Decode batch, #running-req: 1, #token: 97, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.74, #queue-req: 0, 
[2025-12-17 20:51:18] INFO:     127.0.0.1:59650 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:18] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 694, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:18] INFO:     127.0.0.1:59662 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:19] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:20] INFO:     127.0.0.1:59828 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:20] Prefill batch, #new-seq: 1, #new-token: 1239, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:20] Decode batch, #running-req: 1, #token: 1262, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.95, #queue-req: 0, 
[2025-12-17 20:51:20] INFO:     127.0.0.1:59840 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:21] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:21] INFO:     127.0.0.1:60036 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:21] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 754, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:22] INFO:     127.0.0.1:60046 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:23] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:23] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.94, #queue-req: 0, 
[2025-12-17 20:51:23] INFO:     127.0.0.1:60094 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:23] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 694, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:23] INFO:     127.0.0.1:60104 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:25] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:25] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.82, #queue-req: 0, 
[2025-12-17 20:51:25] INFO:     127.0.0.1:60242 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:25] Prefill batch, #new-seq: 1, #new-token: 31, #cached-token: 671, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:25] INFO:     127.0.0.1:60250 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:27] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:27] INFO:     127.0.0.1:60312 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:27] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 1033, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:27] Decode batch, #running-req: 1, #token: 1086, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.30, #queue-req: 0, 
[2025-12-17 20:51:27] INFO:     127.0.0.1:60320 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:29] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:29] INFO:     127.0.0.1:60372 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:30] Prefill batch, #new-seq: 1, #new-token: 1311, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:30] Decode batch, #running-req: 1, #token: 1363, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.41, #queue-req: 0, 
[2025-12-17 20:51:30] INFO:     127.0.0.1:60380 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:31] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:31] INFO:     127.0.0.1:60476 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:31] Prefill batch, #new-seq: 1, #new-token: 1284, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:32] INFO:     127.0.0.1:60488 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:33] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:33] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.93, #queue-req: 0, 
[2025-12-17 20:51:33] INFO:     127.0.0.1:60564 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:33] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 754, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:33] INFO:     127.0.0.1:60568 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:35] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:35] INFO:     127.0.0.1:60578 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:35] Prefill batch, #new-seq: 1, #new-token: 1077, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:35] Decode batch, #running-req: 1, #token: 1101, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.91, #queue-req: 0, 
[2025-12-17 20:51:35] INFO:     127.0.0.1:60584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:37] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:37] INFO:     127.0.0.1:60604 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:37] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 754, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:37] INFO:     127.0.0.1:60612 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:39] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:39] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.90, #queue-req: 0, 
[2025-12-17 20:51:39] INFO:     127.0.0.1:60662 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:39] Prefill batch, #new-seq: 1, #new-token: 1247, #cached-token: 37, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:39] INFO:     127.0.0.1:60668 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:41] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:41] INFO:     127.0.0.1:60746 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:41] Prefill batch, #new-seq: 1, #new-token: 1242, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:41] Decode batch, #running-req: 1, #token: 1278, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.20, #queue-req: 0, 
[2025-12-17 20:51:41] INFO:     127.0.0.1:60752 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:43] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:43] INFO:     127.0.0.1:60828 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:43] Prefill batch, #new-seq: 1, #new-token: 1286, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:43] Decode batch, #running-req: 1, #token: 1329, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.61, #queue-req: 0, 
[2025-12-17 20:51:43] INFO:     127.0.0.1:60832 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:45] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:45] INFO:     127.0.0.1:60876 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:45] Prefill batch, #new-seq: 1, #new-token: 1000, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:45] Decode batch, #running-req: 1, #token: 1038, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.81, #queue-req: 0, 
[2025-12-17 20:51:45] INFO:     127.0.0.1:60880 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:47] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:47] INFO:     127.0.0.1:60890 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:47] Prefill batch, #new-seq: 1, #new-token: 1311, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:47] INFO:     127.0.0.1:60894 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:48] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:48] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.86, #queue-req: 0, 
[2025-12-17 20:51:48] INFO:     127.0.0.1:60900 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:49] Prefill batch, #new-seq: 1, #new-token: 1269, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:49] INFO:     127.0.0.1:60904 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:50] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:50] INFO:     127.0.0.1:60910 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:50] Prefill batch, #new-seq: 1, #new-token: 1188, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:51] Decode batch, #running-req: 1, #token: 1237, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.74, #queue-req: 0, 
[2025-12-17 20:51:51] INFO:     127.0.0.1:60916 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:52] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:52] INFO:     127.0.0.1:60934 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:52] Prefill batch, #new-seq: 1, #new-token: 934, #cached-token: 271, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:52] INFO:     127.0.0.1:60938 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:54] Prefill batch, #new-seq: 1, #new-token: 64, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:54] INFO:     127.0.0.1:60952 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:54] Prefill batch, #new-seq: 1, #new-token: 723, #cached-token: 54, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:54] Decode batch, #running-req: 1, #token: 783, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.83, #queue-req: 0, 
[2025-12-17 20:51:54] INFO:     127.0.0.1:60958 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:56] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:56] INFO:     127.0.0.1:32782 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:56] Prefill batch, #new-seq: 1, #new-token: 1289, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:56] Decode batch, #running-req: 1, #token: 1331, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.64, #queue-req: 0, 
[2025-12-17 20:51:56] INFO:     127.0.0.1:32794 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:58] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:58] INFO:     127.0.0.1:32860 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:51:58] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 754, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:51:58] Decode batch, #running-req: 1, #token: 802, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.70, #queue-req: 0, 
[2025-12-17 20:51:58] Decode batch, #running-req: 1, #token: 842, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.30, #queue-req: 0, 
[2025-12-17 20:51:58] Decode batch, #running-req: 1, #token: 882, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.25, #queue-req: 0, 
[2025-12-17 20:51:59] Decode batch, #running-req: 1, #token: 922, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.29, #queue-req: 0, 
[2025-12-17 20:51:59] Decode batch, #running-req: 1, #token: 962, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.37, #queue-req: 0, 
[2025-12-17 20:51:59] Decode batch, #running-req: 1, #token: 1002, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.41, #queue-req: 0, 
[2025-12-17 20:51:59] Decode batch, #running-req: 1, #token: 1042, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:51:59] Decode batch, #running-req: 1, #token: 1082, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.84, #queue-req: 0, 
[2025-12-17 20:52:00] Decode batch, #running-req: 1, #token: 1122, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:52:00] Decode batch, #running-req: 1, #token: 1162, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:52:00] Decode batch, #running-req: 1, #token: 1202, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:52:00] Decode batch, #running-req: 1, #token: 1242, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 20:52:00] Decode batch, #running-req: 1, #token: 1282, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:52:00] Decode batch, #running-req: 1, #token: 1322, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.53, #queue-req: 0, 
[2025-12-17 20:52:01] Decode batch, #running-req: 1, #token: 1362, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.63, #queue-req: 0, 
[2025-12-17 20:52:01] Decode batch, #running-req: 1, #token: 1402, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 20:52:01] Decode batch, #running-req: 1, #token: 1442, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.73, #queue-req: 0, 
[2025-12-17 20:52:01] Decode batch, #running-req: 1, #token: 1482, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 20:52:01] Decode batch, #running-req: 1, #token: 1522, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 20:52:02] Decode batch, #running-req: 1, #token: 1562, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:52:02] Decode batch, #running-req: 1, #token: 1602, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 20:52:02] Decode batch, #running-req: 1, #token: 1642, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.40, #queue-req: 0, 
[2025-12-17 20:52:02] Decode batch, #running-req: 1, #token: 1682, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.53, #queue-req: 0, 
[2025-12-17 20:52:02] Decode batch, #running-req: 1, #token: 1722, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 20:52:02] Decode batch, #running-req: 1, #token: 1762, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.32, #queue-req: 0, 
[2025-12-17 20:52:03] INFO:     127.0.0.1:32870 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:04] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:04] Decode batch, #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.87, #queue-req: 0, 
[2025-12-17 20:52:04] INFO:     127.0.0.1:32976 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:04] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 754, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:04] INFO:     127.0.0.1:32980 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:06] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:06] INFO:     127.0.0.1:32986 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:06] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 670, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:06] Decode batch, #running-req: 1, #token: 720, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.37, #queue-req: 0, 
[2025-12-17 20:52:06] INFO:     127.0.0.1:32990 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:08] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:08] INFO:     127.0.0.1:32994 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:08] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 756, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:08] INFO:     127.0.0.1:32998 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:10] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:10] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.94, #queue-req: 0, 
[2025-12-17 20:52:10] INFO:     127.0.0.1:33002 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:10] Prefill batch, #new-seq: 1, #new-token: 929, #cached-token: 299, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:10] INFO:     127.0.0.1:33006 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:12] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:12] INFO:     127.0.0.1:33012 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:12] Prefill batch, #new-seq: 1, #new-token: 28, #cached-token: 755, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:12] Decode batch, #running-req: 1, #token: 786, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.32, #queue-req: 0, 
[2025-12-17 20:52:12] INFO:     127.0.0.1:33016 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:14] Prefill batch, #new-seq: 1, #new-token: 61, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:14] INFO:     127.0.0.1:33022 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:14] Prefill batch, #new-seq: 1, #new-token: 1161, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:14] INFO:     127.0.0.1:33026 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:16] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:16] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.88, #queue-req: 0, 
[2025-12-17 20:52:16] INFO:     127.0.0.1:33036 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:16] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 754, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:16] INFO:     127.0.0.1:33040 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:17] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:18] INFO:     127.0.0.1:33058 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:18] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.63, #queue-req: 0, 
[2025-12-17 20:52:18] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 754, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:18] INFO:     127.0.0.1:33066 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:19] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:19] INFO:     127.0.0.1:33086 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:19] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 694, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:20] Decode batch, #running-req: 1, #token: 753, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.94, #queue-req: 0, 
[2025-12-17 20:52:20] INFO:     127.0.0.1:33090 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:26] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:26] INFO:     127.0.0.1:33226 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:26] Prefill batch, #new-seq: 1, #new-token: 1106, #cached-token: 16, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:26] INFO:     127.0.0.1:33234 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:28] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:28] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 4.74, #queue-req: 0, 
[2025-12-17 20:52:28] INFO:     127.0.0.1:33274 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:28] Prefill batch, #new-seq: 1, #new-token: 872, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:28] INFO:     127.0.0.1:33278 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:30] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:30] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.71, #queue-req: 0, 
[2025-12-17 20:52:30] INFO:     127.0.0.1:33308 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:30] Prefill batch, #new-seq: 1, #new-token: 1217, #cached-token: 16, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:30] INFO:     127.0.0.1:33314 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:32] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:32] INFO:     127.0.0.1:33332 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:32] Prefill batch, #new-seq: 1, #new-token: 1147, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:32] Decode batch, #running-req: 1, #token: 1190, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.25, #queue-req: 0, 
[2025-12-17 20:52:32] INFO:     127.0.0.1:33336 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:34] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:34] INFO:     127.0.0.1:33348 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:34] Prefill batch, #new-seq: 1, #new-token: 893, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:34] INFO:     127.0.0.1:33352 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:35] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:36] Decode batch, #running-req: 1, #token: 88, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.90, #queue-req: 0, 
[2025-12-17 20:52:36] INFO:     127.0.0.1:33358 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:36] Prefill batch, #new-seq: 1, #new-token: 1095, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:36] INFO:     127.0.0.1:33362 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:37] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:37] INFO:     127.0.0.1:33366 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:37] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 871, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:37] INFO:     127.0.0.1:33370 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:39] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:39] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.84, #queue-req: 0, 
[2025-12-17 20:52:39] INFO:     127.0.0.1:33374 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:39] Prefill batch, #new-seq: 1, #new-token: 1313, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:39] INFO:     127.0.0.1:33378 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:42] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:42] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.56, #queue-req: 0, 
[2025-12-17 20:52:42] INFO:     127.0.0.1:33382 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:42] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:42] INFO:     127.0.0.1:33386 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:44] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:44] INFO:     127.0.0.1:33390 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:44] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 889, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:44] Decode batch, #running-req: 1, #token: 910, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.77, #queue-req: 0, 
[2025-12-17 20:52:44] INFO:     127.0.0.1:33394 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:45] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:46] INFO:     127.0.0.1:33398 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:46] Prefill batch, #new-seq: 1, #new-token: 1227, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:46] INFO:     127.0.0.1:33402 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:47] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:47] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.91, #queue-req: 0, 
[2025-12-17 20:52:47] INFO:     127.0.0.1:33406 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:47] Prefill batch, #new-seq: 1, #new-token: 1223, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:48] Decode batch, #running-req: 1, #token: 1263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 168.24, #queue-req: 0, 
[2025-12-17 20:52:48] INFO:     127.0.0.1:33410 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:49] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:49] INFO:     127.0.0.1:33414 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:49] Prefill batch, #new-seq: 1, #new-token: 960, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:50] Decode batch, #running-req: 1, #token: 986, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.74, #queue-req: 0, 
[2025-12-17 20:52:50] INFO:     127.0.0.1:33418 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:51] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:51] INFO:     127.0.0.1:33422 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:51] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 892, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:51] INFO:     127.0.0.1:33426 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:53] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:53] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.84, #queue-req: 0, 
[2025-12-17 20:52:53] INFO:     127.0.0.1:33434 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:53] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:53] INFO:     127.0.0.1:33438 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:55] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:55] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.18, #queue-req: 0, 
[2025-12-17 20:52:55] INFO:     127.0.0.1:33444 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:55] Prefill batch, #new-seq: 1, #new-token: 683, #cached-token: 199, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:55] INFO:     127.0.0.1:33448 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:57] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:57] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.21, #queue-req: 0, 
[2025-12-17 20:52:57] INFO:     127.0.0.1:33466 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:57] Prefill batch, #new-seq: 1, #new-token: 906, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:57] INFO:     127.0.0.1:33470 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:59] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:59] INFO:     127.0.0.1:33476 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:52:59] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 891, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:52:59] Decode batch, #running-req: 1, #token: 910, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.03, #queue-req: 0, 
[2025-12-17 20:52:59] INFO:     127.0.0.1:33480 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:01] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:01] INFO:     127.0.0.1:33484 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:01] Prefill batch, #new-seq: 1, #new-token: 1414, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:01] Decode batch, #running-req: 1, #token: 1451, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.80, #queue-req: 0, 
[2025-12-17 20:53:01] INFO:     127.0.0.1:33488 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:03] Prefill batch, #new-seq: 1, #new-token: 63, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:03] INFO:     127.0.0.1:33492 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:03] Prefill batch, #new-seq: 1, #new-token: 1293, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:03] Decode batch, #running-req: 1, #token: 1324, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.94, #queue-req: 0, 
[2025-12-17 20:53:03] INFO:     127.0.0.1:33496 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:05] Prefill batch, #new-seq: 1, #new-token: 65, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:05] Decode batch, #running-req: 1, #token: 107, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.72, #queue-req: 0, 
[2025-12-17 20:53:05] INFO:     127.0.0.1:33500 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:05] Prefill batch, #new-seq: 1, #new-token: 1469, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:05] INFO:     127.0.0.1:33504 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:07] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:07] INFO:     127.0.0.1:33514 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:07] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:07] INFO:     127.0.0.1:33518 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:09] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:09] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.07, #queue-req: 0, 
[2025-12-17 20:53:09] INFO:     127.0.0.1:33522 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:09] Prefill batch, #new-seq: 1, #new-token: 778, #cached-token: 201, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:09] INFO:     127.0.0.1:33526 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:10] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:11] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.30, #queue-req: 0, 
[2025-12-17 20:53:11] INFO:     127.0.0.1:33530 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:11] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 892, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:11] INFO:     127.0.0.1:33534 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:12] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:12] INFO:     127.0.0.1:33538 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:12] Prefill batch, #new-seq: 1, #new-token: 834, #cached-token: 152, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:12] INFO:     127.0.0.1:33542 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:14] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:14] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.06, #queue-req: 0, 
[2025-12-17 20:53:14] INFO:     127.0.0.1:33546 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:14] Prefill batch, #new-seq: 1, #new-token: 535, #cached-token: 367, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:14] INFO:     127.0.0.1:33550 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:16] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:16] INFO:     127.0.0.1:33556 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:16] Prefill batch, #new-seq: 1, #new-token: 1321, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:16] Decode batch, #running-req: 1, #token: 1353, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.98, #queue-req: 0, 
[2025-12-17 20:53:16] INFO:     127.0.0.1:33560 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:18] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:18] INFO:     127.0.0.1:33564 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:18] Prefill batch, #new-seq: 1, #new-token: 1312, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:18] Decode batch, #running-req: 1, #token: 1329, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.25, #queue-req: 0, 
[2025-12-17 20:53:18] INFO:     127.0.0.1:33568 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:20] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:20] INFO:     127.0.0.1:33572 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:20] Prefill batch, #new-seq: 1, #new-token: 1366, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:20] Decode batch, #running-req: 1, #token: 1397, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.39, #queue-req: 0, 
[2025-12-17 20:53:20] INFO:     127.0.0.1:33576 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:21] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:22] INFO:     127.0.0.1:33580 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:22] Prefill batch, #new-seq: 1, #new-token: 1073, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:22] Decode batch, #running-req: 1, #token: 1114, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.38, #queue-req: 0, 
[2025-12-17 20:53:22] INFO:     127.0.0.1:33584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:23] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:24] INFO:     127.0.0.1:33588 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:24] Prefill batch, #new-seq: 1, #new-token: 1161, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:24] Decode batch, #running-req: 1, #token: 1182, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.71, #queue-req: 0, 
[2025-12-17 20:53:24] INFO:     127.0.0.1:33592 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:25] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:25] INFO:     127.0.0.1:33596 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:25] Prefill batch, #new-seq: 1, #new-token: 1252, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:25] Decode batch, #running-req: 1, #token: 1290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.00, #queue-req: 0, 
[2025-12-17 20:53:26] Decode batch, #running-req: 1, #token: 1330, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.74, #queue-req: 0, 
[2025-12-17 20:53:26] INFO:     127.0.0.1:33600 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:27] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:28] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.85, #queue-req: 0, 
[2025-12-17 20:53:28] INFO:     127.0.0.1:33604 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:28] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 869, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:28] INFO:     127.0.0.1:33608 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:29] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:29] INFO:     127.0.0.1:33616 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:29] Prefill batch, #new-seq: 1, #new-token: 1239, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:30] Decode batch, #running-req: 1, #token: 1290, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.33, #queue-req: 0, 
[2025-12-17 20:53:30] INFO:     127.0.0.1:33620 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:32] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:32] INFO:     127.0.0.1:33624 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:32] Prefill batch, #new-seq: 1, #new-token: 808, #cached-token: 150, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:32] Decode batch, #running-req: 1, #token: 980, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.30, #queue-req: 0, 
[2025-12-17 20:53:32] Decode batch, #running-req: 1, #token: 1020, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.43, #queue-req: 0, 
[2025-12-17 20:53:32] Decode batch, #running-req: 1, #token: 1060, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.07, #queue-req: 0, 
[2025-12-17 20:53:33] Decode batch, #running-req: 1, #token: 1100, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.36, #queue-req: 0, 
[2025-12-17 20:53:33] Decode batch, #running-req: 1, #token: 1140, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:53:33] Decode batch, #running-req: 1, #token: 1180, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.94, #queue-req: 0, 
[2025-12-17 20:53:33] Decode batch, #running-req: 1, #token: 1220, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:53:33] Decode batch, #running-req: 1, #token: 1260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.85, #queue-req: 0, 
[2025-12-17 20:53:33] Decode batch, #running-req: 1, #token: 1300, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 20:53:34] Decode batch, #running-req: 1, #token: 1340, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:53:34] Decode batch, #running-req: 1, #token: 1380, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:53:34] Decode batch, #running-req: 1, #token: 1420, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:53:34] Decode batch, #running-req: 1, #token: 1460, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.98, #queue-req: 0, 
[2025-12-17 20:53:34] Decode batch, #running-req: 1, #token: 1500, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 20:53:35] Decode batch, #running-req: 1, #token: 1540, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:53:35] Decode batch, #running-req: 1, #token: 1580, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 20:53:35] Decode batch, #running-req: 1, #token: 1620, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:53:35] Decode batch, #running-req: 1, #token: 1660, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 20:53:35] Decode batch, #running-req: 1, #token: 1700, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 20:53:35] Decode batch, #running-req: 1, #token: 1740, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 20:53:36] Decode batch, #running-req: 1, #token: 1780, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 20:53:36] Decode batch, #running-req: 1, #token: 1820, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:53:36] Decode batch, #running-req: 1, #token: 1860, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.42, #queue-req: 0, 
[2025-12-17 20:53:36] Decode batch, #running-req: 1, #token: 1900, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.33, #queue-req: 0, 
[2025-12-17 20:53:36] Decode batch, #running-req: 1, #token: 1940, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:53:36] INFO:     127.0.0.1:33628 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:38] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:38] INFO:     127.0.0.1:33636 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:38] Prefill batch, #new-seq: 1, #new-token: 1270, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:38] Decode batch, #running-req: 1, #token: 1293, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.45, #queue-req: 0, 
[2025-12-17 20:53:38] INFO:     127.0.0.1:33640 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:40] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:40] INFO:     127.0.0.1:33644 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:40] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 946, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:40] INFO:     127.0.0.1:33648 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:42] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:42] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.16, #queue-req: 0, 
[2025-12-17 20:53:42] INFO:     127.0.0.1:33652 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:42] Prefill batch, #new-seq: 1, #new-token: 1346, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:42] Decode batch, #running-req: 1, #token: 1371, token usage: 0.00, cuda graph: True, gen throughput (token/s): 189.48, #queue-req: 0, 
[2025-12-17 20:53:42] INFO:     127.0.0.1:33656 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:44] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:44] INFO:     127.0.0.1:33660 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:44] Prefill batch, #new-seq: 1, #new-token: 1289, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:44] Decode batch, #running-req: 1, #token: 1328, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.36, #queue-req: 0, 
[2025-12-17 20:53:44] INFO:     127.0.0.1:33664 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:46] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:46] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 21.32, #queue-req: 0, 
[2025-12-17 20:53:46] INFO:     127.0.0.1:33668 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:46] Prefill batch, #new-seq: 1, #new-token: 928, #cached-token: 96, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:46] INFO:     127.0.0.1:33672 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:48] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:48] INFO:     127.0.0.1:33678 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:48] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 963, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:48] Decode batch, #running-req: 1, #token: 988, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.57, #queue-req: 0, 
[2025-12-17 20:53:48] INFO:     127.0.0.1:33682 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:50] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:50] INFO:     127.0.0.1:33686 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:50] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 963, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:50] INFO:     127.0.0.1:33690 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:50] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.63, #queue-req: 0, 
[2025-12-17 20:53:52] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:52] INFO:     127.0.0.1:33694 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:52] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 868, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:52] Decode batch, #running-req: 1, #token: 903, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.65, #queue-req: 0, 
[2025-12-17 20:53:52] Decode batch, #running-req: 1, #token: 943, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.40, #queue-req: 0, 
[2025-12-17 20:53:52] Decode batch, #running-req: 1, #token: 983, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.51, #queue-req: 0, 
[2025-12-17 20:53:53] Decode batch, #running-req: 1, #token: 1023, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.44, #queue-req: 0, 
[2025-12-17 20:53:53] Decode batch, #running-req: 1, #token: 1063, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.02, #queue-req: 0, 
[2025-12-17 20:53:53] Decode batch, #running-req: 1, #token: 1103, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.09, #queue-req: 0, 
[2025-12-17 20:53:53] Decode batch, #running-req: 1, #token: 1143, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 20:53:53] Decode batch, #running-req: 1, #token: 1183, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.90, #queue-req: 0, 
[2025-12-17 20:53:54] Decode batch, #running-req: 1, #token: 1223, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:53:54] Decode batch, #running-req: 1, #token: 1263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:53:54] Decode batch, #running-req: 1, #token: 1303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.80, #queue-req: 0, 
[2025-12-17 20:53:54] Decode batch, #running-req: 1, #token: 1343, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.94, #queue-req: 0, 
[2025-12-17 20:53:54] Decode batch, #running-req: 1, #token: 1383, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 20:53:54] Decode batch, #running-req: 1, #token: 1423, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:53:55] Decode batch, #running-req: 1, #token: 1463, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.06, #queue-req: 0, 
[2025-12-17 20:53:55] Decode batch, #running-req: 1, #token: 1503, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:53:55] Decode batch, #running-req: 1, #token: 1543, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:53:55] Decode batch, #running-req: 1, #token: 1583, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:53:55] Decode batch, #running-req: 1, #token: 1623, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.64, #queue-req: 0, 
[2025-12-17 20:53:56] Decode batch, #running-req: 1, #token: 1663, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 20:53:56] Decode batch, #running-req: 1, #token: 1703, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 20:53:56] Decode batch, #running-req: 1, #token: 1743, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 20:53:56] Decode batch, #running-req: 1, #token: 1783, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.37, #queue-req: 0, 
[2025-12-17 20:53:56] Decode batch, #running-req: 1, #token: 1823, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:53:56] Decode batch, #running-req: 1, #token: 1863, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:53:57] INFO:     127.0.0.1:33698 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:58] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:58] INFO:     127.0.0.1:33702 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:53:58] Prefill batch, #new-seq: 1, #new-token: 1134, #cached-token: 94, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:53:58] Decode batch, #running-req: 1, #token: 1232, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.57, #queue-req: 0, 
[2025-12-17 20:53:59] INFO:     127.0.0.1:33706 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:00] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:00] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.92, #queue-req: 0, 
[2025-12-17 20:54:00] INFO:     127.0.0.1:33714 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:00] Prefill batch, #new-seq: 1, #new-token: 1067, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:00] INFO:     127.0.0.1:33718 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:02] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:02] INFO:     127.0.0.1:33722 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:03] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 890, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:03] Decode batch, #running-req: 1, #token: 918, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.78, #queue-req: 0, 
[2025-12-17 20:54:03] INFO:     127.0.0.1:33726 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:04] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:04] INFO:     127.0.0.1:33730 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:04] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 845, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:05] Decode batch, #running-req: 1, #token: 912, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.09, #queue-req: 0, 
[2025-12-17 20:54:05] INFO:     127.0.0.1:33734 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:06] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:06] INFO:     127.0.0.1:33738 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:06] Prefill batch, #new-seq: 1, #new-token: 1168, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:07] Decode batch, #running-req: 1, #token: 1196, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.35, #queue-req: 0, 
[2025-12-17 20:54:07] INFO:     127.0.0.1:33742 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:08] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:08] INFO:     127.0.0.1:33746 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:08] Prefill batch, #new-seq: 1, #new-token: 1432, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:08] Decode batch, #running-req: 1, #token: 1460, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.44, #queue-req: 0, 
[2025-12-17 20:54:09] INFO:     127.0.0.1:33750 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:11] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:11] INFO:     127.0.0.1:33754 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:11] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 871, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:11] INFO:     127.0.0.1:33758 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:13] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:13] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.68, #queue-req: 0, 
[2025-12-17 20:54:13] INFO:     127.0.0.1:33762 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:13] Prefill batch, #new-seq: 1, #new-token: 1206, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:13] INFO:     127.0.0.1:33768 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:14] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:15] INFO:     127.0.0.1:33772 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:15] Prefill batch, #new-seq: 1, #new-token: 1403, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:15] Decode batch, #running-req: 1, #token: 1446, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.19, #queue-req: 0, 
[2025-12-17 20:54:15] INFO:     127.0.0.1:33776 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:17] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:17] Decode batch, #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.19, #queue-req: 0, 
[2025-12-17 20:54:17] INFO:     127.0.0.1:33780 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:17] Prefill batch, #new-seq: 1, #new-token: 1159, #cached-token: 18, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:17] INFO:     127.0.0.1:33784 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:18] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:18] INFO:     127.0.0.1:33788 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:18] Prefill batch, #new-seq: 1, #new-token: 1026, #cached-token: 18, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:19] Decode batch, #running-req: 1, #token: 1052, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.29, #queue-req: 0, 
[2025-12-17 20:54:19] INFO:     127.0.0.1:33792 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:20] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:20] INFO:     127.0.0.1:33798 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:20] Prefill batch, #new-seq: 1, #new-token: 1403, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:21] Decode batch, #running-req: 1, #token: 1421, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.19, #queue-req: 0, 
[2025-12-17 20:54:21] INFO:     127.0.0.1:33802 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:22] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:22] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.93, #queue-req: 0, 
[2025-12-17 20:54:22] INFO:     127.0.0.1:33806 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:22] Prefill batch, #new-seq: 1, #new-token: 1249, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:23] INFO:     127.0.0.1:33810 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:24] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:24] INFO:     127.0.0.1:33814 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:24] Prefill batch, #new-seq: 1, #new-token: 1087, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:24] Decode batch, #running-req: 1, #token: 1127, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.30, #queue-req: 0, 
[2025-12-17 20:54:24] INFO:     127.0.0.1:33818 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:26] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:26] INFO:     127.0.0.1:33822 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:26] Prefill batch, #new-seq: 1, #new-token: 609, #cached-token: 294, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:26] INFO:     127.0.0.1:33826 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:28] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:28] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.97, #queue-req: 0, 
[2025-12-17 20:54:28] INFO:     127.0.0.1:33830 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:28] Prefill batch, #new-seq: 1, #new-token: 1362, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:28] INFO:     127.0.0.1:33834 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:30] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:30] INFO:     127.0.0.1:33838 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:30] Prefill batch, #new-seq: 1, #new-token: 1206, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:30] Decode batch, #running-req: 1, #token: 1246, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.30, #queue-req: 0, 
[2025-12-17 20:54:30] INFO:     127.0.0.1:33842 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:32] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:32] INFO:     127.0.0.1:33848 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:32] Prefill batch, #new-seq: 1, #new-token: 1169, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:32] INFO:     127.0.0.1:33852 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:34] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:34] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.96, #queue-req: 0, 
[2025-12-17 20:54:35] INFO:     127.0.0.1:33856 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:35] Prefill batch, #new-seq: 1, #new-token: 64, #cached-token: 1252, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:35] INFO:     127.0.0.1:33860 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:37] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:37] INFO:     127.0.0.1:33866 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:37] Prefill batch, #new-seq: 1, #new-token: 915, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:37] Decode batch, #running-req: 1, #token: 954, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.55, #queue-req: 0, 
[2025-12-17 20:54:37] INFO:     127.0.0.1:33870 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:39] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:39] INFO:     127.0.0.1:33874 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:39] Prefill batch, #new-seq: 1, #new-token: 1071, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:39] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.99, #queue-req: 0, 
[2025-12-17 20:54:39] INFO:     127.0.0.1:33878 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:41] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:41] INFO:     127.0.0.1:33882 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:41] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 871, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:41] INFO:     127.0.0.1:33886 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:43] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:43] INFO:     127.0.0.1:33890 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:43] Prefill batch, #new-seq: 1, #new-token: 1348, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:43] Decode batch, #running-req: 1, #token: 1384, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.62, #queue-req: 0, 
[2025-12-17 20:54:43] INFO:     127.0.0.1:33894 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:45] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:45] INFO:     127.0.0.1:33898 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:45] Prefill batch, #new-seq: 1, #new-token: 1130, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:45] Decode batch, #running-req: 1, #token: 1172, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.03, #queue-req: 0, 
[2025-12-17 20:54:45] INFO:     127.0.0.1:33902 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:47] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:47] INFO:     127.0.0.1:33906 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:47] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 886, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:48] INFO:     127.0.0.1:33910 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:50] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:50] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.11, #queue-req: 0, 
[2025-12-17 20:54:50] INFO:     127.0.0.1:33914 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:50] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 889, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:51] INFO:     127.0.0.1:33918 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:53] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:53] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 15.02, #queue-req: 0, 
[2025-12-17 20:54:53] INFO:     127.0.0.1:33924 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:53] Prefill batch, #new-seq: 1, #new-token: 24, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:53] INFO:     127.0.0.1:33928 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:55] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:55] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.09, #queue-req: 0, 
[2025-12-17 20:54:55] INFO:     127.0.0.1:33934 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:55] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 1296, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:55] INFO:     127.0.0.1:33938 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:57] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:57] INFO:     127.0.0.1:33942 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:57] Prefill batch, #new-seq: 1, #new-token: 905, #cached-token: 90, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:57] INFO:     127.0.0.1:33946 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:57] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.96, #queue-req: 0, 
[2025-12-17 20:54:59] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:54:59] INFO:     127.0.0.1:33950 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:54:59] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:00] INFO:     127.0.0.1:33954 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:01] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:01] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.99, #queue-req: 0, 
[2025-12-17 20:55:01] INFO:     127.0.0.1:33958 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:01] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 887, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:02] INFO:     127.0.0.1:33962 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:04] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:04] INFO:     127.0.0.1:33966 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:04] Prefill batch, #new-seq: 1, #new-token: 1364, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:04] INFO:     127.0.0.1:33970 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:06] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:06] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.42, #queue-req: 0, 
[2025-12-17 20:55:06] INFO:     127.0.0.1:33974 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:06] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 966, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:06] INFO:     127.0.0.1:33980 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:08] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:08] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.06, #queue-req: 0, 
[2025-12-17 20:55:08] INFO:     127.0.0.1:33986 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:08] Prefill batch, #new-seq: 1, #new-token: 1273, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:08] INFO:     127.0.0.1:33990 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:10] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:10] INFO:     127.0.0.1:33994 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:10] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 874, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:10] Decode batch, #running-req: 1, #token: 892, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.58, #queue-req: 0, 
[2025-12-17 20:55:10] INFO:     127.0.0.1:33998 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:12] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:12] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.56, #queue-req: 0, 
[2025-12-17 20:55:12] INFO:     127.0.0.1:34002 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:12] Prefill batch, #new-seq: 1, #new-token: 1157, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:12] INFO:     127.0.0.1:34006 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:14] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:14] INFO:     127.0.0.1:34010 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:14] Prefill batch, #new-seq: 1, #new-token: 1250, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:14] INFO:     127.0.0.1:34014 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:14] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.92, #queue-req: 0, 
[2025-12-17 20:55:16] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:16] INFO:     127.0.0.1:34018 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:16] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 893, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:17] INFO:     127.0.0.1:34022 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:18] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:19] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.58, #queue-req: 0, 
[2025-12-17 20:55:19] INFO:     127.0.0.1:34026 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:19] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 869, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:19] INFO:     127.0.0.1:34030 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:21] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:21] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.52, #queue-req: 0, 
[2025-12-17 20:55:21] INFO:     127.0.0.1:34038 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:21] Prefill batch, #new-seq: 1, #new-token: 1289, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:21] INFO:     127.0.0.1:34042 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:23] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:23] INFO:     127.0.0.1:34046 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:23] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:23] INFO:     127.0.0.1:34050 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:25] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:25] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.50, #queue-req: 0, 
[2025-12-17 20:55:25] INFO:     127.0.0.1:34054 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:25] Prefill batch, #new-seq: 1, #new-token: 638, #cached-token: 282, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:26] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 182.67, #queue-req: 0, 
[2025-12-17 20:55:26] INFO:     127.0.0.1:34058 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:28] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:28] INFO:     127.0.0.1:34062 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:28] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:28] INFO:     127.0.0.1:34066 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:30] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:30] INFO:     127.0.0.1:34074 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:30] Prefill batch, #new-seq: 1, #new-token: 1050, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:30] Decode batch, #running-req: 1, #token: 1068, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.60, #queue-req: 0, 
[2025-12-17 20:55:30] INFO:     127.0.0.1:34078 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:32] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:32] INFO:     127.0.0.1:34082 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:32] Prefill batch, #new-seq: 1, #new-token: 26, #cached-token: 871, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:32] INFO:     127.0.0.1:34086 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:32] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.91, #queue-req: 0, 
[2025-12-17 20:55:34] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:34] INFO:     127.0.0.1:34090 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:34] Prefill batch, #new-seq: 1, #new-token: 1489, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:34] Decode batch, #running-req: 1, #token: 1530, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.89, #queue-req: 0, 
[2025-12-17 20:55:34] INFO:     127.0.0.1:34094 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:36] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:36] INFO:     127.0.0.1:34098 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:36] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:36] INFO:     127.0.0.1:34102 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:38] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:38] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.55, #queue-req: 0, 
[2025-12-17 20:55:38] INFO:     127.0.0.1:34110 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:38] Prefill batch, #new-seq: 1, #new-token: 1183, #cached-token: 169, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:38] Decode batch, #running-req: 1, #token: 1384, token usage: 0.00, cuda graph: True, gen throughput (token/s): 170.42, #queue-req: 0, 
[2025-12-17 20:55:38] INFO:     127.0.0.1:34114 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:40] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:40] INFO:     127.0.0.1:34120 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:41] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 873, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:41] INFO:     127.0.0.1:34124 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:42] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:43] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.77, #queue-req: 0, 
[2025-12-17 20:55:43] INFO:     127.0.0.1:34128 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:43] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 946, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:43] INFO:     127.0.0.1:34132 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:45] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:45] INFO:     127.0.0.1:34136 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:45] Prefill batch, #new-seq: 1, #new-token: 1047, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:45] Decode batch, #running-req: 1, #token: 1082, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.98, #queue-req: 0, 
[2025-12-17 20:55:45] Decode batch, #running-req: 1, #token: 1122, token usage: 0.00, cuda graph: True, gen throughput (token/s): 214.91, #queue-req: 0, 
[2025-12-17 20:55:45] INFO:     127.0.0.1:34140 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:47] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:47] INFO:     127.0.0.1:34144 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:47] Prefill batch, #new-seq: 1, #new-token: 1209, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:47] Decode batch, #running-req: 1, #token: 1235, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.29, #queue-req: 0, 
[2025-12-17 20:55:47] INFO:     127.0.0.1:34148 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:49] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:49] INFO:     127.0.0.1:34152 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:49] Prefill batch, #new-seq: 1, #new-token: 1023, #cached-token: 92, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:49] Decode batch, #running-req: 1, #token: 1139, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.33, #queue-req: 0, 
[2025-12-17 20:55:49] INFO:     127.0.0.1:34156 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:51] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:51] INFO:     127.0.0.1:34160 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:51] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:52] INFO:     127.0.0.1:34164 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:53] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:53] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.79, #queue-req: 0, 
[2025-12-17 20:55:53] INFO:     127.0.0.1:34168 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:53] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 871, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:54] Decode batch, #running-req: 1, #token: 919, token usage: 0.00, cuda graph: True, gen throughput (token/s): 194.20, #queue-req: 0, 
[2025-12-17 20:55:54] INFO:     127.0.0.1:34172 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:56] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:56] INFO:     127.0.0.1:34178 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:56] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 871, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:56] INFO:     127.0.0.1:34182 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:58] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:58] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.58, #queue-req: 0, 
[2025-12-17 20:55:58] INFO:     127.0.0.1:34186 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:55:58] Prefill batch, #new-seq: 1, #new-token: 1137, #cached-token: 139, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:55:58] INFO:     127.0.0.1:34190 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:00] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:00] INFO:     127.0.0.1:34194 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:00] Prefill batch, #new-seq: 1, #new-token: 1347, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:00] INFO:     127.0.0.1:34198 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:02] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:02] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.82, #queue-req: 0, 
[2025-12-17 20:56:02] INFO:     127.0.0.1:34202 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:02] Prefill batch, #new-seq: 1, #new-token: 1418, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:02] INFO:     127.0.0.1:34206 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:05] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:05] Decode batch, #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.51, #queue-req: 0, 
[2025-12-17 20:56:05] INFO:     127.0.0.1:34212 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:05] Prefill batch, #new-seq: 1, #new-token: 24, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:05] INFO:     127.0.0.1:34216 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:07] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:07] INFO:     127.0.0.1:34220 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:07] Prefill batch, #new-seq: 1, #new-token: 24, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:07] Decode batch, #running-req: 1, #token: 909, token usage: 0.00, cuda graph: True, gen throughput (token/s): 14.84, #queue-req: 0, 
[2025-12-17 20:56:07] INFO:     127.0.0.1:34224 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:09] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:10] INFO:     127.0.0.1:34228 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:10] Prefill batch, #new-seq: 1, #new-token: 23, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:10] Decode batch, #running-req: 1, #token: 906, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.76, #queue-req: 0, 
[2025-12-17 20:56:10] INFO:     127.0.0.1:34232 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:12] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:12] INFO:     127.0.0.1:34236 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:12] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 874, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:12] INFO:     127.0.0.1:34240 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:14] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:14] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.89, #queue-req: 0, 
[2025-12-17 20:56:14] INFO:     127.0.0.1:34246 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:14] Prefill batch, #new-seq: 1, #new-token: 1286, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:14] INFO:     127.0.0.1:34250 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:16] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:16] INFO:     127.0.0.1:34254 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:16] Prefill batch, #new-seq: 1, #new-token: 1332, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:16] Decode batch, #running-req: 1, #token: 1354, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.71, #queue-req: 0, 
[2025-12-17 20:56:16] INFO:     127.0.0.1:34258 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:18] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:18] INFO:     127.0.0.1:34262 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:18] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 869, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:18] Decode batch, #running-req: 1, #token: 895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.21, #queue-req: 0, 
[2025-12-17 20:56:18] INFO:     127.0.0.1:34266 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:20] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:20] INFO:     127.0.0.1:34270 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:20] Prefill batch, #new-seq: 1, #new-token: 1067, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:20] Decode batch, #running-req: 1, #token: 1108, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.11, #queue-req: 0, 
[2025-12-17 20:56:20] INFO:     127.0.0.1:34274 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:23] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:23] INFO:     127.0.0.1:34278 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:23] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 946, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:23] Decode batch, #running-req: 1, #token: 970, token usage: 0.00, cuda graph: True, gen throughput (token/s): 15.14, #queue-req: 0, 
[2025-12-17 20:56:23] INFO:     127.0.0.1:34282 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:25] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:25] INFO:     127.0.0.1:34286 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:25] Prefill batch, #new-seq: 1, #new-token: 1209, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:25] Decode batch, #running-req: 1, #token: 1251, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.08, #queue-req: 0, 
[2025-12-17 20:56:26] INFO:     127.0.0.1:34290 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:28] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:28] INFO:     127.0.0.1:34294 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:28] Prefill batch, #new-seq: 1, #new-token: 915, #cached-token: 118, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:28] Decode batch, #running-req: 1, #token: 1048, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.17, #queue-req: 0, 
[2025-12-17 20:56:28] INFO:     127.0.0.1:34298 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:30] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:30] INFO:     127.0.0.1:34302 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:30] Prefill batch, #new-seq: 1, #new-token: 1284, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:30] Decode batch, #running-req: 1, #token: 1312, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.26, #queue-req: 0, 
[2025-12-17 20:56:30] INFO:     127.0.0.1:34306 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:32] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:32] INFO:     127.0.0.1:34312 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:32] Prefill batch, #new-seq: 1, #new-token: 1235, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:32] Decode batch, #running-req: 1, #token: 1285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.07, #queue-req: 0, 
[2025-12-17 20:56:32] INFO:     127.0.0.1:34316 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:34] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:34] INFO:     127.0.0.1:34326 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:34] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 869, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:34] Decode batch, #running-req: 1, #token: 903, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.92, #queue-req: 0, 
[2025-12-17 20:56:34] INFO:     127.0.0.1:34330 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:36] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:36] INFO:     127.0.0.1:34342 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:36] Prefill batch, #new-seq: 1, #new-token: 1161, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:36] INFO:     127.0.0.1:34346 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:39] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:39] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 7.89, #queue-req: 0, 
[2025-12-17 20:56:39] INFO:     127.0.0.1:34366 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:39] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 874, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:39] INFO:     127.0.0.1:34372 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:42] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:42] INFO:     127.0.0.1:34382 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:42] Prefill batch, #new-seq: 1, #new-token: 1210, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:42] Decode batch, #running-req: 1, #token: 1252, token usage: 0.00, cuda graph: True, gen throughput (token/s): 14.08, #queue-req: 0, 
[2025-12-17 20:56:42] INFO:     127.0.0.1:34386 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:44] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:44] INFO:     127.0.0.1:34524 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:44] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 870, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:44] Decode batch, #running-req: 1, #token: 898, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.38, #queue-req: 0, 
[2025-12-17 20:56:44] Decode batch, #running-req: 1, #token: 938, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.15, #queue-req: 0, 
[2025-12-17 20:56:45] Decode batch, #running-req: 1, #token: 978, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.25, #queue-req: 0, 
[2025-12-17 20:56:45] Decode batch, #running-req: 1, #token: 1018, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.22, #queue-req: 0, 
[2025-12-17 20:56:45] Decode batch, #running-req: 1, #token: 1058, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 20:56:45] Decode batch, #running-req: 1, #token: 1098, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:56:45] Decode batch, #running-req: 1, #token: 1138, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.46, #queue-req: 0, 
[2025-12-17 20:56:46] Decode batch, #running-req: 1, #token: 1178, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.62, #queue-req: 0, 
[2025-12-17 20:56:46] Decode batch, #running-req: 1, #token: 1218, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 20:56:46] Decode batch, #running-req: 1, #token: 1258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 20:56:46] Decode batch, #running-req: 1, #token: 1298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.63, #queue-req: 0, 
[2025-12-17 20:56:46] Decode batch, #running-req: 1, #token: 1338, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 20:56:46] Decode batch, #running-req: 1, #token: 1378, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 20:56:47] Decode batch, #running-req: 1, #token: 1418, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.63, #queue-req: 0, 
[2025-12-17 20:56:47] Decode batch, #running-req: 1, #token: 1458, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 20:56:47] Decode batch, #running-req: 1, #token: 1498, token usage: 0.00, cuda graph: True, gen throughput (token/s): 110.69, #queue-req: 0, 
[2025-12-17 20:56:47] Decode batch, #running-req: 1, #token: 1538, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 20:56:48] Decode batch, #running-req: 1, #token: 1578, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 20:56:48] Decode batch, #running-req: 1, #token: 1618, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 20:56:48] Decode batch, #running-req: 1, #token: 1658, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.26, #queue-req: 0, 
[2025-12-17 20:56:48] Decode batch, #running-req: 1, #token: 1698, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.32, #queue-req: 0, 
[2025-12-17 20:56:48] Decode batch, #running-req: 1, #token: 1738, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 20:56:48] Decode batch, #running-req: 1, #token: 1778, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.39, #queue-req: 0, 
[2025-12-17 20:56:49] Decode batch, #running-req: 1, #token: 1818, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.25, #queue-req: 0, 
[2025-12-17 20:56:49] Decode batch, #running-req: 1, #token: 1858, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.20, #queue-req: 0, 
[2025-12-17 20:56:49] INFO:     127.0.0.1:34532 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:51] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:52] INFO:     127.0.0.1:35844 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:52] Prefill batch, #new-seq: 1, #new-token: 1015, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:52] Decode batch, #running-req: 1, #token: 1053, token usage: 0.00, cuda graph: True, gen throughput (token/s): 14.01, #queue-req: 0, 
[2025-12-17 20:56:52] INFO:     127.0.0.1:35932 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:54] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:54] INFO:     127.0.0.1:36136 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:54] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 945, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:54] Decode batch, #running-req: 1, #token: 969, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.56, #queue-req: 0, 
[2025-12-17 20:56:54] INFO:     127.0.0.1:36158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:56] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:56] INFO:     127.0.0.1:36298 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:56] Prefill batch, #new-seq: 1, #new-token: 1443, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:56] Decode batch, #running-req: 1, #token: 1485, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.57, #queue-req: 0, 
[2025-12-17 20:56:56] INFO:     127.0.0.1:36304 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:58] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:58] INFO:     127.0.0.1:36402 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:56:58] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:56:58] Decode batch, #running-req: 1, #token: 908, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.31, #queue-req: 0, 
[2025-12-17 20:56:58] INFO:     127.0.0.1:36412 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:00] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:00] INFO:     127.0.0.1:36544 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:00] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 873, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:01] Decode batch, #running-req: 1, #token: 905, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.15, #queue-req: 0, 
[2025-12-17 20:57:01] INFO:     127.0.0.1:36548 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:03] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:03] INFO:     127.0.0.1:36582 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:03] Prefill batch, #new-seq: 1, #new-token: 799, #cached-token: 92, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:03] INFO:     127.0.0.1:36586 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:05] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:05] INFO:     127.0.0.1:36692 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:05] Prefill batch, #new-seq: 1, #new-token: 991, #cached-token: 153, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:05] Decode batch, #running-req: 1, #token: 1146, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.43, #queue-req: 0, 
[2025-12-17 20:57:05] INFO:     127.0.0.1:36696 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:07] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:07] INFO:     127.0.0.1:36778 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:07] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 945, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:07] Decode batch, #running-req: 1, #token: 980, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.83, #queue-req: 0, 
[2025-12-17 20:57:07] INFO:     127.0.0.1:36788 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:09] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:09] INFO:     127.0.0.1:36812 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:09] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 876, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:09] Decode batch, #running-req: 1, #token: 896, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.31, #queue-req: 0, 
[2025-12-17 20:57:09] INFO:     127.0.0.1:36816 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:11] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:11] INFO:     127.0.0.1:36838 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:11] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 946, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:11] INFO:     127.0.0.1:36846 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:13] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:13] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.55, #queue-req: 0, 
[2025-12-17 20:57:13] INFO:     127.0.0.1:36902 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:13] Prefill batch, #new-seq: 1, #new-token: 979, #cached-token: 179, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:13] Decode batch, #running-req: 1, #token: 1184, token usage: 0.00, cuda graph: True, gen throughput (token/s): 175.45, #queue-req: 0, 
[2025-12-17 20:57:14] INFO:     127.0.0.1:36908 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:16] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:16] INFO:     127.0.0.1:37018 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:16] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 946, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:16] INFO:     127.0.0.1:37026 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:18] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:18] Decode batch, #running-req: 1, #token: 72, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.02, #queue-req: 0, 
[2025-12-17 20:57:18] INFO:     127.0.0.1:37086 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:18] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 874, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:18] INFO:     127.0.0.1:37090 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:20] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:20] INFO:     127.0.0.1:37104 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:20] Prefill batch, #new-seq: 1, #new-token: 21, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:20] Decode batch, #running-req: 1, #token: 901, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.04, #queue-req: 0, 
[2025-12-17 20:57:20] INFO:     127.0.0.1:37108 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:22] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:22] INFO:     127.0.0.1:37114 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:22] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 946, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:22] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.96, #queue-req: 0, 
[2025-12-17 20:57:22] INFO:     127.0.0.1:37118 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:24] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:24] INFO:     127.0.0.1:37134 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:24] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 873, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:25] INFO:     127.0.0.1:37138 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:26] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:26] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.04, #queue-req: 0, 
[2025-12-17 20:57:26] INFO:     127.0.0.1:37152 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:26] Prefill batch, #new-seq: 1, #new-token: 1187, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:26] INFO:     127.0.0.1:37158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:28] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:29] INFO:     127.0.0.1:37200 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:29] Prefill batch, #new-seq: 1, #new-token: 1167, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:29] Decode batch, #running-req: 1, #token: 1204, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.98, #queue-req: 0, 
[2025-12-17 20:57:29] INFO:     127.0.0.1:37204 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:31] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:31] INFO:     127.0.0.1:37264 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:31] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 874, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:31] INFO:     127.0.0.1:37270 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:33] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:33] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.39, #queue-req: 0, 
[2025-12-17 20:57:33] INFO:     127.0.0.1:37334 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:33] Prefill batch, #new-seq: 1, #new-token: 1181, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:33] INFO:     127.0.0.1:37342 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:35] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:35] INFO:     127.0.0.1:37402 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:35] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.13, #queue-req: 0, 
[2025-12-17 20:57:35] Prefill batch, #new-seq: 1, #new-token: 970, #cached-token: 69, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:35] INFO:     127.0.0.1:37406 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:37] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:37] INFO:     127.0.0.1:37426 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:37] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 874, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:37] INFO:     127.0.0.1:37430 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:39] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:39] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.92, #queue-req: 0, 
[2025-12-17 20:57:39] INFO:     127.0.0.1:37444 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:39] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:39] INFO:     127.0.0.1:37448 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:41] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:41] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.10, #queue-req: 0, 
[2025-12-17 20:57:41] INFO:     127.0.0.1:37454 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:41] Prefill batch, #new-seq: 1, #new-token: 797, #cached-token: 95, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:41] INFO:     127.0.0.1:37458 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:43] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:43] INFO:     127.0.0.1:37462 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:43] Prefill batch, #new-seq: 1, #new-token: 1287, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:44] Decode batch, #running-req: 1, #token: 1331, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.89, #queue-req: 0, 
[2025-12-17 20:57:44] INFO:     127.0.0.1:37466 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:46] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:46] INFO:     127.0.0.1:37474 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:46] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 874, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:46] Decode batch, #running-req: 1, #token: 905, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.19, #queue-req: 0, 
[2025-12-17 20:57:46] INFO:     127.0.0.1:37478 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:48] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:48] Decode batch, #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 20.11, #queue-req: 0, 
[2025-12-17 20:57:48] INFO:     127.0.0.1:37488 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:48] Prefill batch, #new-seq: 1, #new-token: 23, #cached-token: 874, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:48] Decode batch, #running-req: 1, #token: 934, token usage: 0.00, cuda graph: True, gen throughput (token/s): 192.22, #queue-req: 0, 
[2025-12-17 20:57:48] Decode batch, #running-req: 1, #token: 974, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.78, #queue-req: 0, 
[2025-12-17 20:57:48] Decode batch, #running-req: 1, #token: 1014, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.52, #queue-req: 0, 
[2025-12-17 20:57:48] Decode batch, #running-req: 1, #token: 1054, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.22, #queue-req: 0, 
[2025-12-17 20:57:49] Decode batch, #running-req: 1, #token: 1094, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.15, #queue-req: 0, 
[2025-12-17 20:57:49] Decode batch, #running-req: 1, #token: 1134, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.99, #queue-req: 0, 
[2025-12-17 20:57:49] Decode batch, #running-req: 1, #token: 1174, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.97, #queue-req: 0, 
[2025-12-17 20:57:49] Decode batch, #running-req: 1, #token: 1214, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.00, #queue-req: 0, 
[2025-12-17 20:57:49] Decode batch, #running-req: 1, #token: 1254, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 20:57:50] Decode batch, #running-req: 1, #token: 1294, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.03, #queue-req: 0, 
[2025-12-17 20:57:50] Decode batch, #running-req: 1, #token: 1334, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 20:57:50] Decode batch, #running-req: 1, #token: 1374, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.06, #queue-req: 0, 
[2025-12-17 20:57:50] Decode batch, #running-req: 1, #token: 1414, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 20:57:50] Decode batch, #running-req: 1, #token: 1454, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.03, #queue-req: 0, 
[2025-12-17 20:57:50] Decode batch, #running-req: 1, #token: 1494, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.14, #queue-req: 0, 
[2025-12-17 20:57:51] Decode batch, #running-req: 1, #token: 1534, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.11, #queue-req: 0, 
[2025-12-17 20:57:51] Decode batch, #running-req: 1, #token: 1574, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:57:51] Decode batch, #running-req: 1, #token: 1614, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:57:51] Decode batch, #running-req: 1, #token: 1654, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:57:51] Decode batch, #running-req: 1, #token: 1694, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.82, #queue-req: 0, 
[2025-12-17 20:57:52] Decode batch, #running-req: 1, #token: 1734, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.92, #queue-req: 0, 
[2025-12-17 20:57:52] Decode batch, #running-req: 1, #token: 1774, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.88, #queue-req: 0, 
[2025-12-17 20:57:52] Decode batch, #running-req: 1, #token: 1814, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.62, #queue-req: 0, 
[2025-12-17 20:57:52] Decode batch, #running-req: 1, #token: 1854, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 20:57:52] Decode batch, #running-req: 1, #token: 1894, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.77, #queue-req: 0, 
[2025-12-17 20:57:52] INFO:     127.0.0.1:37492 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:54] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:54] INFO:     127.0.0.1:37560 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:54] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:54] INFO:     127.0.0.1:37564 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:56] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:56] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.61, #queue-req: 0, 
[2025-12-17 20:57:56] INFO:     127.0.0.1:37594 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:56] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 869, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:57] INFO:     127.0.0.1:37600 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:58] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:59] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.78, #queue-req: 0, 
[2025-12-17 20:57:59] INFO:     127.0.0.1:37640 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:57:59] Prefill batch, #new-seq: 1, #new-token: 1327, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:57:59] INFO:     127.0.0.1:37646 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:01] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:01] INFO:     127.0.0.1:37694 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:01] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:01] Decode batch, #running-req: 1, #token: 895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.81, #queue-req: 0, 
[2025-12-17 20:58:01] INFO:     127.0.0.1:37700 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:03] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:03] INFO:     127.0.0.1:37748 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:03] Prefill batch, #new-seq: 1, #new-token: 1225, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:03] Decode batch, #running-req: 1, #token: 1271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.96, #queue-req: 0, 
[2025-12-17 20:58:03] INFO:     127.0.0.1:37752 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:05] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:05] INFO:     127.0.0.1:37780 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:05] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 1279, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:05] INFO:     127.0.0.1:37786 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:07] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:07] INFO:     127.0.0.1:37798 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:07] Prefill batch, #new-seq: 1, #new-token: 1405, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:07] Decode batch, #running-req: 1, #token: 1419, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.63, #queue-req: 0, 
[2025-12-17 20:58:07] INFO:     127.0.0.1:37802 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:10] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:10] INFO:     127.0.0.1:37808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:10] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 874, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:10] Decode batch, #running-req: 1, #token: 894, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.13, #queue-req: 0, 
[2025-12-17 20:58:10] INFO:     127.0.0.1:37812 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:12] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:12] INFO:     127.0.0.1:37816 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:12] Prefill batch, #new-seq: 1, #new-token: 21, #cached-token: 1278, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:12] Decode batch, #running-req: 1, #token: 1311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 15.07, #queue-req: 0, 
[2025-12-17 20:58:12] INFO:     127.0.0.1:37820 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:15] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:15] INFO:     127.0.0.1:37824 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:15] Prefill batch, #new-seq: 1, #new-token: 1141, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:15] Decode batch, #running-req: 1, #token: 1174, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.25, #queue-req: 0, 
[2025-12-17 20:58:15] INFO:     127.0.0.1:37828 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:17] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:17] INFO:     127.0.0.1:37834 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:17] Prefill batch, #new-seq: 1, #new-token: 1312, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:17] Decode batch, #running-req: 1, #token: 1364, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.94, #queue-req: 0, 
[2025-12-17 20:58:17] INFO:     127.0.0.1:37838 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:19] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:19] INFO:     127.0.0.1:37842 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:19] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 850, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:19] INFO:     127.0.0.1:37846 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:21] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:22] Decode batch, #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.78, #queue-req: 0, 
[2025-12-17 20:58:22] INFO:     127.0.0.1:37852 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:22] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 850, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:22] INFO:     127.0.0.1:37856 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:24] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:24] INFO:     127.0.0.1:37862 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:24] Prefill batch, #new-seq: 1, #new-token: 1467, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:24] Decode batch, #running-req: 1, #token: 1489, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.97, #queue-req: 0, 
[2025-12-17 20:58:24] INFO:     127.0.0.1:37866 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:26] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:27] INFO:     127.0.0.1:37870 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:27] Prefill batch, #new-seq: 1, #new-token: 1443, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:27] INFO:     127.0.0.1:37880 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:29] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:29] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.05, #queue-req: 0, 
[2025-12-17 20:58:29] INFO:     127.0.0.1:37890 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:29] Prefill batch, #new-seq: 1, #new-token: 1235, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:29] INFO:     127.0.0.1:37894 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:31] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:31] INFO:     127.0.0.1:37908 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:31] Prefill batch, #new-seq: 1, #new-token: 1219, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:31] Decode batch, #running-req: 1, #token: 1263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.92, #queue-req: 0, 
[2025-12-17 20:58:31] INFO:     127.0.0.1:37912 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:33] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:34] INFO:     127.0.0.1:37926 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:34] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 924, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:34] INFO:     127.0.0.1:37930 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:36] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:36] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.65, #queue-req: 0, 
[2025-12-17 20:58:36] INFO:     127.0.0.1:37956 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:36] Prefill batch, #new-seq: 1, #new-token: 1268, #cached-token: 40, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:36] INFO:     127.0.0.1:37966 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:38] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:38] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.12, #queue-req: 0, 
[2025-12-17 20:58:38] INFO:     127.0.0.1:38006 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:38] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 925, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:38] INFO:     127.0.0.1:38010 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:40] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:40] INFO:     127.0.0.1:38040 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:40] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 851, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:40] Decode batch, #running-req: 1, #token: 889, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.71, #queue-req: 0, 
[2025-12-17 20:58:40] INFO:     127.0.0.1:38046 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:42] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 40, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:42] INFO:     127.0.0.1:38088 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:42] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 928, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:42] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.04, #queue-req: 0, 
[2025-12-17 20:58:42] INFO:     127.0.0.1:38094 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:44] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:44] INFO:     127.0.0.1:38118 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:44] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 925, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:44] INFO:     127.0.0.1:38124 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:50] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:50] INFO:     127.0.0.1:38182 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:50] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 4.89, #queue-req: 0, 
[2025-12-17 20:58:50] Prefill batch, #new-seq: 1, #new-token: 1154, #cached-token: 147, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:50] INFO:     127.0.0.1:38186 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:53] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:53] INFO:     127.0.0.1:38198 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:53] Prefill batch, #new-seq: 1, #new-token: 1248, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:53] Decode batch, #running-req: 1, #token: 1288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.67, #queue-req: 0, 
[2025-12-17 20:58:53] INFO:     127.0.0.1:38202 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:55] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:55] INFO:     127.0.0.1:38214 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:55] Prefill batch, #new-seq: 1, #new-token: 1342, #cached-token: 41, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:55] Decode batch, #running-req: 1, #token: 1400, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.95, #queue-req: 0, 
[2025-12-17 20:58:55] INFO:     127.0.0.1:38218 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:57] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:57] INFO:     127.0.0.1:38230 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:57] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 914, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:57] INFO:     127.0.0.1:38234 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:59] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:59] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.90, #queue-req: 0, 
[2025-12-17 20:58:59] INFO:     127.0.0.1:38238 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:58:59] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 851, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:58:59] INFO:     127.0.0.1:38242 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:01] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:01] INFO:     127.0.0.1:38246 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:01] Prefill batch, #new-seq: 1, #new-token: 1172, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:01] Decode batch, #running-req: 1, #token: 1209, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.76, #queue-req: 0, 
[2025-12-17 20:59:01] INFO:     127.0.0.1:38250 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:04] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:04] INFO:     127.0.0.1:38254 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:04] Prefill batch, #new-seq: 1, #new-token: 1068, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:04] INFO:     127.0.0.1:38258 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:06] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:06] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.03, #queue-req: 0, 
[2025-12-17 20:59:06] INFO:     127.0.0.1:38262 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:06] Prefill batch, #new-seq: 1, #new-token: 1313, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:07] INFO:     127.0.0.1:38266 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:09] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:09] INFO:     127.0.0.1:38270 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:09] Prefill batch, #new-seq: 1, #new-token: 31, #cached-token: 853, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:09] Decode batch, #running-req: 1, #token: 887, token usage: 0.00, cuda graph: True, gen throughput (token/s): 15.52, #queue-req: 0, 
[2025-12-17 20:59:09] INFO:     127.0.0.1:38274 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:11] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:11] INFO:     127.0.0.1:38280 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:11] Prefill batch, #new-seq: 1, #new-token: 29, #cached-token: 925, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:11] INFO:     127.0.0.1:38284 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:13] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:13] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.74, #queue-req: 0, 
[2025-12-17 20:59:13] INFO:     127.0.0.1:38288 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:13] Prefill batch, #new-seq: 1, #new-token: 1128, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:13] INFO:     127.0.0.1:38294 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:15] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:15] INFO:     127.0.0.1:38298 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:15] Prefill batch, #new-seq: 1, #new-token: 1240, #cached-token: 18, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:15] Decode batch, #running-req: 1, #token: 1264, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.72, #queue-req: 0, 
[2025-12-17 20:59:15] INFO:     127.0.0.1:38304 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:18] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:18] INFO:     127.0.0.1:38308 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:18] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 15.06, #queue-req: 0, 
[2025-12-17 20:59:18] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 924, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:18] INFO:     127.0.0.1:38312 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:20] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:20] INFO:     127.0.0.1:38320 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:20] Prefill batch, #new-seq: 1, #new-token: 1039, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:20] Decode batch, #running-req: 1, #token: 1079, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.62, #queue-req: 0, 
[2025-12-17 20:59:20] INFO:     127.0.0.1:38324 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:22] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:22] INFO:     127.0.0.1:38328 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:22] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 847, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:22] Decode batch, #running-req: 1, #token: 892, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.27, #queue-req: 0, 
[2025-12-17 20:59:22] INFO:     127.0.0.1:38332 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:24] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:25] INFO:     127.0.0.1:38336 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:25] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 851, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:25] Decode batch, #running-req: 1, #token: 904, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.37, #queue-req: 0, 
[2025-12-17 20:59:25] INFO:     127.0.0.1:38340 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:27] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:27] INFO:     127.0.0.1:38344 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:27] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 924, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 20:59:27] INFO:     127.0.0.1:38348 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 20:59:48] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:00] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 1.14, #queue-req: 0, 
[2025-12-17 21:00:00] INFO:     127.0.0.1:38366 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:00] Prefill batch, #new-seq: 1, #new-token: 1088, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:00] INFO:     127.0.0.1:38376 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:07] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:07] Decode batch, #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 5.46, #queue-req: 0, 
[2025-12-17 21:00:07] INFO:     127.0.0.1:38380 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:07] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 850, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:07] INFO:     127.0.0.1:38384 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:09] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:09] INFO:     127.0.0.1:38388 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:09] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 852, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:09] Decode batch, #running-req: 1, #token: 900, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.80, #queue-req: 0, 
[2025-12-17 21:00:09] INFO:     127.0.0.1:38392 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:11] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:11] INFO:     127.0.0.1:38396 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:11] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 851, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:11] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.87, #queue-req: 0, 
[2025-12-17 21:00:11] INFO:     127.0.0.1:38400 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:13] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:13] INFO:     127.0.0.1:38404 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:13] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 848, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:14] INFO:     127.0.0.1:38408 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:16] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:16] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.58, #queue-req: 0, 
[2025-12-17 21:00:16] INFO:     127.0.0.1:38412 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:16] Prefill batch, #new-seq: 1, #new-token: 1312, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:16] INFO:     127.0.0.1:38416 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:18] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:18] INFO:     127.0.0.1:38420 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:18] Prefill batch, #new-seq: 1, #new-token: 37, #cached-token: 1257, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:18] Decode batch, #running-req: 1, #token: 1299, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.28, #queue-req: 0, 
[2025-12-17 21:00:18] INFO:     127.0.0.1:38424 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:20] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:20] INFO:     127.0.0.1:38428 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:20] Prefill batch, #new-seq: 1, #new-token: 28, #cached-token: 852, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:21] INFO:     127.0.0.1:38432 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:23] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:23] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.27, #queue-req: 0, 
[2025-12-17 21:00:23] INFO:     127.0.0.1:38436 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:23] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 853, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:23] INFO:     127.0.0.1:38440 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:32] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:34] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 3.44, #queue-req: 0, 
[2025-12-17 21:00:34] INFO:     127.0.0.1:38446 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:37] Prefill batch, #new-seq: 1, #new-token: 1511, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:39] INFO:     127.0.0.1:38454 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:41] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:41] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 5.69, #queue-req: 0, 
[2025-12-17 21:00:41] INFO:     127.0.0.1:38458 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:41] Prefill batch, #new-seq: 1, #new-token: 1226, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:41] INFO:     127.0.0.1:38462 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:47] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:47] INFO:     127.0.0.1:38470 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:47] Prefill batch, #new-seq: 1, #new-token: 1259, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:47] Decode batch, #running-req: 1, #token: 1277, token usage: 0.00, cuda graph: True, gen throughput (token/s): 7.36, #queue-req: 0, 
[2025-12-17 21:00:47] INFO:     127.0.0.1:38474 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:49] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:49] INFO:     127.0.0.1:38482 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:49] Prefill batch, #new-seq: 1, #new-token: 886, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:49] Decode batch, #running-req: 1, #token: 910, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.71, #queue-req: 0, 
[2025-12-17 21:00:49] INFO:     127.0.0.1:38486 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:51] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:51] INFO:     127.0.0.1:38490 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:51] Prefill batch, #new-seq: 1, #new-token: 955, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:51] INFO:     127.0.0.1:38494 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:54] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:54] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.73, #queue-req: 0, 
[2025-12-17 21:00:54] INFO:     127.0.0.1:38498 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:54] Prefill batch, #new-seq: 1, #new-token: 1279, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:54] INFO:     127.0.0.1:38502 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:56] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:56] INFO:     127.0.0.1:38506 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:56] Prefill batch, #new-seq: 1, #new-token: 1555, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:00:56] Decode batch, #running-req: 1, #token: 1572, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.83, #queue-req: 0, 
[2025-12-17 21:00:56] INFO:     127.0.0.1:38510 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:00:58] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:12] INFO:     127.0.0.1:38514 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:12] Prefill batch, #new-seq: 1, #new-token: 927, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:12] Decode batch, #running-req: 1, #token: 956, token usage: 0.00, cuda graph: True, gen throughput (token/s): 2.48, #queue-req: 0, 
[2025-12-17 21:01:12] INFO:     127.0.0.1:38524 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:14] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:14] INFO:     127.0.0.1:38528 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:14] Prefill batch, #new-seq: 1, #new-token: 1263, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:14] INFO:     127.0.0.1:38532 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:16] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:16] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.19, #queue-req: 0, 
[2025-12-17 21:01:16] INFO:     127.0.0.1:38536 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:16] Prefill batch, #new-seq: 1, #new-token: 1473, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:17] INFO:     127.0.0.1:38540 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:18] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:19] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.35, #queue-req: 0, 
[2025-12-17 21:01:19] INFO:     127.0.0.1:38544 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:19] Prefill batch, #new-seq: 1, #new-token: 1433, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:19] INFO:     127.0.0.1:38548 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:21] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:21] INFO:     127.0.0.1:38554 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:21] Prefill batch, #new-seq: 1, #new-token: 837, #cached-token: 100, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:21] Decode batch, #running-req: 1, #token: 945, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.92, #queue-req: 0, 
[2025-12-17 21:01:21] INFO:     127.0.0.1:38558 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:23] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:23] INFO:     127.0.0.1:38562 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:23] Prefill batch, #new-seq: 1, #new-token: 1342, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:23] Decode batch, #running-req: 1, #token: 1370, token usage: 0.00, cuda graph: True, gen throughput (token/s): 14.61, #queue-req: 0, 
[2025-12-17 21:01:24] INFO:     127.0.0.1:38566 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:25] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:25] INFO:     127.0.0.1:38572 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:25] Prefill batch, #new-seq: 1, #new-token: 1311, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:26] INFO:     127.0.0.1:38576 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:28] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:28] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.74, #queue-req: 0, 
[2025-12-17 21:01:28] INFO:     127.0.0.1:38580 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:28] Prefill batch, #new-seq: 1, #new-token: 1416, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:28] Decode batch, #running-req: 1, #token: 1467, token usage: 0.00, cuda graph: True, gen throughput (token/s): 149.15, #queue-req: 0, 
[2025-12-17 21:01:28] Decode batch, #running-req: 1, #token: 1507, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 21:01:28] Decode batch, #running-req: 1, #token: 1547, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.53, #queue-req: 0, 
[2025-12-17 21:01:28] Decode batch, #running-req: 1, #token: 1587, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 21:01:29] Decode batch, #running-req: 1, #token: 1627, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.62, #queue-req: 0, 
[2025-12-17 21:01:29] Decode batch, #running-req: 1, #token: 1667, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 21:01:29] Decode batch, #running-req: 1, #token: 1707, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 21:01:29] Decode batch, #running-req: 1, #token: 1747, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 21:01:29] Decode batch, #running-req: 1, #token: 1787, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.40, #queue-req: 0, 
[2025-12-17 21:01:30] Decode batch, #running-req: 1, #token: 1827, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.30, #queue-req: 0, 
[2025-12-17 21:01:30] Decode batch, #running-req: 1, #token: 1867, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.21, #queue-req: 0, 
[2025-12-17 21:01:30] Decode batch, #running-req: 1, #token: 1907, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.19, #queue-req: 0, 
[2025-12-17 21:01:30] Decode batch, #running-req: 1, #token: 1947, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 21:01:30] Decode batch, #running-req: 1, #token: 1987, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.42, #queue-req: 0, 
[2025-12-17 21:01:30] Decode batch, #running-req: 1, #token: 2027, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 21:01:31] Decode batch, #running-req: 1, #token: 2067, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.27, #queue-req: 0, 
[2025-12-17 21:01:31] Decode batch, #running-req: 1, #token: 2107, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.00, #queue-req: 0, 
[2025-12-17 21:01:31] Decode batch, #running-req: 1, #token: 2147, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.15, #queue-req: 0, 
[2025-12-17 21:01:31] Decode batch, #running-req: 1, #token: 2187, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.88, #queue-req: 0, 
[2025-12-17 21:01:31] Decode batch, #running-req: 1, #token: 2227, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.84, #queue-req: 0, 
[2025-12-17 21:01:31] Decode batch, #running-req: 1, #token: 2267, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.91, #queue-req: 0, 
[2025-12-17 21:01:32] Decode batch, #running-req: 1, #token: 2307, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.76, #queue-req: 0, 
[2025-12-17 21:01:32] Decode batch, #running-req: 1, #token: 2347, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.59, #queue-req: 0, 
[2025-12-17 21:01:32] Decode batch, #running-req: 1, #token: 2387, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.57, #queue-req: 0, 
[2025-12-17 21:01:32] Decode batch, #running-req: 1, #token: 2427, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.76, #queue-req: 0, 
[2025-12-17 21:01:32] INFO:     127.0.0.1:38584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:34] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:34] INFO:     127.0.0.1:38588 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:34] Prefill batch, #new-seq: 1, #new-token: 1065, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:34] Decode batch, #running-req: 1, #token: 1100, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.27, #queue-req: 0, 
[2025-12-17 21:01:34] INFO:     127.0.0.1:38592 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:36] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:36] INFO:     127.0.0.1:38598 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:36] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 899, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:36] INFO:     127.0.0.1:38602 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:36] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.37, #queue-req: 0, 
[2025-12-17 21:01:38] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:39] INFO:     127.0.0.1:38606 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:39] Prefill batch, #new-seq: 1, #new-token: 1384, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:39] INFO:     127.0.0.1:38610 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:41] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:41] INFO:     127.0.0.1:39720 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:41] Prefill batch, #new-seq: 1, #new-token: 850, #cached-token: 100, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:41] Decode batch, #running-req: 1, #token: 956, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.52, #queue-req: 0, 
[2025-12-17 21:01:41] INFO:     127.0.0.1:39724 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:43] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:43] INFO:     127.0.0.1:39728 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:43] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 934, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:43] INFO:     127.0.0.1:39732 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:45] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:45] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.36, #queue-req: 0, 
[2025-12-17 21:01:45] INFO:     127.0.0.1:39736 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:45] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 925, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:45] INFO:     127.0.0.1:39740 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:47] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:47] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.28, #queue-req: 0, 
[2025-12-17 21:01:47] INFO:     127.0.0.1:39746 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:47] Prefill batch, #new-seq: 1, #new-token: 1035, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:47] INFO:     127.0.0.1:39750 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:49] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:49] Decode batch, #running-req: 1, #token: 70, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.35, #queue-req: 0, 
[2025-12-17 21:01:50] INFO:     127.0.0.1:39754 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:50] Prefill batch, #new-seq: 1, #new-token: 1123, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:50] INFO:     127.0.0.1:39758 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:52] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:52] INFO:     127.0.0.1:39762 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:52] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.20, #queue-req: 0, 
[2025-12-17 21:01:52] Prefill batch, #new-seq: 1, #new-token: 1130, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:52] Decode batch, #running-req: 1, #token: 1183, token usage: 0.00, cuda graph: True, gen throughput (token/s): 177.06, #queue-req: 0, 
[2025-12-17 21:01:52] Decode batch, #running-req: 1, #token: 1223, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 21:01:52] Decode batch, #running-req: 1, #token: 1263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.45, #queue-req: 0, 
[2025-12-17 21:01:52] Decode batch, #running-req: 1, #token: 1303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 21:01:53] Decode batch, #running-req: 1, #token: 1343, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 21:01:53] Decode batch, #running-req: 1, #token: 1383, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 21:01:53] Decode batch, #running-req: 1, #token: 1423, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 21:01:53] Decode batch, #running-req: 1, #token: 1463, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 21:01:53] Decode batch, #running-req: 1, #token: 1503, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.64, #queue-req: 0, 
[2025-12-17 21:01:54] Decode batch, #running-req: 1, #token: 1543, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 21:01:54] Decode batch, #running-req: 1, #token: 1583, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.46, #queue-req: 0, 
[2025-12-17 21:01:54] Decode batch, #running-req: 1, #token: 1623, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.36, #queue-req: 0, 
[2025-12-17 21:01:54] Decode batch, #running-req: 1, #token: 1663, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.13, #queue-req: 0, 
[2025-12-17 21:01:54] Decode batch, #running-req: 1, #token: 1703, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.34, #queue-req: 0, 
[2025-12-17 21:01:54] Decode batch, #running-req: 1, #token: 1743, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.23, #queue-req: 0, 
[2025-12-17 21:01:55] Decode batch, #running-req: 1, #token: 1783, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.21, #queue-req: 0, 
[2025-12-17 21:01:55] Decode batch, #running-req: 1, #token: 1823, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.35, #queue-req: 0, 
[2025-12-17 21:01:55] Decode batch, #running-req: 1, #token: 1863, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.23, #queue-req: 0, 
[2025-12-17 21:01:55] Decode batch, #running-req: 1, #token: 1903, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.12, #queue-req: 0, 
[2025-12-17 21:01:55] Decode batch, #running-req: 1, #token: 1943, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.35, #queue-req: 0, 
[2025-12-17 21:01:56] Decode batch, #running-req: 1, #token: 1983, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.32, #queue-req: 0, 
[2025-12-17 21:01:56] Decode batch, #running-req: 1, #token: 2023, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 21:01:56] Decode batch, #running-req: 1, #token: 2063, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.30, #queue-req: 0, 
[2025-12-17 21:01:56] Decode batch, #running-req: 1, #token: 2103, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.81, #queue-req: 0, 
[2025-12-17 21:01:56] INFO:     127.0.0.1:39766 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:56] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.02, #queue-req: 0, 
[2025-12-17 21:01:58] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 21, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:58] INFO:     127.0.0.1:40616 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:01:58] Prefill batch, #new-seq: 1, #new-token: 10, #cached-token: 925, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:01:58] INFO:     127.0.0.1:40620 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:00] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:00] INFO:     127.0.0.1:40626 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:00] Prefill batch, #new-seq: 1, #new-token: 824, #cached-token: 102, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:00] Decode batch, #running-req: 1, #token: 929, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.41, #queue-req: 0, 
[2025-12-17 21:02:01] INFO:     127.0.0.1:40630 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:02] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:03] INFO:     127.0.0.1:40634 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:03] Prefill batch, #new-seq: 1, #new-token: 1073, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:03] INFO:     127.0.0.1:40638 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:05] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:05] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.67, #queue-req: 0, 
[2025-12-17 21:02:05] INFO:     127.0.0.1:40642 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:05] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 943, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:05] INFO:     127.0.0.1:40646 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:07] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:07] INFO:     127.0.0.1:40650 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:07] Prefill batch, #new-seq: 1, #new-token: 1111, #cached-token: 16, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:07] Decode batch, #running-req: 1, #token: 1132, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.15, #queue-req: 0, 
[2025-12-17 21:02:07] INFO:     127.0.0.1:40654 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:09] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:09] INFO:     127.0.0.1:40658 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:09] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.37, #queue-req: 0, 
[2025-12-17 21:02:09] Prefill batch, #new-seq: 1, #new-token: 1425, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:09] INFO:     127.0.0.1:40662 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:11] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:11] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.02, #queue-req: 0, 
[2025-12-17 21:02:11] INFO:     127.0.0.1:40666 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:12] Prefill batch, #new-seq: 1, #new-token: 1232, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:12] INFO:     127.0.0.1:40670 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:14] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:14] INFO:     127.0.0.1:40674 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:14] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 943, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:14] Decode batch, #running-req: 1, #token: 972, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.74, #queue-req: 0, 
[2025-12-17 21:02:14] INFO:     127.0.0.1:40678 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:16] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:16] INFO:     127.0.0.1:40682 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:16] Prefill batch, #new-seq: 1, #new-token: 1613, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:16] INFO:     127.0.0.1:40686 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:18] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:18] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.89, #queue-req: 0, 
[2025-12-17 21:02:18] INFO:     127.0.0.1:40690 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:18] Prefill batch, #new-seq: 1, #new-token: 1249, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:18] INFO:     127.0.0.1:40694 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:20] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:20] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 15.60, #queue-req: 0, 
[2025-12-17 21:02:20] INFO:     127.0.0.1:40698 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:20] Prefill batch, #new-seq: 1, #new-token: 1089, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:20] INFO:     127.0.0.1:40702 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:22] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:23] INFO:     127.0.0.1:40708 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:23] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 945, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:23] Decode batch, #running-req: 1, #token: 964, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.97, #queue-req: 0, 
[2025-12-17 21:02:23] INFO:     127.0.0.1:40712 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:25] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:25] INFO:     127.0.0.1:40718 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:25] Prefill batch, #new-seq: 1, #new-token: 1271, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:25] INFO:     127.0.0.1:40722 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:26] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:27] INFO:     127.0.0.1:40726 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:27] Prefill batch, #new-seq: 1, #new-token: 1244, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:27] Decode batch, #running-req: 1, #token: 1263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.03, #queue-req: 0, 
[2025-12-17 21:02:27] INFO:     127.0.0.1:40730 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:29] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:29] INFO:     127.0.0.1:40734 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:29] Prefill batch, #new-seq: 1, #new-token: 866, #cached-token: 102, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:29] INFO:     127.0.0.1:40738 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:31] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:31] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.67, #queue-req: 0, 
[2025-12-17 21:02:31] INFO:     127.0.0.1:40742 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:31] Prefill batch, #new-seq: 1, #new-token: 1350, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:31] INFO:     127.0.0.1:40746 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:31] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 163.33, #queue-req: 0, 
[2025-12-17 21:02:33] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:33] INFO:     127.0.0.1:40750 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:33] Prefill batch, #new-seq: 1, #new-token: 1221, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:33] INFO:     127.0.0.1:40754 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:35] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:35] INFO:     127.0.0.1:40758 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:35] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 925, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:35] Decode batch, #running-req: 1, #token: 950, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.54, #queue-req: 0, 
[2025-12-17 21:02:35] INFO:     127.0.0.1:40762 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:37] Prefill batch, #new-seq: 1, #new-token: 67, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:37] INFO:     127.0.0.1:40766 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:37] Prefill batch, #new-seq: 1, #new-token: 1014, #cached-token: 97, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:37] Decode batch, #running-req: 1, #token: 1121, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.52, #queue-req: 0, 
[2025-12-17 21:02:37] INFO:     127.0.0.1:40770 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:39] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:39] INFO:     127.0.0.1:40774 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:39] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 947, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:39] INFO:     127.0.0.1:40778 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:42] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:42] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.90, #queue-req: 0, 
[2025-12-17 21:02:42] INFO:     127.0.0.1:40782 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:42] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 912, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:42] INFO:     127.0.0.1:40786 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:44] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:44] INFO:     127.0.0.1:40792 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:44] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 934, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:44] Decode batch, #running-req: 1, #token: 959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.03, #queue-req: 0, 
[2025-12-17 21:02:44] INFO:     127.0.0.1:40796 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:46] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:46] INFO:     127.0.0.1:40800 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:46] Prefill batch, #new-seq: 1, #new-token: 1060, #cached-token: 99, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:46] INFO:     127.0.0.1:40804 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:48] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:48] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.80, #queue-req: 0, 
[2025-12-17 21:02:48] INFO:     127.0.0.1:40808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:48] Prefill batch, #new-seq: 1, #new-token: 1415, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:48] INFO:     127.0.0.1:40812 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:50] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:50] INFO:     127.0.0.1:40816 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:50] Prefill batch, #new-seq: 1, #new-token: 20, #cached-token: 943, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:50] Decode batch, #running-req: 1, #token: 976, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.76, #queue-req: 0, 
[2025-12-17 21:02:50] INFO:     127.0.0.1:40820 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:52] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:52] INFO:     127.0.0.1:40826 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:52] Prefill batch, #new-seq: 1, #new-token: 1545, #cached-token: 37, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:52] Decode batch, #running-req: 1, #token: 1601, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.10, #queue-req: 0, 
[2025-12-17 21:02:52] INFO:     127.0.0.1:40830 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:54] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:54] INFO:     127.0.0.1:40834 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:54] Prefill batch, #new-seq: 1, #new-token: 1491, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:55] INFO:     127.0.0.1:40838 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:57] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:57] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.77, #queue-req: 0, 
[2025-12-17 21:02:57] INFO:     127.0.0.1:40844 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:57] Prefill batch, #new-seq: 1, #new-token: 1241, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:57] INFO:     127.0.0.1:40848 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:59] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:59] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 14.95, #queue-req: 0, 
[2025-12-17 21:02:59] INFO:     127.0.0.1:40852 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:02:59] Prefill batch, #new-seq: 1, #new-token: 1328, #cached-token: 18, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:02:59] INFO:     127.0.0.1:40856 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:01] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:01] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.26, #queue-req: 0, 
[2025-12-17 21:03:01] INFO:     127.0.0.1:40860 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:01] Prefill batch, #new-seq: 1, #new-token: 1012, #cached-token: 16, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:02] INFO:     127.0.0.1:40864 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:03] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:04] INFO:     127.0.0.1:40868 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:04] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 935, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:04] Decode batch, #running-req: 1, #token: 962, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.05, #queue-req: 0, 
[2025-12-17 21:03:04] INFO:     127.0.0.1:40872 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:06] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:06] INFO:     127.0.0.1:40876 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:06] Prefill batch, #new-seq: 1, #new-token: 1153, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:06] Decode batch, #running-req: 1, #token: 1190, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.93, #queue-req: 0, 
[2025-12-17 21:03:06] Decode batch, #running-req: 1, #token: 1230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 216.92, #queue-req: 0, 
[2025-12-17 21:03:06] Decode batch, #running-req: 1, #token: 1270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 21:03:06] Decode batch, #running-req: 1, #token: 1310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.64, #queue-req: 0, 
[2025-12-17 21:03:07] Decode batch, #running-req: 1, #token: 1350, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 21:03:07] Decode batch, #running-req: 1, #token: 1390, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.70, #queue-req: 0, 
[2025-12-17 21:03:07] Decode batch, #running-req: 1, #token: 1430, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 21:03:07] Decode batch, #running-req: 1, #token: 1470, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 21:03:07] Decode batch, #running-req: 1, #token: 1510, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 21:03:07] Decode batch, #running-req: 1, #token: 1550, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.78, #queue-req: 0, 
[2025-12-17 21:03:08] Decode batch, #running-req: 1, #token: 1590, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 21:03:08] Decode batch, #running-req: 1, #token: 1630, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.46, #queue-req: 0, 
[2025-12-17 21:03:08] Decode batch, #running-req: 1, #token: 1670, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.46, #queue-req: 0, 
[2025-12-17 21:03:08] Decode batch, #running-req: 1, #token: 1710, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 21:03:08] Decode batch, #running-req: 1, #token: 1750, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 21:03:09] Decode batch, #running-req: 1, #token: 1790, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 21:03:09] Decode batch, #running-req: 1, #token: 1830, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 21:03:09] Decode batch, #running-req: 1, #token: 1870, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.35, #queue-req: 0, 
[2025-12-17 21:03:09] Decode batch, #running-req: 1, #token: 1910, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 21:03:09] Decode batch, #running-req: 1, #token: 1950, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 21:03:09] Decode batch, #running-req: 1, #token: 1990, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.63, #queue-req: 0, 
[2025-12-17 21:03:10] Decode batch, #running-req: 1, #token: 2030, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 21:03:10] Decode batch, #running-req: 1, #token: 2070, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.29, #queue-req: 0, 
[2025-12-17 21:03:10] Decode batch, #running-req: 1, #token: 2110, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.91, #queue-req: 0, 
[2025-12-17 21:03:10] Decode batch, #running-req: 1, #token: 2150, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.88, #queue-req: 0, 
[2025-12-17 21:03:10] INFO:     127.0.0.1:40880 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:12] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:12] INFO:     127.0.0.1:40884 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:12] Prefill batch, #new-seq: 1, #new-token: 1382, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:12] INFO:     127.0.0.1:40890 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:12] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.71, #queue-req: 0, 
[2025-12-17 21:03:14] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:14] INFO:     127.0.0.1:40894 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:15] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 944, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:15] INFO:     127.0.0.1:40898 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:16] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:17] INFO:     127.0.0.1:40902 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:17] Prefill batch, #new-seq: 1, #new-token: 1310, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:17] Decode batch, #running-req: 1, #token: 1330, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.58, #queue-req: 0, 
[2025-12-17 21:03:17] INFO:     127.0.0.1:40906 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:18] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:19] INFO:     127.0.0.1:40910 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:19] Prefill batch, #new-seq: 1, #new-token: 1567, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:19] INFO:     127.0.0.1:40914 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:21] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:21] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 10.03, #queue-req: 0, 
[2025-12-17 21:03:21] INFO:     127.0.0.1:40918 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:21] Prefill batch, #new-seq: 1, #new-token: 1308, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:21] Decode batch, #running-req: 1, #token: 1378, token usage: 0.00, cuda graph: True, gen throughput (token/s): 170.63, #queue-req: 0, 
[2025-12-17 21:03:21] Decode batch, #running-req: 1, #token: 1418, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.46, #queue-req: 0, 
[2025-12-17 21:03:21] Decode batch, #running-req: 1, #token: 1458, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 21:03:21] Decode batch, #running-req: 1, #token: 1498, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 21:03:22] Decode batch, #running-req: 1, #token: 1538, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 21:03:22] Decode batch, #running-req: 1, #token: 1578, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 21:03:22] Decode batch, #running-req: 1, #token: 1618, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.49, #queue-req: 0, 
[2025-12-17 21:03:22] Decode batch, #running-req: 1, #token: 1658, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.25, #queue-req: 0, 
[2025-12-17 21:03:22] Decode batch, #running-req: 1, #token: 1698, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.36, #queue-req: 0, 
[2025-12-17 21:03:22] Decode batch, #running-req: 1, #token: 1738, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 21:03:23] Decode batch, #running-req: 1, #token: 1778, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.40, #queue-req: 0, 
[2025-12-17 21:03:23] Decode batch, #running-req: 1, #token: 1818, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.34, #queue-req: 0, 
[2025-12-17 21:03:23] Decode batch, #running-req: 1, #token: 1858, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.30, #queue-req: 0, 
[2025-12-17 21:03:23] Decode batch, #running-req: 1, #token: 1898, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.21, #queue-req: 0, 
[2025-12-17 21:03:23] Decode batch, #running-req: 1, #token: 1938, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.35, #queue-req: 0, 
[2025-12-17 21:03:24] Decode batch, #running-req: 1, #token: 1978, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 21:03:24] Decode batch, #running-req: 1, #token: 2018, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.46, #queue-req: 0, 
[2025-12-17 21:03:24] Decode batch, #running-req: 1, #token: 2058, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.26, #queue-req: 0, 
[2025-12-17 21:03:24] Decode batch, #running-req: 1, #token: 2098, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.82, #queue-req: 0, 
[2025-12-17 21:03:24] Decode batch, #running-req: 1, #token: 2138, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.94, #queue-req: 0, 
[2025-12-17 21:03:24] Decode batch, #running-req: 1, #token: 2178, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.97, #queue-req: 0, 
[2025-12-17 21:03:25] Decode batch, #running-req: 1, #token: 2218, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.89, #queue-req: 0, 
[2025-12-17 21:03:25] Decode batch, #running-req: 1, #token: 2258, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.88, #queue-req: 0, 
[2025-12-17 21:03:25] Decode batch, #running-req: 1, #token: 2298, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.84, #queue-req: 0, 
[2025-12-17 21:03:25] Decode batch, #running-req: 1, #token: 2338, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.90, #queue-req: 0, 
[2025-12-17 21:03:25] INFO:     127.0.0.1:40922 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:27] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:27] INFO:     127.0.0.1:40932 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:27] Prefill batch, #new-seq: 1, #new-token: 1295, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:27] INFO:     127.0.0.1:40936 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:29] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:29] INFO:     127.0.0.1:40940 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:29] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.49, #queue-req: 0, 
[2025-12-17 21:03:29] Prefill batch, #new-seq: 1, #new-token: 1628, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:30] INFO:     127.0.0.1:40944 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:32] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:32] INFO:     127.0.0.1:40950 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:32] Prefill batch, #new-seq: 1, #new-token: 1223, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:32] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 14.53, #queue-req: 0, 
[2025-12-17 21:03:32] INFO:     127.0.0.1:40954 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:34] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:34] INFO:     127.0.0.1:40960 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:34] Prefill batch, #new-seq: 1, #new-token: 1356, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:34] Decode batch, #running-req: 1, #token: 1415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.20, #queue-req: 0, 
[2025-12-17 21:03:35] Decode batch, #running-req: 1, #token: 1455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 217.92, #queue-req: 0, 
[2025-12-17 21:03:35] Decode batch, #running-req: 1, #token: 1495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.88, #queue-req: 0, 
[2025-12-17 21:03:35] Decode batch, #running-req: 1, #token: 1535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.64, #queue-req: 0, 
[2025-12-17 21:03:35] Decode batch, #running-req: 1, #token: 1575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 21:03:35] Decode batch, #running-req: 1, #token: 1615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 21:03:35] Decode batch, #running-req: 1, #token: 1655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 21:03:36] Decode batch, #running-req: 1, #token: 1695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 21:03:36] Decode batch, #running-req: 1, #token: 1735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 21:03:36] Decode batch, #running-req: 1, #token: 1775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 21:03:36] Decode batch, #running-req: 1, #token: 1815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 21:03:36] Decode batch, #running-req: 1, #token: 1855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.63, #queue-req: 0, 
[2025-12-17 21:03:37] Decode batch, #running-req: 1, #token: 1895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.49, #queue-req: 0, 
[2025-12-17 21:03:37] Decode batch, #running-req: 1, #token: 1935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 21:03:37] Decode batch, #running-req: 1, #token: 1975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 21:03:37] Decode batch, #running-req: 1, #token: 2015, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 21:03:37] Decode batch, #running-req: 1, #token: 2055, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 21:03:37] Decode batch, #running-req: 1, #token: 2095, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.15, #queue-req: 0, 
[2025-12-17 21:03:38] Decode batch, #running-req: 1, #token: 2135, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.07, #queue-req: 0, 
[2025-12-17 21:03:38] Decode batch, #running-req: 1, #token: 2175, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.12, #queue-req: 0, 
[2025-12-17 21:03:38] Decode batch, #running-req: 1, #token: 2215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.06, #queue-req: 0, 
[2025-12-17 21:03:38] Decode batch, #running-req: 1, #token: 2255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.24, #queue-req: 0, 
[2025-12-17 21:03:38] Decode batch, #running-req: 1, #token: 2295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.18, #queue-req: 0, 
[2025-12-17 21:03:39] Decode batch, #running-req: 1, #token: 2335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.90, #queue-req: 0, 
[2025-12-17 21:03:39] Decode batch, #running-req: 1, #token: 2375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.14, #queue-req: 0, 
[2025-12-17 21:03:39] INFO:     127.0.0.1:40964 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:41] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:41] INFO:     127.0.0.1:40970 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:41] Prefill batch, #new-seq: 1, #new-token: 1364, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:41] INFO:     127.0.0.1:40974 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:43] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:43] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.57, #queue-req: 0, 
[2025-12-17 21:03:43] INFO:     127.0.0.1:40980 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:43] Prefill batch, #new-seq: 1, #new-token: 1385, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:44] INFO:     127.0.0.1:40984 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:46] Prefill batch, #new-seq: 1, #new-token: 53, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:46] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 13.78, #queue-req: 0, 
[2025-12-17 21:03:46] INFO:     127.0.0.1:40988 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:46] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 945, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:47] Decode batch, #running-req: 1, #token: 1000, token usage: 0.00, cuda graph: True, gen throughput (token/s): 177.86, #queue-req: 0, 
[2025-12-17 21:03:47] Decode batch, #running-req: 1, #token: 1040, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 21:03:47] Decode batch, #running-req: 1, #token: 1080, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 21:03:47] Decode batch, #running-req: 1, #token: 1120, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 21:03:47] Decode batch, #running-req: 1, #token: 1160, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 21:03:47] Decode batch, #running-req: 1, #token: 1200, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 21:03:48] Decode batch, #running-req: 1, #token: 1240, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 21:03:48] Decode batch, #running-req: 1, #token: 1280, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 21:03:48] Decode batch, #running-req: 1, #token: 1320, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 21:03:48] Decode batch, #running-req: 1, #token: 1360, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 21:03:48] Decode batch, #running-req: 1, #token: 1400, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.35, #queue-req: 0, 
[2025-12-17 21:03:49] Decode batch, #running-req: 1, #token: 1440, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 21:03:49] Decode batch, #running-req: 1, #token: 1480, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.65, #queue-req: 0, 
[2025-12-17 21:03:49] Decode batch, #running-req: 1, #token: 1520, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 21:03:49] Decode batch, #running-req: 1, #token: 1560, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 21:03:49] Decode batch, #running-req: 1, #token: 1600, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 21:03:49] Decode batch, #running-req: 1, #token: 1640, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.36, #queue-req: 0, 
[2025-12-17 21:03:50] Decode batch, #running-req: 1, #token: 1680, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.30, #queue-req: 0, 
[2025-12-17 21:03:50] Decode batch, #running-req: 1, #token: 1720, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.33, #queue-req: 0, 
[2025-12-17 21:03:50] Decode batch, #running-req: 1, #token: 1760, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.24, #queue-req: 0, 
[2025-12-17 21:03:50] Decode batch, #running-req: 1, #token: 1800, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 21:03:50] Decode batch, #running-req: 1, #token: 1840, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.36, #queue-req: 0, 
[2025-12-17 21:03:51] Decode batch, #running-req: 1, #token: 1880, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.34, #queue-req: 0, 
[2025-12-17 21:03:51] Decode batch, #running-req: 1, #token: 1920, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.23, #queue-req: 0, 
[2025-12-17 21:03:51] Decode batch, #running-req: 1, #token: 1960, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.31, #queue-req: 0, 
[2025-12-17 21:03:51] INFO:     127.0.0.1:40992 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:53] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:53] INFO:     127.0.0.1:40996 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:53] Prefill batch, #new-seq: 1, #new-token: 1395, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:53] INFO:     127.0.0.1:41000 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:56] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:56] INFO:     127.0.0.1:41008 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:56] Prefill batch, #new-seq: 1, #new-token: 1346, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:56] Decode batch, #running-req: 1, #token: 1382, token usage: 0.00, cuda graph: True, gen throughput (token/s): 7.33, #queue-req: 0, 
[2025-12-17 21:03:56] INFO:     127.0.0.1:41012 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:58] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:58] INFO:     127.0.0.1:41016 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:03:58] Prefill batch, #new-seq: 1, #new-token: 1247, #cached-token: 97, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:03:59] Decode batch, #running-req: 1, #token: 1356, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.01, #queue-req: 0, 
[2025-12-17 21:03:59] Decode batch, #running-req: 1, #token: 1396, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 21:03:59] Decode batch, #running-req: 1, #token: 1436, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 21:03:59] Decode batch, #running-req: 1, #token: 1476, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.76, #queue-req: 0, 
[2025-12-17 21:03:59] Decode batch, #running-req: 1, #token: 1516, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.55, #queue-req: 0, 
[2025-12-17 21:03:59] Decode batch, #running-req: 1, #token: 1556, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 21:04:00] Decode batch, #running-req: 1, #token: 1596, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.62, #queue-req: 0, 
[2025-12-17 21:04:00] Decode batch, #running-req: 1, #token: 1636, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.49, #queue-req: 0, 
[2025-12-17 21:04:00] Decode batch, #running-req: 1, #token: 1676, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 21:04:00] Decode batch, #running-req: 1, #token: 1716, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 21:04:00] Decode batch, #running-req: 1, #token: 1756, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 21:04:01] Decode batch, #running-req: 1, #token: 1796, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.54, #queue-req: 0, 
[2025-12-17 21:04:01] Decode batch, #running-req: 1, #token: 1836, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 21:04:01] Decode batch, #running-req: 1, #token: 1876, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.32, #queue-req: 0, 
[2025-12-17 21:04:01] Decode batch, #running-req: 1, #token: 1916, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.27, #queue-req: 0, 
[2025-12-17 21:04:01] Decode batch, #running-req: 1, #token: 1956, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 21:04:01] Decode batch, #running-req: 1, #token: 1996, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 21:04:02] Decode batch, #running-req: 1, #token: 2036, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 21:04:02] Decode batch, #running-req: 1, #token: 2076, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.18, #queue-req: 0, 
[2025-12-17 21:04:02] Decode batch, #running-req: 1, #token: 2116, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.18, #queue-req: 0, 
[2025-12-17 21:04:02] Decode batch, #running-req: 1, #token: 2156, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.09, #queue-req: 0, 
[2025-12-17 21:04:02] Decode batch, #running-req: 1, #token: 2196, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.86, #queue-req: 0, 
[2025-12-17 21:04:03] Decode batch, #running-req: 1, #token: 2236, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.02, #queue-req: 0, 
[2025-12-17 21:04:03] Decode batch, #running-req: 1, #token: 2276, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.00, #queue-req: 0, 
[2025-12-17 21:04:03] Decode batch, #running-req: 1, #token: 2316, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.89, #queue-req: 0, 
[2025-12-17 21:04:03] INFO:     127.0.0.1:41020 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:05] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:05] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.55, #queue-req: 0, 
[2025-12-17 21:04:05] INFO:     127.0.0.1:41024 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:05] Prefill batch, #new-seq: 1, #new-token: 1303, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:05] INFO:     127.0.0.1:41028 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:07] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:07] Decode batch, #running-req: 1, #token: 93, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.02, #queue-req: 0, 
[2025-12-17 21:04:07] INFO:     127.0.0.1:41032 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:07] Prefill batch, #new-seq: 1, #new-token: 21, #cached-token: 887, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:07] INFO:     127.0.0.1:41036 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:09] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:09] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.34, #queue-req: 0, 
[2025-12-17 21:04:09] INFO:     127.0.0.1:41040 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:09] Prefill batch, #new-seq: 1, #new-token: 1441, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:10] INFO:     127.0.0.1:41044 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:11] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:12] INFO:     127.0.0.1:41048 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:12] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 926, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:12] Decode batch, #running-req: 1, #token: 946, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.03, #queue-req: 0, 
[2025-12-17 21:04:12] INFO:     127.0.0.1:41052 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:14] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:14] INFO:     127.0.0.1:41056 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:14] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 926, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:14] Decode batch, #running-req: 1, #token: 957, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.20, #queue-req: 0, 
[2025-12-17 21:04:14] INFO:     127.0.0.1:41060 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:16] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:16] INFO:     127.0.0.1:41064 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:16] Prefill batch, #new-seq: 1, #new-token: 1287, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:16] INFO:     127.0.0.1:41068 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:18] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:18] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.54, #queue-req: 0, 
[2025-12-17 21:04:18] INFO:     127.0.0.1:41072 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:18] Prefill batch, #new-seq: 1, #new-token: 725, #cached-token: 100, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:18] INFO:     127.0.0.1:41076 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:20] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:20] INFO:     127.0.0.1:41080 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:20] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 926, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:20] Decode batch, #running-req: 1, #token: 950, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.39, #queue-req: 0, 
[2025-12-17 21:04:20] Decode batch, #running-req: 1, #token: 990, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 21:04:20] Decode batch, #running-req: 1, #token: 1030, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.58, #queue-req: 0, 
[2025-12-17 21:04:21] Decode batch, #running-req: 1, #token: 1070, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.93, #queue-req: 0, 
[2025-12-17 21:04:21] Decode batch, #running-req: 1, #token: 1110, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 21:04:21] Decode batch, #running-req: 1, #token: 1150, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.91, #queue-req: 0, 
[2025-12-17 21:04:21] Decode batch, #running-req: 1, #token: 1190, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 21:04:21] Decode batch, #running-req: 1, #token: 1230, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.87, #queue-req: 0, 
[2025-12-17 21:04:21] Decode batch, #running-req: 1, #token: 1270, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.67, #queue-req: 0, 
[2025-12-17 21:04:22] Decode batch, #running-req: 1, #token: 1310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.04, #queue-req: 0, 
[2025-12-17 21:04:22] Decode batch, #running-req: 1, #token: 1350, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 21:04:22] Decode batch, #running-req: 1, #token: 1390, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 21:04:22] Decode batch, #running-req: 1, #token: 1430, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 21:04:22] Decode batch, #running-req: 1, #token: 1470, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.89, #queue-req: 0, 
[2025-12-17 21:04:23] Decode batch, #running-req: 1, #token: 1510, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 21:04:23] Decode batch, #running-req: 1, #token: 1550, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.96, #queue-req: 0, 
[2025-12-17 21:04:23] Decode batch, #running-req: 1, #token: 1590, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.81, #queue-req: 0, 
[2025-12-17 21:04:23] Decode batch, #running-req: 1, #token: 1630, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.60, #queue-req: 0, 
[2025-12-17 21:04:23] Decode batch, #running-req: 1, #token: 1670, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.71, #queue-req: 0, 
[2025-12-17 21:04:23] Decode batch, #running-req: 1, #token: 1710, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 21:04:24] Decode batch, #running-req: 1, #token: 1750, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 21:04:24] Decode batch, #running-req: 1, #token: 1790, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 21:04:24] Decode batch, #running-req: 1, #token: 1830, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 21:04:24] Decode batch, #running-req: 1, #token: 1870, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.66, #queue-req: 0, 
[2025-12-17 21:04:24] Decode batch, #running-req: 1, #token: 1910, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 21:04:25] INFO:     127.0.0.1:41084 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:26] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:27] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.64, #queue-req: 0, 
[2025-12-17 21:04:27] INFO:     127.0.0.1:41088 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:27] Prefill batch, #new-seq: 1, #new-token: 16, #cached-token: 886, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:27] INFO:     127.0.0.1:41092 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:29] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:29] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.90, #queue-req: 0, 
[2025-12-17 21:04:29] INFO:     127.0.0.1:41098 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:29] Prefill batch, #new-seq: 1, #new-token: 617, #cached-token: 289, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:29] INFO:     127.0.0.1:41102 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:31] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:31] INFO:     127.0.0.1:41106 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:31] Prefill batch, #new-seq: 1, #new-token: 1242, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:31] Decode batch, #running-req: 1, #token: 1275, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.69, #queue-req: 0, 
[2025-12-17 21:04:31] INFO:     127.0.0.1:41110 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:33] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:33] INFO:     127.0.0.1:41116 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:33] Prefill batch, #new-seq: 1, #new-token: 940, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:33] INFO:     127.0.0.1:41120 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:35] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:35] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.70, #queue-req: 0, 
[2025-12-17 21:04:35] INFO:     127.0.0.1:41124 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:35] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 926, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:35] Decode batch, #running-req: 1, #token: 974, token usage: 0.00, cuda graph: True, gen throughput (token/s): 185.76, #queue-req: 0, 
[2025-12-17 21:04:35] INFO:     127.0.0.1:41128 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:37] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:37] INFO:     127.0.0.1:41132 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:37] Prefill batch, #new-seq: 1, #new-token: 9, #cached-token: 935, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:37] Decode batch, #running-req: 1, #token: 968, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.39, #queue-req: 0, 
[2025-12-17 21:04:38] Decode batch, #running-req: 1, #token: 1008, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.23, #queue-req: 0, 
[2025-12-17 21:04:38] Decode batch, #running-req: 1, #token: 1048, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.95, #queue-req: 0, 
[2025-12-17 21:04:38] Decode batch, #running-req: 1, #token: 1088, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 21:04:38] Decode batch, #running-req: 1, #token: 1128, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.58, #queue-req: 0, 
[2025-12-17 21:04:38] Decode batch, #running-req: 1, #token: 1168, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 21:04:39] Decode batch, #running-req: 1, #token: 1208, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.74, #queue-req: 0, 
[2025-12-17 21:04:39] Decode batch, #running-req: 1, #token: 1248, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.75, #queue-req: 0, 
[2025-12-17 21:04:39] Decode batch, #running-req: 1, #token: 1288, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 21:04:39] Decode batch, #running-req: 1, #token: 1328, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.52, #queue-req: 0, 
[2025-12-17 21:04:39] Decode batch, #running-req: 1, #token: 1368, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.56, #queue-req: 0, 
[2025-12-17 21:04:39] Decode batch, #running-req: 1, #token: 1408, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 21:04:40] Decode batch, #running-req: 1, #token: 1448, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.86, #queue-req: 0, 
[2025-12-17 21:04:40] Decode batch, #running-req: 1, #token: 1488, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.68, #queue-req: 0, 
[2025-12-17 21:04:40] Decode batch, #running-req: 1, #token: 1528, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.63, #queue-req: 0, 
[2025-12-17 21:04:40] Decode batch, #running-req: 1, #token: 1568, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.41, #queue-req: 0, 
[2025-12-17 21:04:40] Decode batch, #running-req: 1, #token: 1608, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.37, #queue-req: 0, 
[2025-12-17 21:04:41] Decode batch, #running-req: 1, #token: 1648, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.36, #queue-req: 0, 
[2025-12-17 21:04:41] Decode batch, #running-req: 1, #token: 1688, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.48, #queue-req: 0, 
[2025-12-17 21:04:41] Decode batch, #running-req: 1, #token: 1728, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.34, #queue-req: 0, 
[2025-12-17 21:04:41] Decode batch, #running-req: 1, #token: 1768, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 21:04:41] Decode batch, #running-req: 1, #token: 1808, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.38, #queue-req: 0, 
[2025-12-17 21:04:41] Decode batch, #running-req: 1, #token: 1848, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.17, #queue-req: 0, 
[2025-12-17 21:04:42] Decode batch, #running-req: 1, #token: 1888, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.29, #queue-req: 0, 
[2025-12-17 21:04:42] Decode batch, #running-req: 1, #token: 1928, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.19, #queue-req: 0, 
[2025-12-17 21:04:42] INFO:     127.0.0.1:41136 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:44] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:44] INFO:     127.0.0.1:41140 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:44] Prefill batch, #new-seq: 1, #new-token: 1476, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:44] Decode batch, #running-req: 1, #token: 1515, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.97, #queue-req: 0, 
[2025-12-17 21:04:44] INFO:     127.0.0.1:41144 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:47] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:47] INFO:     127.0.0.1:41150 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:47] Prefill batch, #new-seq: 1, #new-token: 1355, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:47] Decode batch, #running-req: 1, #token: 1383, token usage: 0.00, cuda graph: True, gen throughput (token/s): 13.71, #queue-req: 0, 
[2025-12-17 21:04:47] INFO:     127.0.0.1:41154 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:49] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:49] INFO:     127.0.0.1:41158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:49] Prefill batch, #new-seq: 1, #new-token: 966, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:50] INFO:     127.0.0.1:41162 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:51] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:51] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.09, #queue-req: 0, 
[2025-12-17 21:04:51] INFO:     127.0.0.1:41166 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:51] Prefill batch, #new-seq: 1, #new-token: 1332, #cached-token: 11, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:51] INFO:     127.0.0.1:41170 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:53] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:54] INFO:     127.0.0.1:41174 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:54] Prefill batch, #new-seq: 1, #new-token: 1175, #cached-token: 118, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:54] Decode batch, #running-req: 1, #token: 1295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.97, #queue-req: 0, 
[2025-12-17 21:04:54] INFO:     127.0.0.1:41178 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:56] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:56] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 15.65, #queue-req: 0, 
[2025-12-17 21:04:56] INFO:     127.0.0.1:41182 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:56] Prefill batch, #new-seq: 1, #new-token: 18, #cached-token: 1249, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:56] INFO:     127.0.0.1:41186 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:58] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:58] INFO:     127.0.0.1:41190 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:04:58] Prefill batch, #new-seq: 1, #new-token: 1115, #cached-token: 171, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:04:58] Decode batch, #running-req: 1, #token: 1295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.96, #queue-req: 0, 
[2025-12-17 21:04:58] INFO:     127.0.0.1:41194 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:00] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:00] INFO:     127.0.0.1:41198 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:00] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 892, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:00] INFO:     127.0.0.1:41202 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:02] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:02] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.94, #queue-req: 0, 
[2025-12-17 21:05:02] INFO:     127.0.0.1:41208 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:02] Prefill batch, #new-seq: 1, #new-token: 1211, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:03] INFO:     127.0.0.1:41212 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:05] Prefill batch, #new-seq: 1, #new-token: 57, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:05] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.93, #queue-req: 0, 
[2025-12-17 21:05:05] INFO:     127.0.0.1:41218 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:05] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 926, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:05] INFO:     127.0.0.1:41222 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:07] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:07] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.92, #queue-req: 0, 
[2025-12-17 21:05:07] INFO:     127.0.0.1:41226 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:07] Prefill batch, #new-seq: 1, #new-token: 1433, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:07] INFO:     127.0.0.1:41230 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:09] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:09] INFO:     127.0.0.1:41234 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:09] Prefill batch, #new-seq: 1, #new-token: 1305, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:09] Decode batch, #running-req: 1, #token: 1342, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.93, #queue-req: 0, 
[2025-12-17 21:05:09] INFO:     127.0.0.1:41238 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:11] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:11] INFO:     127.0.0.1:41244 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:11] Prefill batch, #new-seq: 1, #new-token: 991, #cached-token: 133, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:11] INFO:     127.0.0.1:41248 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:13] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:13] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.95, #queue-req: 0, 
[2025-12-17 21:05:13] INFO:     127.0.0.1:41252 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:13] Prefill batch, #new-seq: 1, #new-token: 1393, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:13] INFO:     127.0.0.1:41256 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:15] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:15] Decode batch, #running-req: 1, #token: 71, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.16, #queue-req: 0, 
[2025-12-17 21:05:15] INFO:     127.0.0.1:41262 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:15] Prefill batch, #new-seq: 1, #new-token: 1347, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:15] INFO:     127.0.0.1:41266 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:17] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:18] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.74, #queue-req: 0, 
[2025-12-17 21:05:18] INFO:     127.0.0.1:41272 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:18] Prefill batch, #new-seq: 1, #new-token: 1216, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:18] INFO:     127.0.0.1:41276 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:20] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:20] Decode batch, #running-req: 1, #token: 86, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.50, #queue-req: 0, 
[2025-12-17 21:05:20] INFO:     127.0.0.1:41280 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:20] Prefill batch, #new-seq: 1, #new-token: 1144, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:20] INFO:     127.0.0.1:41284 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:22] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:22] Decode batch, #running-req: 1, #token: 78, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.31, #queue-req: 0, 
[2025-12-17 21:05:22] INFO:     127.0.0.1:41288 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:22] Prefill batch, #new-seq: 1, #new-token: 1382, #cached-token: 37, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:22] INFO:     127.0.0.1:41292 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:24] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:24] INFO:     127.0.0.1:41298 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:24] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 935, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:24] Decode batch, #running-req: 1, #token: 956, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.67, #queue-req: 0, 
[2025-12-17 21:05:24] INFO:     127.0.0.1:41302 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:26] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:26] INFO:     127.0.0.1:41306 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:26] Prefill batch, #new-seq: 1, #new-token: 1151, #cached-token: 110, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:26] Decode batch, #running-req: 1, #token: 1285, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.17, #queue-req: 0, 
[2025-12-17 21:05:26] INFO:     127.0.0.1:41310 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:28] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:28] INFO:     127.0.0.1:41314 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:28] Prefill batch, #new-seq: 1, #new-token: 757, #cached-token: 188, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:28] INFO:     127.0.0.1:41318 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:31] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:31] Decode batch, #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.27, #queue-req: 0, 
[2025-12-17 21:05:31] INFO:     127.0.0.1:41322 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:31] Prefill batch, #new-seq: 1, #new-token: 1544, #cached-token: 169, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:31] INFO:     127.0.0.1:41326 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:33] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:33] INFO:     127.0.0.1:41330 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:33] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.12, #queue-req: 0, 
[2025-12-17 21:05:33] Prefill batch, #new-seq: 1, #new-token: 1332, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:33] INFO:     127.0.0.1:41334 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:35] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:35] Decode batch, #running-req: 1, #token: 95, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.37, #queue-req: 0, 
[2025-12-17 21:05:35] INFO:     127.0.0.1:41340 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:35] Prefill batch, #new-seq: 1, #new-token: 22, #cached-token: 893, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:35] INFO:     127.0.0.1:41344 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:37] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:37] INFO:     127.0.0.1:41350 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:37] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 935, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:38] Decode batch, #running-req: 1, #token: 957, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.30, #queue-req: 0, 
[2025-12-17 21:05:38] INFO:     127.0.0.1:41354 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:40] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:40] INFO:     127.0.0.1:41358 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:40] Prefill batch, #new-seq: 1, #new-token: 1070, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:40] Decode batch, #running-req: 1, #token: 1114, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.15, #queue-req: 0, 
[2025-12-17 21:05:40] INFO:     127.0.0.1:41362 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:42] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:42] INFO:     127.0.0.1:41368 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:42] Prefill batch, #new-seq: 1, #new-token: 1284, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:42] INFO:     127.0.0.1:41372 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:42] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.21, #queue-req: 0, 
[2025-12-17 21:05:44] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:44] INFO:     127.0.0.1:41376 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:44] Prefill batch, #new-seq: 1, #new-token: 1502, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:44] Decode batch, #running-req: 1, #token: 1559, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.09, #queue-req: 0, 
[2025-12-17 21:05:44] INFO:     127.0.0.1:41380 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:46] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:46] INFO:     127.0.0.1:41384 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:46] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 893, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:46] INFO:     127.0.0.1:41388 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:48] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:48] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.59, #queue-req: 0, 
[2025-12-17 21:05:48] INFO:     127.0.0.1:41394 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:48] Prefill batch, #new-seq: 1, #new-token: 1223, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:48] INFO:     127.0.0.1:41398 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:50] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:50] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.12, #queue-req: 0, 
[2025-12-17 21:05:50] INFO:     127.0.0.1:41402 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:50] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 926, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:50] INFO:     127.0.0.1:41406 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:53] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:53] INFO:     127.0.0.1:41410 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:53] Prefill batch, #new-seq: 1, #new-token: 1469, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:53] INFO:     127.0.0.1:41414 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:55] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:55] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.77, #queue-req: 0, 
[2025-12-17 21:05:55] INFO:     127.0.0.1:41418 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:55] Prefill batch, #new-seq: 1, #new-token: 12, #cached-token: 936, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:55] Decode batch, #running-req: 1, #token: 980, token usage: 0.00, cuda graph: True, gen throughput (token/s): 179.92, #queue-req: 0, 
[2025-12-17 21:05:55] INFO:     127.0.0.1:41422 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:57] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:57] INFO:     127.0.0.1:41426 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:05:57] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 893, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:05:57] Decode batch, #running-req: 1, #token: 923, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.60, #queue-req: 0, 
[2025-12-17 21:05:58] INFO:     127.0.0.1:41430 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:00] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:00] INFO:     127.0.0.1:41434 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:00] Prefill batch, #new-seq: 1, #new-token: 1385, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:00] Decode batch, #running-req: 1, #token: 1431, token usage: 0.00, cuda graph: True, gen throughput (token/s): 14.57, #queue-req: 0, 
[2025-12-17 21:06:00] Decode batch, #running-req: 1, #token: 1471, token usage: 0.00, cuda graph: True, gen throughput (token/s): 221.50, #queue-req: 0, 
[2025-12-17 21:06:01] Decode batch, #running-req: 1, #token: 1511, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.72, #queue-req: 0, 
[2025-12-17 21:06:01] Decode batch, #running-req: 1, #token: 1551, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 21:06:01] Decode batch, #running-req: 1, #token: 1591, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.18, #queue-req: 0, 
[2025-12-17 21:06:01] Decode batch, #running-req: 1, #token: 1631, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.38, #queue-req: 0, 
[2025-12-17 21:06:01] Decode batch, #running-req: 1, #token: 1671, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 21:06:01] Decode batch, #running-req: 1, #token: 1711, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.29, #queue-req: 0, 
[2025-12-17 21:06:02] Decode batch, #running-req: 1, #token: 1751, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.59, #queue-req: 0, 
[2025-12-17 21:06:02] Decode batch, #running-req: 1, #token: 1791, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.39, #queue-req: 0, 
[2025-12-17 21:06:02] Decode batch, #running-req: 1, #token: 1831, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.42, #queue-req: 0, 
[2025-12-17 21:06:02] Decode batch, #running-req: 1, #token: 1871, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.39, #queue-req: 0, 
[2025-12-17 21:06:02] Decode batch, #running-req: 1, #token: 1911, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.47, #queue-req: 0, 
[2025-12-17 21:06:03] Decode batch, #running-req: 1, #token: 1951, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.33, #queue-req: 0, 
[2025-12-17 21:06:03] Decode batch, #running-req: 1, #token: 1991, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 21:06:03] Decode batch, #running-req: 1, #token: 2031, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.38, #queue-req: 0, 
[2025-12-17 21:06:03] Decode batch, #running-req: 1, #token: 2071, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.27, #queue-req: 0, 
[2025-12-17 21:06:03] Decode batch, #running-req: 1, #token: 2111, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.89, #queue-req: 0, 
[2025-12-17 21:06:03] Decode batch, #running-req: 1, #token: 2151, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.93, #queue-req: 0, 
[2025-12-17 21:06:04] Decode batch, #running-req: 1, #token: 2191, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.74, #queue-req: 0, 
[2025-12-17 21:06:04] Decode batch, #running-req: 1, #token: 2231, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.80, #queue-req: 0, 
[2025-12-17 21:06:04] Decode batch, #running-req: 1, #token: 2271, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.85, #queue-req: 0, 
[2025-12-17 21:06:04] Decode batch, #running-req: 1, #token: 2311, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.84, #queue-req: 0, 
[2025-12-17 21:06:04] Decode batch, #running-req: 1, #token: 2351, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.80, #queue-req: 0, 
[2025-12-17 21:06:05] Decode batch, #running-req: 1, #token: 2391, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.89, #queue-req: 0, 
[2025-12-17 21:06:05] INFO:     127.0.0.1:41438 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:08] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:08] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 11.73, #queue-req: 0, 
[2025-12-17 21:06:08] INFO:     127.0.0.1:41446 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:08] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 926, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:08] INFO:     127.0.0.1:41450 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:10] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:10] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.68, #queue-req: 0, 
[2025-12-17 21:06:10] INFO:     127.0.0.1:41454 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:10] Prefill batch, #new-seq: 1, #new-token: 1248, #cached-token: 13, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:10] INFO:     127.0.0.1:41458 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:12] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:12] INFO:     127.0.0.1:41462 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:12] Prefill batch, #new-seq: 1, #new-token: 15, #cached-token: 926, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:12] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.81, #queue-req: 0, 
[2025-12-17 21:06:12] INFO:     127.0.0.1:41466 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:14] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:14] INFO:     127.0.0.1:41470 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:14] Prefill batch, #new-seq: 1, #new-token: 1072, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:15] Decode batch, #running-req: 1, #token: 1129, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.66, #queue-req: 0, 
[2025-12-17 21:06:15] INFO:     127.0.0.1:41474 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:16] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:17] INFO:     127.0.0.1:41478 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:17] Prefill batch, #new-seq: 1, #new-token: 19, #cached-token: 926, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:17] Decode batch, #running-req: 1, #token: 969, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.40, #queue-req: 0, 
[2025-12-17 21:06:17] INFO:     127.0.0.1:41482 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:19] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:19] INFO:     127.0.0.1:41486 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:19] Prefill batch, #new-seq: 1, #new-token: 1303, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:19] INFO:     127.0.0.1:41490 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:21] Prefill batch, #new-seq: 1, #new-token: 52, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:21] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.91, #queue-req: 0, 
[2025-12-17 21:06:21] INFO:     127.0.0.1:41494 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:21] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 926, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:21] INFO:     127.0.0.1:41498 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:23] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:23] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.73, #queue-req: 0, 
[2025-12-17 21:06:23] INFO:     127.0.0.1:41502 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:23] Prefill batch, #new-seq: 1, #new-token: 1520, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:23] INFO:     127.0.0.1:41506 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:25] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:25] INFO:     127.0.0.1:41510 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:25] Prefill batch, #new-seq: 1, #new-token: 1370, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:26] Decode batch, #running-req: 1, #token: 1412, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.14, #queue-req: 0, 
[2025-12-17 21:06:26] INFO:     127.0.0.1:41514 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:28] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:28] INFO:     127.0.0.1:41518 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:28] Prefill batch, #new-seq: 1, #new-token: 1328, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:28] Decode batch, #running-req: 1, #token: 1365, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.41, #queue-req: 0, 
[2025-12-17 21:06:28] INFO:     127.0.0.1:41522 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:30] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:30] INFO:     127.0.0.1:41528 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:30] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 925, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:30] Decode batch, #running-req: 1, #token: 957, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.34, #queue-req: 0, 
[2025-12-17 21:06:30] INFO:     127.0.0.1:41532 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:32] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:32] INFO:     127.0.0.1:41536 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:32] Prefill batch, #new-seq: 1, #new-token: 1259, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:32] Decode batch, #running-req: 1, #token: 1304, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.92, #queue-req: 0, 
[2025-12-17 21:06:32] INFO:     127.0.0.1:41540 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:34] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:34] INFO:     127.0.0.1:41544 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:34] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 1254, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:34] Decode batch, #running-req: 1, #token: 1289, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.22, #queue-req: 0, 
[2025-12-17 21:06:34] INFO:     127.0.0.1:41548 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:36] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:36] INFO:     127.0.0.1:41554 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:36] Prefill batch, #new-seq: 1, #new-token: 1115, #cached-token: 120, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:36] Decode batch, #running-req: 1, #token: 1255, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.74, #queue-req: 0, 
[2025-12-17 21:06:37] Decode batch, #running-req: 1, #token: 1295, token usage: 0.00, cuda graph: True, gen throughput (token/s): 211.17, #queue-req: 0, 
[2025-12-17 21:06:37] Decode batch, #running-req: 1, #token: 1335, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 21:06:37] Decode batch, #running-req: 1, #token: 1375, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.61, #queue-req: 0, 
[2025-12-17 21:06:37] Decode batch, #running-req: 1, #token: 1415, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.53, #queue-req: 0, 
[2025-12-17 21:06:37] Decode batch, #running-req: 1, #token: 1455, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.63, #queue-req: 0, 
[2025-12-17 21:06:38] Decode batch, #running-req: 1, #token: 1495, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.50, #queue-req: 0, 
[2025-12-17 21:06:38] Decode batch, #running-req: 1, #token: 1535, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.55, #queue-req: 0, 
[2025-12-17 21:06:38] Decode batch, #running-req: 1, #token: 1575, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.44, #queue-req: 0, 
[2025-12-17 21:06:38] Decode batch, #running-req: 1, #token: 1615, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.40, #queue-req: 0, 
[2025-12-17 21:06:38] Decode batch, #running-req: 1, #token: 1655, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.39, #queue-req: 0, 
[2025-12-17 21:06:38] Decode batch, #running-req: 1, #token: 1695, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.37, #queue-req: 0, 
[2025-12-17 21:06:39] Decode batch, #running-req: 1, #token: 1735, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.37, #queue-req: 0, 
[2025-12-17 21:06:39] Decode batch, #running-req: 1, #token: 1775, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.51, #queue-req: 0, 
[2025-12-17 21:06:39] Decode batch, #running-req: 1, #token: 1815, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.33, #queue-req: 0, 
[2025-12-17 21:06:39] Decode batch, #running-req: 1, #token: 1855, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.33, #queue-req: 0, 
[2025-12-17 21:06:39] Decode batch, #running-req: 1, #token: 1895, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.29, #queue-req: 0, 
[2025-12-17 21:06:40] Decode batch, #running-req: 1, #token: 1935, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.28, #queue-req: 0, 
[2025-12-17 21:06:40] Decode batch, #running-req: 1, #token: 1975, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.57, #queue-req: 0, 
[2025-12-17 21:06:40] Decode batch, #running-req: 1, #token: 2015, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.46, #queue-req: 0, 
[2025-12-17 21:06:40] Decode batch, #running-req: 1, #token: 2055, token usage: 0.00, cuda graph: True, gen throughput (token/s): 220.29, #queue-req: 0, 
[2025-12-17 21:06:40] Decode batch, #running-req: 1, #token: 2095, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.87, #queue-req: 0, 
[2025-12-17 21:06:40] Decode batch, #running-req: 1, #token: 2135, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.97, #queue-req: 0, 
[2025-12-17 21:06:41] Decode batch, #running-req: 1, #token: 2175, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.85, #queue-req: 0, 
[2025-12-17 21:06:41] Decode batch, #running-req: 1, #token: 2215, token usage: 0.00, cuda graph: True, gen throughput (token/s): 219.68, #queue-req: 0, 
[2025-12-17 21:06:41] INFO:     127.0.0.1:41558 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:43] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:43] INFO:     127.0.0.1:41564 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:43] Prefill batch, #new-seq: 1, #new-token: 1527, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:43] Decode batch, #running-req: 1, #token: 1568, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.88, #queue-req: 0, 
[2025-12-17 21:06:43] INFO:     127.0.0.1:41568 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:45] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:45] INFO:     127.0.0.1:41572 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:45] Prefill batch, #new-seq: 1, #new-token: 13, #cached-token: 927, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:45] INFO:     127.0.0.1:41576 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:47] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:47] Decode batch, #running-req: 1, #token: 83, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.27, #queue-req: 0, 
[2025-12-17 21:06:47] INFO:     127.0.0.1:41580 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:48] Prefill batch, #new-seq: 1, #new-token: 1408, #cached-token: 40, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:48] INFO:     127.0.0.1:41584 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:50] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:50] INFO:     127.0.0.1:41588 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:50] Prefill batch, #new-seq: 1, #new-token: 1315, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:50] Decode batch, #running-req: 1, #token: 1357, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.85, #queue-req: 0, 
[2025-12-17 21:06:50] INFO:     127.0.0.1:41592 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:52] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:52] INFO:     127.0.0.1:41596 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:52] Prefill batch, #new-seq: 1, #new-token: 1164, #cached-token: 12, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:52] INFO:     127.0.0.1:41600 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:54] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:54] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.43, #queue-req: 0, 
[2025-12-17 21:06:54] INFO:     127.0.0.1:41604 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:54] Prefill batch, #new-seq: 1, #new-token: 1263, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:54] Decode batch, #running-req: 1, #token: 1324, token usage: 0.00, cuda graph: True, gen throughput (token/s): 176.63, #queue-req: 0, 
[2025-12-17 21:06:54] INFO:     127.0.0.1:41608 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:56] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:56] INFO:     127.0.0.1:41612 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:56] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 926, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:56] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.41, #queue-req: 0, 
[2025-12-17 21:06:56] INFO:     127.0.0.1:41616 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:58] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:58] INFO:     127.0.0.1:41620 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:06:58] Prefill batch, #new-seq: 1, #new-token: 1139, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:06:58] INFO:     127.0.0.1:41624 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:04] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:04] INFO:     127.0.0.1:41628 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:04] Prefill batch, #new-seq: 1, #new-token: 1199, #cached-token: 140, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:04] Decode batch, #running-req: 1, #token: 1344, token usage: 0.00, cuda graph: True, gen throughput (token/s): 4.86, #queue-req: 0, 
[2025-12-17 21:07:05] INFO:     127.0.0.1:41632 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:07] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:07] INFO:     127.0.0.1:41638 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:07] Prefill batch, #new-seq: 1, #new-token: 11, #cached-token: 894, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:07] Decode batch, #running-req: 1, #token: 908, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.24, #queue-req: 0, 
[2025-12-17 21:07:07] INFO:     127.0.0.1:41642 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:09] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:09] INFO:     127.0.0.1:41648 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:09] Prefill batch, #new-seq: 1, #new-token: 1091, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:09] Decode batch, #running-req: 1, #token: 1141, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.55, #queue-req: 0, 
[2025-12-17 21:07:09] INFO:     127.0.0.1:41652 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:12] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:12] INFO:     127.0.0.1:41658 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:12] Prefill batch, #new-seq: 1, #new-token: 1209, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:12] INFO:     127.0.0.1:41662 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:14] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:14] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.76, #queue-req: 0, 
[2025-12-17 21:07:14] INFO:     127.0.0.1:41666 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:14] Prefill batch, #new-seq: 1, #new-token: 14, #cached-token: 935, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:14] INFO:     127.0.0.1:41670 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:16] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:16] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.62, #queue-req: 0, 
[2025-12-17 21:07:16] INFO:     127.0.0.1:41676 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:16] Prefill batch, #new-seq: 1, #new-token: 1233, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:16] INFO:     127.0.0.1:41680 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:18] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:18] Decode batch, #running-req: 1, #token: 91, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.67, #queue-req: 0, 
[2025-12-17 21:07:18] INFO:     127.0.0.1:41684 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:18] Prefill batch, #new-seq: 1, #new-token: 23, #cached-token: 926, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:18] INFO:     127.0.0.1:41688 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:20] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:20] INFO:     127.0.0.1:41692 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:20] Prefill batch, #new-seq: 1, #new-token: 1432, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:20] Decode batch, #running-req: 1, #token: 1468, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.20, #queue-req: 0, 
[2025-12-17 21:07:20] INFO:     127.0.0.1:41696 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:22] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:23] INFO:     127.0.0.1:41700 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:23] Prefill batch, #new-seq: 1, #new-token: 1160, #cached-token: 95, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:23] INFO:     127.0.0.1:41704 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:25] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:25] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.43, #queue-req: 0, 
[2025-12-17 21:07:25] INFO:     127.0.0.1:41712 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:25] Prefill batch, #new-seq: 1, #new-token: 1222, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:25] INFO:     127.0.0.1:41716 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:27] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:27] INFO:     127.0.0.1:41720 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:27] Prefill batch, #new-seq: 1, #new-token: 1144, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:27] INFO:     127.0.0.1:41724 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:29] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:29] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.60, #queue-req: 0, 
[2025-12-17 21:07:29] INFO:     127.0.0.1:41730 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:29] Prefill batch, #new-seq: 1, #new-token: 1319, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:29] INFO:     127.0.0.1:41734 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:31] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:31] INFO:     127.0.0.1:41740 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:31] Prefill batch, #new-seq: 1, #new-token: 1246, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:31] INFO:     127.0.0.1:41744 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:31] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.39, #queue-req: 0, 
[2025-12-17 21:07:33] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:33] INFO:     127.0.0.1:41748 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:33] Prefill batch, #new-seq: 1, #new-token: 17, #cached-token: 926, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:33] Decode batch, #running-req: 1, #token: 970, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.72, #queue-req: 0, 
[2025-12-17 21:07:33] INFO:     127.0.0.1:41752 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:36] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:36] INFO:     127.0.0.1:41756 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:36] Prefill batch, #new-seq: 1, #new-token: 1062, #cached-token: 156, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:36] INFO:     127.0.0.1:41760 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:38] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:38] Decode batch, #running-req: 1, #token: 77, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.61, #queue-req: 0, 
[2025-12-17 21:07:38] INFO:     127.0.0.1:41764 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:38] Prefill batch, #new-seq: 1, #new-token: 929, #cached-token: 156, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:38] INFO:     127.0.0.1:41768 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:40] Prefill batch, #new-seq: 1, #new-token: 56, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:40] Decode batch, #running-req: 1, #token: 82, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.92, #queue-req: 0, 
[2025-12-17 21:07:40] INFO:     127.0.0.1:41774 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:40] Prefill batch, #new-seq: 1, #new-token: 1240, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:40] INFO:     127.0.0.1:41778 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:42] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:43] INFO:     127.0.0.1:41782 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:43] Prefill batch, #new-seq: 1, #new-token: 1266, #cached-token: 134, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:43] Decode batch, #running-req: 1, #token: 1402, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.41, #queue-req: 0, 
[2025-12-17 21:07:43] INFO:     127.0.0.1:41786 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:45] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:45] INFO:     127.0.0.1:41790 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:45] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 904, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:45] Decode batch, #running-req: 1, #token: 959, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.77, #queue-req: 0, 
[2025-12-17 21:07:45] INFO:     127.0.0.1:41794 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:47] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:47] INFO:     127.0.0.1:41798 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:47] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 871, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:47] Decode batch, #running-req: 1, #token: 936, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.38, #queue-req: 0, 
[2025-12-17 21:07:47] INFO:     127.0.0.1:41802 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:49] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:50] INFO:     127.0.0.1:41808 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:50] Prefill batch, #new-seq: 1, #new-token: 1261, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:50] Decode batch, #running-req: 1, #token: 1310, token usage: 0.00, cuda graph: True, gen throughput (token/s): 14.57, #queue-req: 0, 
[2025-12-17 21:07:50] INFO:     127.0.0.1:41812 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:52] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:52] INFO:     127.0.0.1:41816 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:52] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 905, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:52] Decode batch, #running-req: 1, #token: 960, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.86, #queue-req: 0, 
[2025-12-17 21:07:52] INFO:     127.0.0.1:41820 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:54] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:54] INFO:     127.0.0.1:41824 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:54] Prefill batch, #new-seq: 1, #new-token: 935, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:54] INFO:     127.0.0.1:41828 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:56] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:56] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.23, #queue-req: 0, 
[2025-12-17 21:07:56] INFO:     127.0.0.1:41832 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:56] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 913, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:56] INFO:     127.0.0.1:41836 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:58] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:58] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 18.81, #queue-req: 0, 
[2025-12-17 21:07:58] INFO:     127.0.0.1:41840 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:07:58] Prefill batch, #new-seq: 1, #new-token: 1461, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:07:58] INFO:     127.0.0.1:41844 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:01] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:01] INFO:     127.0.0.1:41848 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:01] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 904, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:01] Decode batch, #running-req: 1, #token: 955, token usage: 0.00, cuda graph: True, gen throughput (token/s): 14.22, #queue-req: 0, 
[2025-12-17 21:08:01] INFO:     127.0.0.1:41852 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:04] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:04] INFO:     127.0.0.1:41856 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:04] Prefill batch, #new-seq: 1, #new-token: 1119, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:04] INFO:     127.0.0.1:41860 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:06] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:06] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.32, #queue-req: 0, 
[2025-12-17 21:08:06] INFO:     127.0.0.1:41864 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:06] Prefill batch, #new-seq: 1, #new-token: 40, #cached-token: 905, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:06] INFO:     127.0.0.1:41868 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:09] Prefill batch, #new-seq: 1, #new-token: 49, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:09] INFO:     127.0.0.1:41874 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:09] Prefill batch, #new-seq: 1, #new-token: 1065, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:09] Decode batch, #running-req: 1, #token: 1112, token usage: 0.00, cuda graph: True, gen throughput (token/s): 13.72, #queue-req: 0, 
[2025-12-17 21:08:09] INFO:     127.0.0.1:41878 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:11] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:11] INFO:     127.0.0.1:41882 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:11] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 905, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:11] INFO:     127.0.0.1:41886 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:13] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:13] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.43, #queue-req: 0, 
[2025-12-17 21:08:13] INFO:     127.0.0.1:41890 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:13] Prefill batch, #new-seq: 1, #new-token: 1226, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:13] INFO:     127.0.0.1:41894 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:15] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:15] INFO:     127.0.0.1:41898 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:15] Prefill batch, #new-seq: 1, #new-token: 1220, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:15] Decode batch, #running-req: 1, #token: 1260, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.48, #queue-req: 0, 
[2025-12-17 21:08:15] INFO:     127.0.0.1:41902 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:17] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:17] INFO:     127.0.0.1:41906 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:17] Prefill batch, #new-seq: 1, #new-token: 1254, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:18] INFO:     127.0.0.1:41910 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:20] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:20] Decode batch, #running-req: 1, #token: 76, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.52, #queue-req: 0, 
[2025-12-17 21:08:20] INFO:     127.0.0.1:41914 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:20] Prefill batch, #new-seq: 1, #new-token: 1125, #cached-token: 36, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:20] INFO:     127.0.0.1:41918 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:22] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:22] INFO:     127.0.0.1:41924 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:22] Prefill batch, #new-seq: 1, #new-token: 29, #cached-token: 905, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:22] Decode batch, #running-req: 1, #token: 936, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.32, #queue-req: 0, 
[2025-12-17 21:08:22] INFO:     127.0.0.1:41928 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:24] Prefill batch, #new-seq: 1, #new-token: 58, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:24] INFO:     127.0.0.1:41932 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:24] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 904, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:24] INFO:     127.0.0.1:41936 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:26] Prefill batch, #new-seq: 1, #new-token: 54, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:26] Decode batch, #running-req: 1, #token: 87, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.47, #queue-req: 0, 
[2025-12-17 21:08:26] INFO:     127.0.0.1:41940 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:26] Prefill batch, #new-seq: 1, #new-token: 1438, #cached-token: 14, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:26] INFO:     127.0.0.1:41944 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:28] Prefill batch, #new-seq: 1, #new-token: 55, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:28] INFO:     127.0.0.1:41948 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:28] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 925, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:28] Decode batch, #running-req: 1, #token: 974, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.14, #queue-req: 0, 
[2025-12-17 21:08:28] INFO:     127.0.0.1:41952 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:30] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 22, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:30] INFO:     127.0.0.1:41956 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:30] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 931, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:30] INFO:     127.0.0.1:41960 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:33] Prefill batch, #new-seq: 1, #new-token: 51, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:33] Decode batch, #running-req: 1, #token: 84, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.40, #queue-req: 0, 
[2025-12-17 21:08:33] INFO:     127.0.0.1:41966 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:33] Prefill batch, #new-seq: 1, #new-token: 1424, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:33] INFO:     127.0.0.1:41970 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:35] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:35] INFO:     127.0.0.1:41974 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:35] Prefill batch, #new-seq: 1, #new-token: 1405, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:35] INFO:     127.0.0.1:41978 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:37] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 27, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:37] Decode batch, #running-req: 1, #token: 75, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.23, #queue-req: 0, 
[2025-12-17 21:08:37] INFO:     127.0.0.1:41982 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:37] Prefill batch, #new-seq: 1, #new-token: 38, #cached-token: 914, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:38] INFO:     127.0.0.1:41986 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:40] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:40] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 12.84, #queue-req: 0, 
[2025-12-17 21:08:40] INFO:     127.0.0.1:41990 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:40] Prefill batch, #new-seq: 1, #new-token: 1437, #cached-token: 34, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:41] INFO:     127.0.0.1:41994 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:43] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 31, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:43] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.85, #queue-req: 0, 
[2025-12-17 21:08:43] INFO:     127.0.0.1:41998 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:43] Prefill batch, #new-seq: 1, #new-token: 39, #cached-token: 872, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:43] INFO:     127.0.0.1:42002 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:45] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:45] INFO:     127.0.0.1:42006 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:45] Prefill batch, #new-seq: 1, #new-token: 33, #cached-token: 905, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:45] Decode batch, #running-req: 1, #token: 943, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.59, #queue-req: 0, 
[2025-12-17 21:08:45] INFO:     127.0.0.1:42010 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:47] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:47] INFO:     127.0.0.1:42014 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:47] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 904, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:47] INFO:     127.0.0.1:42018 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:50] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 33, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:50] Decode batch, #running-req: 1, #token: 79, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.45, #queue-req: 0, 
[2025-12-17 21:08:50] INFO:     127.0.0.1:42024 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:50] Prefill batch, #new-seq: 1, #new-token: 36, #cached-token: 904, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:50] INFO:     127.0.0.1:42030 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:56] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:56] INFO:     127.0.0.1:42036 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:56] Prefill batch, #new-seq: 1, #new-token: 34, #cached-token: 905, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:56] Decode batch, #running-req: 1, #token: 942, token usage: 0.00, cuda graph: True, gen throughput (token/s): 6.50, #queue-req: 0, 
[2025-12-17 21:08:56] INFO:     127.0.0.1:42040 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:58] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:58] INFO:     127.0.0.1:42044 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:08:58] Prefill batch, #new-seq: 1, #new-token: 32, #cached-token: 904, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:08:58] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.86, #queue-req: 0, 
[2025-12-17 21:08:58] INFO:     127.0.0.1:42048 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:00] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 28, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:00] INFO:     127.0.0.1:42054 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:00] Prefill batch, #new-seq: 1, #new-token: 1352, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:00] INFO:     127.0.0.1:42058 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:02] Prefill batch, #new-seq: 1, #new-token: 41, #cached-token: 29, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:03] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 8.97, #queue-req: 0, 
[2025-12-17 21:09:03] INFO:     127.0.0.1:42064 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:03] Prefill batch, #new-seq: 1, #new-token: 763, #cached-token: 190, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:03] INFO:     127.0.0.1:42068 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:05] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:05] Decode batch, #running-req: 1, #token: 81, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.57, #queue-req: 0, 
[2025-12-17 21:09:05] INFO:     127.0.0.1:42072 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:05] Prefill batch, #new-seq: 1, #new-token: 1231, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:05] INFO:     127.0.0.1:42076 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:07] Prefill batch, #new-seq: 1, #new-token: 44, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:07] Decode batch, #running-req: 1, #token: 0, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.53, #queue-req: 0, 
[2025-12-17 21:09:07] INFO:     127.0.0.1:42080 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:07] Prefill batch, #new-seq: 1, #new-token: 1097, #cached-token: 112, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:07] INFO:     127.0.0.1:42084 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:09] Prefill batch, #new-seq: 1, #new-token: 46, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:09] INFO:     127.0.0.1:42088 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:09] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 1229, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:09] INFO:     127.0.0.1:42092 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:11] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:11] Decode batch, #running-req: 1, #token: 74, token usage: 0.00, cuda graph: True, gen throughput (token/s): 9.47, #queue-req: 0, 
[2025-12-17 21:09:11] INFO:     127.0.0.1:42096 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:11] Prefill batch, #new-seq: 1, #new-token: 29, #cached-token: 907, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:11] INFO:     127.0.0.1:42100 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:13] Prefill batch, #new-seq: 1, #new-token: 42, #cached-token: 38, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:14] Decode batch, #running-req: 1, #token: 90, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.81, #queue-req: 0, 
[2025-12-17 21:09:14] INFO:     127.0.0.1:42106 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:14] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 874, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:14] INFO:     127.0.0.1:42110 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:16] Prefill batch, #new-seq: 1, #new-token: 45, #cached-token: 30, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:16] Decode batch, #running-req: 1, #token: 80, token usage: 0.00, cuda graph: True, gen throughput (token/s): 16.92, #queue-req: 0, 
[2025-12-17 21:09:16] INFO:     127.0.0.1:42114 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:16] Prefill batch, #new-seq: 1, #new-token: 1197, #cached-token: 35, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:16] INFO:     127.0.0.1:42118 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:18] Prefill batch, #new-seq: 1, #new-token: 59, #cached-token: 23, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:18] Decode batch, #running-req: 1, #token: 85, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.57, #queue-req: 0, 
[2025-12-17 21:09:18] INFO:     127.0.0.1:42122 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:18] Prefill batch, #new-seq: 1, #new-token: 1152, #cached-token: 118, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:18] INFO:     127.0.0.1:42126 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:20] Prefill batch, #new-seq: 1, #new-token: 43, #cached-token: 25, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:20] Decode batch, #running-req: 1, #token: 73, token usage: 0.00, cuda graph: True, gen throughput (token/s): 19.67, #queue-req: 0, 
[2025-12-17 21:09:20] INFO:     127.0.0.1:42132 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:20] Prefill batch, #new-seq: 1, #new-token: 1222, #cached-token: 32, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:20] INFO:     127.0.0.1:42136 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:22] Prefill batch, #new-seq: 1, #new-token: 48, #cached-token: 26, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:22] INFO:     127.0.0.1:42140 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:22] Prefill batch, #new-seq: 1, #new-token: 1232, #cached-token: 101, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:23] Decode batch, #running-req: 1, #token: 1338, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.64, #queue-req: 0, 
[2025-12-17 21:09:23] INFO:     127.0.0.1:42144 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:25] Prefill batch, #new-seq: 1, #new-token: 50, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:25] INFO:     127.0.0.1:42148 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:25] Prefill batch, #new-seq: 1, #new-token: 35, #cached-token: 914, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:25] Decode batch, #running-req: 1, #token: 956, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.99, #queue-req: 0, 
[2025-12-17 21:09:25] INFO:     127.0.0.1:42154 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:27] Prefill batch, #new-seq: 1, #new-token: 47, #cached-token: 24, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:27] INFO:     127.0.0.1:42158 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:09:27] Prefill batch, #new-seq: 1, #new-token: 1122, #cached-token: 15, token usage: 0.00, #running-req: 0, #queue-req: 0, 
[2025-12-17 21:09:27] Decode batch, #running-req: 1, #token: 1151, token usage: 0.00, cuda graph: True, gen throughput (token/s): 17.71, #queue-req: 0, 
[2025-12-17 21:09:27] INFO:     127.0.0.1:42162 - "POST /generate HTTP/1.1" 200 OK
[2025-12-17 21:11:05] SIGTERM received. signum=None frame=None. Draining requests and shutting down...
